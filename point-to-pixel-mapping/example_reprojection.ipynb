{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import Birch, KMeans, MeanShift, DBSCAN\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from point_cloud_utils import get_pcd\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from reproject_merged_pointcloud import reproject_points_to_label, merge_associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/laurenzheidrich/Downloads/','fused_dataset')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "            KittiGTMovingObjectFilter(\n",
    "                os.path.join(\n",
    "                    DATASET_PATH,\n",
    "                    \"sequences\",\n",
    "                    \"%.2d\" % SEQUENCE_NUM,\n",
    "                    \"labels\",\n",
    "                )\n",
    "            ),\n",
    "            RangeFilter(2.5, 120),\n",
    "            ApplyPose(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the point cloud and the left and right image of the stereo camera. If labels for those images are available they can be read in, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 58\n",
    "ind_end = 59\n",
    "\n",
    "pcd, T_pcd = aggregate_pointcloud(dataset, ind_start, ind_end, clip_to_imageframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = [\"cam2\", \"cam3\"]\n",
    "cam_ind = 0\n",
    "point_to_label_reprojections = []\n",
    "\n",
    "for points_index in range(ind_start+5, ind_end+5):\n",
    "\tlabel_PIL = dataset.get_sam_label(cams[cam_ind], points_index)\n",
    "\tlabel = cv2.cvtColor(np.array(label_PIL), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\tT_world2lidar = np.linalg.inv(dataset.get_pose(points_index))\n",
    "\tT_lidar2cam, K = dataset.get_calibration_matrices(cams[cam_ind])\n",
    "\tT_world2cam = T_lidar2cam @ T_world2lidar\n",
    "\t\n",
    "\tpoint_to_label_reprojections.append(reproject_points_to_label(np.array(pcd.points), T_pcd, label, T_world2cam, K, hidden_point_removal=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_matrix = merge_associations(point_to_label_reprojections, len(pcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range (num_points):\n",
    "    if not np.any(association_matrix[i].toarray()):\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227357\n"
     ]
    }
   ],
   "source": [
    "print(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = len(pcd.points)\n",
    "proximity_threshold = 0.5\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "points = np.asarray(pcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = cdist(points, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for i in range(num_points):\n",
    "    G.add_node(i, pos=points[i], associations=association_matrix[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_points):\n",
    "    for j in range (i+1, num_points):\n",
    "        if dist_matrix[i, j] <= proximity_threshold:\n",
    "            dist_weight = np.exp(-alpha * dist_matrix[i, j])\n",
    "            feature_weight = np.exp(-beta * np.sum(G.nodes[i]['associations'] != G.nodes[j]['associations']))\n",
    "            G.add_edge(i, j, weight=(dist_weight * feature_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = [node for node, degree in G.degree() if degree == 0]\n",
    "print(len(isolated_nodes))\n",
    "G.remove_nodes_from(isolated_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "connected_components = list(nx.connected_components(G))\n",
    "print(len(connected_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pcd_test= filter_points_from_dict(np.array(pcd.points), point_to_label_reprojections[5])\n",
    "#pcd_test_o3d = color_pcd_with_labels(pcd_test, point_to_label_reprojections[5])\n",
    "#o3d.visualization.draw_geometries([pcd_test_o3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 75\n",
    "tSVD = TruncatedSVD(n_components=68)\n",
    "transformed_data = tSVD.fit_transform(association_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birch is fastest, results are also quite nice\n",
    "birch_model = Birch(threshold=0.1, n_clusters=67)\n",
    "birch_model.fit(transformed_data)\n",
    "labels = birch_model.predict(transformed_data)\n",
    "\n",
    "# kmeans is quite fast, results look okay, some noise\n",
    "#kmeans = KMeans(n_clusters=80)\n",
    "#labels = kmeans.fit_predict(transformed_data)\n",
    "\n",
    "# DBSCAN doesn't really produce great results and takes really long\n",
    "#dbscan = DBSCAN(eps=0.5, min_samples=100)\n",
    "#labels = dbscan.fit_predict(transformed_data)\n",
    "\n",
    "# Meanshift takes way too long\n",
    "#meanshift = MeanShift()\n",
    "#labels = meanshift.fit_predict(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Assignments:\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(\"Cluster Assignments:\")\n",
    "print(len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorspace = plt.cm.rainbow(np.linspace(0, 1, len(set(labels))))[:, :3]\n",
    "colors = [colorspace[i] for i in labels]\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.array(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"pcd_merge_clustered.pcd\", pcd, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
