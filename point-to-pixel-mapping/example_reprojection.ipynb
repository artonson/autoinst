{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import networkx as nx\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import eigh\n",
    "from scipy.sparse import linalg\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.cluster import Birch, KMeans, MeanShift, DBSCAN, SpectralClustering\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from normalized_cut import normalized_cut\n",
    "\n",
    "from point_cloud_utils import get_pcd\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from reproject_merged_pointcloud import reproject_points_to_label, merge_associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/laurenzheidrich/Downloads/','fused_dataset')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "            KittiGTMovingObjectFilter(\n",
    "                os.path.join(\n",
    "                    DATASET_PATH,\n",
    "                    \"sequences\",\n",
    "                    \"%.2d\" % SEQUENCE_NUM,\n",
    "                    \"labels\",\n",
    "                )\n",
    "            ),\n",
    "            RangeFilter(2.5, 120),\n",
    "            ApplyPose(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the point cloud and the left and right image of the stereo camera. If labels for those images are available they can be read in, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 58\n",
    "ind_end = 65\n",
    "\n",
    "pcd_aggregated, T_pcd = aggregate_pointcloud(dataset, ind_start, ind_end, clip_to_imageframe=True)\n",
    "\n",
    "pcd_cut = pcd_aggregated\n",
    "pcd_cut = pcd_cut.select_by_index(np.where(np.asarray(pcd_cut.points)[:,0] > 6)[0])\n",
    "pcd_cut = pcd_cut.select_by_index(np.where(np.asarray(pcd_cut.points)[:,0] < 15)[0])\n",
    "\n",
    "pcd = pcd_cut.voxel_down_sample(voxel_size=0.25)\n",
    "\n",
    "# Just use a subset of pcd for testing\n",
    "#pcd = pcd.select_by_index(np.where(np.asarray(pcd.points)[:,0] < 10)[0])\n",
    "#pcd = pcd.select_by_index(np.where(np.asarray(pcd.points)[:,0] > 6)[0])\n",
    "#pcd.points = pcd.points[::10]\n",
    "num_points = np.asarray(pcd.points).shape[0]\n",
    "print(\"num points: \", num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.io.write_point_cloud(\"pcd_cropped.pcd\", pcd, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can to the point to label reprojection for each timestep and merge them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = [\"cam2\", \"cam3\"]\n",
    "cam_ind = 0\n",
    "point_to_label_reprojections = []\n",
    "\n",
    "for points_index in range(ind_start, ind_end):\n",
    "\tlabel_PIL = dataset.get_sam_label(cams[cam_ind], points_index)\n",
    "\tlabel = cv2.cvtColor(np.array(label_PIL), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\tT_world2lidar = np.linalg.inv(dataset.get_pose(points_index))\n",
    "\tT_lidar2cam, K = dataset.get_calibration_matrices(cams[cam_ind])\n",
    "\tT_world2cam = T_lidar2cam @ T_world2lidar\n",
    "\t\n",
    "\tpoint_to_label_reprojections.append(reproject_points_to_label(np.array(pcd.points), T_pcd, label, T_world2cam, K, hidden_point_removal=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the merged list we can now build the association matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_matrix = merge_associations(point_to_label_reprojections, len(pcd.points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define important parameters and build the point-to-point distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proximity_threshold = 1 # meters that points can be apart froim each other and still be considered neighbors\n",
    "alpha = 6.0 # weight of the spatial proximity term\n",
    "beta = 1.0 # weight of the feature similarity term\n",
    "points = np.asarray(pcd.points)\n",
    "dist_matrix = cdist(points, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the graph with nodes and edges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.where(dist_matrix <= proximity_threshold, 1, 0)\n",
    "\n",
    "feature_diff = np.zeros((num_points, num_points))\n",
    "\n",
    "for i in range(num_points):\n",
    "    for j in range(i+1, num_points):\n",
    "        if mask[i,j] == 1:\n",
    "            feature_diff[i,j] = np.exp(-beta * np.sum(association_matrix[i] != association_matrix[j]))\n",
    "            feature_diff[j,i] = feature_diff[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.exp(-alpha * (mask * dist_matrix)) * feature_diff\n",
    "G = nx.from_numpy_array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for i in range(num_points):\n",
    "    G.add_node(i, pos=points[i], label=0, associations=association_matrix[i])\n",
    "\n",
    "for i in range(num_points):\n",
    "    for j in range (i+1, num_points):\n",
    "        if dist_matrix[i, j] <= proximity_threshold:\n",
    "            dist_weight = np.exp(-alpha * dist_matrix[i, j])\n",
    "            feature_weight = np.exp(-beta * np.sum(G.nodes[i]['associations'] != G.nodes[j]['associations']))\n",
    "            G.add_edge(i, j, weight=(dist_weight * feature_weight))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can check for the number of connected components and number of isolated nodes in the constructed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_nodes = [node for node, degree in G.degree() if degree == 0]\n",
    "print(\"There are\", len(isolated_nodes), \"isolated nodes\")\n",
    "#G.remove_nodes_from(isolated_nodes)\n",
    "\n",
    "connected_components = list(nx.connected_components(G))\n",
    "print(\"There are\", len(connected_components), \"connected components\")\n",
    "\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform normalized cuts and save the cut graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import re\n",
    "#cut_graph = cProfile.run('normalized_cut(G, thresh = 0.01, num_cuts = 10)')\n",
    "cut_graph = normalized_cut(G, thresh = 0.01, num_cuts = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize the different components and save them to a point cloud file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = list(nx.connected_components(cut_graph))\n",
    "print(\"Number of cut regions:\",len(connected_components))\n",
    "\n",
    "# Visualize the connected components\n",
    "component_lengths = []\n",
    "labels = np.zeros(num_points, dtype=np.int32)\n",
    "for i in range(len(connected_components)):\n",
    "    labels[list(connected_components[i])] = i\n",
    "    component_lengths.append(len(connected_components[i]))\n",
    "\n",
    "print(\"Component lengths:\", component_lengths)\n",
    "\n",
    "colorspace = plt.cm.rainbow(np.linspace(0, 1, len(set(labels))))[:, :3]\n",
    "np.random.shuffle(colorspace) #Otherwise close subgraphs look very similar!\n",
    "colors = [colorspace[i] for i in labels]\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.array(colors))\n",
    "\n",
    "#o3d.io.write_point_cloud(\"pcd_merge_clustered.pcd\", pcd, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, we can perform the nearest point labeling on the big point cloud, if the clustering beforehand was done on a sampled point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_cut.paint_uniform_color([0, 0, 0])\n",
    "pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "i=0\n",
    "for point in np.asarray(pcd_cut.points):\n",
    "    [_, idx, _] = pcd_tree.search_knn_vector_3d(point, 1)\n",
    "    np.asarray(pcd_cut.colors)[i,:] = np.asarray(pcd.colors)[idx[0], :]\n",
    "    i+=1\n",
    "\n",
    "o3d.io.write_point_cloud(\"pcd_merge_clustered.pcd\", pcd_cut, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform spectral clustering instead of normalized cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 55\n",
    "A = nx.adjacency_matrix(G).toarray()\n",
    "sc = SpectralClustering(n_clusters=n_clusters, affinity=\"precomputed\", n_init=100, assign_labels=\"discretize\")\n",
    "labels = sc.fit_predict(A)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorspace = plt.cm.rainbow(np.linspace(0, 1, n_clusters))[:, :3]\n",
    "colors = [colorspace[i] for i in labels]\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.array(colors))\n",
    "#o3d.io.write_point_cloud(\"pcd_merge_clustered.pcd\", pcd, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can perform the nearest point labeling on the big point cloud, if the clustering beforehand was done on a sampled point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_cut.paint_uniform_color([0, 0, 0])\n",
    "pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "i=0\n",
    "for point in np.asarray(pcd_cut.points):\n",
    "    [_, idx, _] = pcd_tree.search_knn_vector_3d(point, 1)\n",
    "    np.asarray(pcd_cut.colors)[i,:] = np.asarray(pcd.colors)[idx[0], :]\n",
    "    i+=1\n",
    "\n",
    "o3d.io.write_point_cloud(\"pcd_merge_clustered.pcd\", pcd_cut, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform other clustering methods of the feature matrix, that do not take the graph as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 25\n",
    "tSVD = TruncatedSVD(n_components=25)\n",
    "transformed_data = tSVD.fit_transform(association_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birch is fastest, results are also quite nice\n",
    "birch_model = Birch(threshold=0.1, n_clusters=25)\n",
    "birch_model.fit(transformed_data)\n",
    "labels = birch_model.predict(transformed_data)\n",
    "\n",
    "# kmeans is quite fast, results look okay, some noise\n",
    "#kmeans = KMeans(n_clusters=80)\n",
    "#labels = kmeans.fit_predict(transformed_data)\n",
    "\n",
    "# DBSCAN doesn't really produce great results and takes really long\n",
    "#dbscan = DBSCAN(eps=0.5, min_samples=100)\n",
    "#labels = dbscan.fit_predict(transformed_data)\n",
    "\n",
    "# Meanshift takes way too long\n",
    "#meanshift = MeanShift()\n",
    "#labels = meanshift.fit_predict(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster Assignments:\")\n",
    "print(len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorspace = plt.cm.rainbow(np.linspace(0, 1, len(set(labels))))[:, :3]\n",
    "colors = [colorspace[i] for i in labels]\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.array(colors))\n",
    "o3d.io.write_point_cloud(\"pcd_merge_clustered.pcd\", pcd, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
