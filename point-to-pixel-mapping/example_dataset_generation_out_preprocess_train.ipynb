{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics_class import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN\n",
    "\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "def remove_semantics(labels,preds):\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "        return new_ncuts_labels\n",
    "\n",
    "def DBSCAN_clustering_logic(cur_pcd, pcd_all, eps=1.0, min_samples=100):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on the point cloud data.\n",
    "\n",
    "    :param cur_pcd: Current point cloud for clustering.\n",
    "    :param pcd_all: All point cloud data.\n",
    "    :param eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "    :param min_samples: The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "    :return: Cluster labels for each point in the point cloud.\n",
    "    \"\"\"\n",
    "    not_road_points = np.asarray(cur_pcd.points)\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(not_road_points)\n",
    "    #clustering = HDBSCAN(min_cluster_size=min_samples).fit(not_road_points)\n",
    "    labels_not_road = clustering.labels_\n",
    "    colors_gen = generate_random_colors(500)\n",
    "    \n",
    "    # Reproject cluster labels to the original point cloud size\n",
    "    cluster_labels = np.ones((len(pcd_all.points), 1)) * -1\n",
    "    labels_non_ground = kDTree_1NN_feature_reprojection(cluster_labels, pcd_all, labels_not_road.reshape(-1,1), cur_pcd)\n",
    "    colors = np.zeros((labels_non_ground.shape[0],3))\n",
    "    unique_labels = list(np.unique(labels_non_ground))\n",
    "    for j in unique_labels:\n",
    "            cur_idcs = np.where(labels_non_ground == j)[0]\n",
    "            \n",
    "            colors[cur_idcs] = np.array(colors_gen[unique_labels.index(j)])\n",
    "    pcd_all.colors = o3d.utility.Vector3dVector(colors / 255.)\n",
    "    return pcd_all\n",
    "\n",
    "def dbscan_clustering(pcd_chunks_major_downsampled, pcds, center_ids,ground_clouds):\n",
    "    labels_clustering = []\n",
    "    for i in range(len(pcd_chunks_major_downsampled)):\n",
    "        cur_pcd = pcd_chunks_major_downsampled[i]\n",
    "        pcd_all = pcds[i]\n",
    "        ground_cloud = ground_clouds[i]\n",
    "        cluster_labels = DBSCAN_clustering_logic(cur_pcd, pcd_all)  # Implement your DBSCAN logic here\n",
    "        ground_labels = np.ones((np.asarray(ground_cloud.points).shape[0],1)) * -1\n",
    "        cluster_labels = np.concatenate((cluster_labels,ground_labels),0)\n",
    "        labels_clustering.append(cluster_labels)\n",
    "        \n",
    "    return labels_clustering\n",
    "\n",
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "\n",
    "\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "        #if labels[i] != (-1):\n",
    "        #    pcd_colored.colors[i] = np.array(colors[labels[i]]) / 255\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/ 255)\n",
    "    return pcd_colored\n",
    "\n",
    "\n",
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "def uniform_down_sample_with_indices(points,every_k_points):\n",
    "    # Create a new point cloud for the downsampled output\n",
    "    \n",
    "    # List to hold the indices of the points that are kept\n",
    "    indices = []\n",
    "    \n",
    "    \n",
    "    # Iterate over the points and keep every k-th point\n",
    "    for i in range(0, points.shape[0], every_k_points):\n",
    "        indices.append(i)\n",
    "\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge \n",
    "\n",
    "def downsample_chunk(points,chunk_preds_ncut,kitti_chunk_labels,labels_clustering):\n",
    "        num_points_to_sample = 60000\n",
    "        every_k_points = int(kitti_chunk_labels.shape[0] /num_points_to_sample) \n",
    "        indeces = uniform_down_sample_with_indices(kitti_chunk_labels,every_k_points)\n",
    "\n",
    "        points = points[indeces]\n",
    "        chunk_preds_ncut = chunk_preds_ncut[indeces]\n",
    "        kitti_chunk_labels = kitti_chunk_labels[indeces]\n",
    "        labels_clustering = labels_clustering[indeces]\n",
    "        return points,chunk_preds_ncut,kitti_chunk_labels,labels_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 7\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join('/Users/cedric/Datasets/semantic_kitti/')\n",
    "import shutil \n",
    "\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 24 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False \n",
    "out_folder_ncuts = 'test_data/'\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "\n",
    "seqs = list(range(7,8))\n",
    "\n",
    "for seq in seqs : \n",
    "        print(\"Sequence\",seq)\n",
    "        SEQUENCE_NUM = seq\n",
    "        dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "        ind_start = 0\n",
    "        ind_end = len(dataset)\n",
    "        \n",
    "        if os.path.exists(f'{out_folder}non_ground{SEQUENCE_NUM}.pcd') == False : \n",
    "                process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                        major_voxel_size=major_voxel_size,icp=False,\n",
    "                                        out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                        ground_segmentation_method=ground_segmentation_method)\n",
    "        \n",
    "        if os.path.exists(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}.pcd') == False : \n",
    "                pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        \n",
    "                o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "                np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}.npz',panoptic_nonground=kitti_labels['panoptic_nonground'],\n",
    "                                                        panoptic_ground=kitti_labels['panoptic_ground'],\n",
    "                                                        instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                        instance_ground=kitti_labels['instance_ground'],\n",
    "                                                        seg_ground = kitti_labels['seg_ground'],\n",
    "                                                        seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                        )\n",
    "        \n",
    "        pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}.pcd')\n",
    "        pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}.pcd')\n",
    "\n",
    "        kitti_labels_orig = {}\n",
    "        with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}.npz') as data :\n",
    "                kitti_labels_orig['panoptic_ground'] = data['panoptic_ground']\n",
    "                kitti_labels_orig['panoptic_nonground'] = data['panoptic_nonground']\n",
    "                kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "                kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "                kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "                kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        with np.load(f'{out_folder}all_poses_' + str(SEQUENCE_NUM) + '.npz') as data:\n",
    "                all_poses = data['all_poses']\n",
    "                T_pcd = data['T_pcd']\n",
    "                first_position = T_pcd[:3, 3]\n",
    "                \n",
    "        poses, positions, \\\n",
    "        sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)\n",
    "\n",
    "        pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "        pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "        indices,indices_ground, center_positions, \\\n",
    "        center_ids, chunk_bounds, kitti_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)\n",
    "\n",
    "        data_store_folder = out_folder + str(SEQUENCE_NUM) + \"/\"\n",
    "        if os.path.exists(data_store_folder) == False :\n",
    "                os.makedirs(data_store_folder)\n",
    "        \n",
    "        patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "        out_data = []\n",
    "        for sequence in range(len(center_ids)):\n",
    "                        merged_chunk,file_name, pcd_chunk, pcd_chunk_ground, inliers_ground = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                                pcd_nonground_chunks_major_downsampling,\n",
    "                                pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                                positions,first_position,sampled_indices_global,\n",
    "                                chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                                alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                                proximity_threshold=proximity_threshold,\n",
    "                                out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                                patchwise_indices=patchwise_indices)\n",
    "                        \n",
    "                        kitti_labels['ground']['panoptic'][sequence] = kitti_labels['ground']['panoptic'][sequence][inliers_ground]\n",
    "                        kitti_labels['ground']['instance'][sequence] = kitti_labels['ground']['instance'][sequence][inliers_ground]\n",
    "                        \n",
    "                        name = file_name.split('/')[-1]\n",
    "                        o3d.io.write_point_cloud(file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                        \n",
    "                        pcd_dbscan = DBSCAN_clustering_logic(pcd_nonground_chunks_major_downsampling[sequence],\n",
    "                                                        pcd_nonground_chunks[sequence],\n",
    "                                                        eps=0.6, min_samples=10)\n",
    "                        cur_name = name.split('.')[0]\n",
    "                        \n",
    "                        kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['panoptic'][sequence].reshape(-1,),\n",
    "                                                colors=colors,gt_labels=kitti_labels_orig['panoptic_nonground'])\n",
    "                        \n",
    "                        kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                                colors=colors,gt_labels=kitti_labels_orig['instance_nonground'])\n",
    "                        \n",
    "                        cluster_pcd = pcd_dbscan + pcd_chunk_ground\n",
    "                        gt_pcd = kitti_chunk + pcd_chunk_ground\n",
    "                        pred_pcd = merged_chunk  + pcd_chunk_ground\n",
    "                        \n",
    "                        unique_colors, labels_ncuts = np.unique(np.asarray(pred_pcd.colors), axis=0, return_inverse=True)\n",
    "                        unique_colors, labels_dbscan = np.unique(np.asarray(cluster_pcd.colors), axis=0, return_inverse=True)\n",
    "                        unique_colors, labels_kitti = np.unique(np.asarray(gt_pcd.colors),axis=0, return_inverse=True)\n",
    "                        \n",
    "                        pts = np.asarray(gt_pcd.points)\n",
    "                        points,labels_ncuts,labels_kitti,labels_dbscan = downsample_chunk(pts,\n",
    "                                                                                labels_ncuts,labels_kitti,labels_dbscan)\n",
    "                        \n",
    "                        np.savez(data_store_folder + name.split('.')[0] +  '.npz',pts=points,ncut_labels=labels_ncuts,\n",
    "                                kitti_labels=labels_kitti,cluster_labels=labels_dbscan)\n",
    "                        \n",
    "                        #kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,kitti_labels['ground']['instance'][sequence].reshape(-1,))\n",
    "                        #o3d.io.write_point_cloud(out_dbscan + name, pcd_dbscan + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                        #o3d.io.write_point_cloud(out_kitti + name, kitti_chunk + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                        #o3d.io.write_point_cloud(out_kitti_instance + name, kitti_chunk_instance + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npcd_new = o3d.geometry.PointCloud()\\npts_num = 1000000\\npcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\\n\\nmap_labelled = color_pcd_by_labels(pcd_new,                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\\n\\no3d.visualization.draw_geometries([map_labelled])\\n#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pts_num = 1000000\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmetrics_ncuts = Metrics(name='ncuts')\\nmetrics_dbscan = Metrics(name='dbscan')\\nmetrics_test = Metrics(name='test')\\n\\nmetrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\\n\\nmetrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\\n\\nmetrics_dbscan.compute_all_aps()\\nmetrics_ncuts.compute_all_aps()\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_dbscan = np.unique(np.asarray(merge_dbscan.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "\n",
    "\n",
    "\n",
    "new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "new_dbscan_labels = remove_semantics(labels_kitti,labels_dbscan)\n",
    "\n",
    "\n",
    "'''\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_dbscan = Metrics(name='dbscan')\n",
    "metrics_test = Metrics(name='test')\n",
    "\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\n",
    "\n",
    "metrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\n",
    "\n",
    "metrics_dbscan.compute_all_aps()\n",
    "metrics_ncuts.compute_all_aps()\n",
    "'''\n",
    "#merge_vis = color_pcd_by_labels(merge,labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kitti_pcd = color_pcd_by_labels(merge_dbscan,new_ncuts_labels)\n",
    "o3d.io.write_point_cloud(out_folder + \"ncuts_instances_tarl.pcd\",new_kitti_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "#new_dbscan_pcd = color_pcd_by_labels(merge_dbscan,new_dbscan_labels)\n",
    "#o3d.io.write_point_cloud(out_folder + \"dbscan_instances.pcd\",new_dbscan_pcd, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_dbscan = Metrics(name='dbscan')\n",
    "metrics_test = Metrics(name='test')\n",
    "\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\n",
    "#metrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\n",
    "metrics_ncuts.compute_all_aps()\n",
    "#metrics_dbscan.compute_all_aps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([new_kitti_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/cedric/Datasets/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d.pipelines import registration\n",
    "import numpy as np \n",
    "merge.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\n",
    "for i in range(70,72):\n",
    "\tlocal_pcd = o3d.geometry.PointCloud()\n",
    "\tlocal_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\t\n",
    "\t\n",
    "\t## label visualization \n",
    "\tlabeled_pcd = o3d.geometry.PointCloud()\n",
    "\tlabeled_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\tlabeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n",
    "\tpanoptic_labels = dataset[i].panoptic_labels # semantics + panoptics combined \n",
    "\tsemantic_labels = dataset[i].semantic_labels\n",
    "\tinstance_labels = dataset[i].instance_labels\n",
    "\tintensity = dataset[i].intensity\n",
    "\t\n",
    "\ttransform = dataset.get_pose(i)\n",
    "\tlocal_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\treg_p2l = registration.registration_icp(local_pcd, merge, 0.9, transform, registration.TransformationEstimationPointToPlane(), registration.ICPConvergenceCriteria(max_iteration=1000))\n",
    "\ttransform = reg_p2l.transformation\n",
    "\tlocal_pcd.transform(transform)\n",
    "\t\n",
    "\tlocal_pcd.normals = o3d.utility.Vector3dVector([])\n",
    "\t\n",
    "\tlocal_pcd.paint_uniform_color([0, 0, 0])\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tcolors, labels,local_labels = kDTree_1NN_feature_reprojection_colors(np.asarray(local_pcd.colors), local_pcd, np.asarray(merge.colors), merge,panoptic_labels, max_radius=0.2)\n",
    "\tlabeled_pcd = color_pcd_by_labels(labeled_pcd,labels.reshape(-1,))\n",
    "\tlocal_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\t#o3d.io.write_point_cloud(\"test.pcd\", local_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tlabeled_pcd.translate([0,120,0])\n",
    "\to3d.visualization.draw_geometries([local_pcd,labeled_pcd])\n",
    "\tunique_colors, labels = np.unique(colors, axis=0, return_inverse=True)\n",
    "\tunseen_mask = np.all(colors == [1,0,0], axis=1)\n",
    "\tlabels[unseen_mask] = -1\n",
    "\tstreet_mask = np.all(colors == [0,0,0], axis=1)\n",
    "\tlabels[street_mask] = 1\n",
    "\t\n",
    "\t#np.savez('output_files/7_tarl/ ' + str(i) + '.npz',labels=labels)\n",
    "\n",
    "\t\n",
    "\n",
    "\t#np.savez('output_files/7_original/' + str(i) + '.npz',ncut_labels=local_labels,kitti_labels=labels,pts=np.asarray(local_pcd.points),           \n",
    "\t#intensities=intensity,kitti_labels_semantic=semantic_labels,kitti_labels_instance=instance_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "with np.load('output_files/7_original/0.npz') as data:\n",
    "            xyz = data['pts'].astype(np.float)\n",
    "            labels = data['ncut_labels'].astype(np.int32)  \n",
    "            kitti_labels = data['kitti_labels']\n",
    "            intensity = data['intensities']\n",
    "            \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "pcd = color_pcd_by_labels(pcd,labels)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
