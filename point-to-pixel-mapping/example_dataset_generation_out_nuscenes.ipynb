{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[(0.267004, 0.004874, 0.329415), (0.277018, 0.050344, 0.375715), (0.282656, 0.100196, 0.42216), (0.28229, 0.145912, 0.46151), (0.276194, 0.190074, 0.493001), (0.265145, 0.232956, 0.516599), (0.252194, 0.269783, 0.531579), (0.235526, 0.309527, 0.542944), (0.21813, 0.347432, 0.550038), (0.201239, 0.38367, 0.554294), (0.185556, 0.41857, 0.556753), (0.171176, 0.45253, 0.557965), (0.159194, 0.482237, 0.558073), (0.14618, 0.515413, 0.556823), (0.133743, 0.548535, 0.553541), (0.123463, 0.581687, 0.547445), (0.119483, 0.614817, 0.537692), (0.128087, 0.647749, 0.523491), (0.150148, 0.676631, 0.506589), (0.19109, 0.708366, 0.482284), (0.24607, 0.73891, 0.452024), (0.311925, 0.767822, 0.415586), (0.386433, 0.794644, 0.372886), (0.468053, 0.818921, 0.323998), (0.545524, 0.838039, 0.275626), (0.636902, 0.856542, 0.21662), (0.730889, 0.871916, 0.156029), (0.82494, 0.88472, 0.106217), (0.916242, 0.896091, 0.100717), (0.993248, 0.906157, 0.143936)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset_utils import create_nuscenes_odometry_dataset\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on nuscenes sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "404 lidarseg,\n",
      "404 panoptic,\n",
      "Done loading in 0.350 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '/media/cedric/Datasets1/nuScenes_mini_v2/nuScenes'\n",
    "SEQUENCE_NUM = 4\n",
    "\n",
    "dist_threshold = 5 #moving object filter threshold \n",
    "\n",
    "dataset = create_nuscenes_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True, sam_folder_name=\"SAM_Underseg\", dinov2_folder_name=\"Dinov2\",dist_threshold=dist_threshold)\n",
    "\n",
    "ind_start = 0\n",
    "ind_end = len(dataset)\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False \n",
    "out_folder_ncuts = 'test_data/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "out_folder = 'pcd_preprocessed_nuscenes/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:05<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('{out_folder}all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'{out_folder}pcd_ground_minor.pcd') == True:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}nuscenes_labels_preprocessed.npz',\n",
    "                                                instance_nonground= labels['instance_nonground'],\n",
    "                                                instance_ground= labels['instance_ground'],\n",
    "                                                seg_ground = labels['seg_ground'],\n",
    "                                                seg_nonground= labels['seg_nonground']\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor.pcd')\n",
    "\n",
    "nuscenes_labels_orig = {}\n",
    "with np.load(f'{out_folder}nuscenes_labels_preprocessed.npz') as data :\n",
    "        nuscenes_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        nuscenes_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        nuscenes_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        nuscenes_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 shape (226153,)\n",
      "i 1 shape (158,)\n",
      "i 2 shape (521,)\n",
      "i 3 shape (136,)\n",
      "i 4 shape (118,)\n",
      "i 5 shape (5,)\n",
      "i 6 shape (111,)\n",
      "i 7 shape (5389,)\n",
      "i 8 shape (17,)\n",
      "i 9 shape (99,)\n",
      "i 10 shape (125,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points))\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                nuscenes_labels_orig['instance_nonground'].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2081.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1339.61it/s]\n"
     ]
    }
   ],
   "source": [
    "poses, positions, \\\n",
    "sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (104668, 3) to (5206, 3) points (non-ground)\n",
      "Downsampled from (127374, 3) to (6832, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, nuscenes_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=nuscenes_labels_orig)\n",
    "\n",
    "nuscenes_labels_inlier = copy.deepcopy(nuscenes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "\n",
    "\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "        #if labels[i] != (-1):\n",
    "        #    pcd_colored.colors[i] = np.array(colors[labels[i]]) / 255\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/ 255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Start of sequence 0\n",
      "5206 points in downsampled chunk (major)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m sequence \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(center_ids))[lower_limit:upper_limit]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39mif\u001b[39;00m NCUT_ground \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m : \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                 merged_chunk, file_name, pcd_chunk, pcd_chunk_ground, inliers, inliers_ground \u001b[39m=\u001b[39m ncuts_chunk(dataset, indices, pcd_nonground_chunks, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                         pcd_ground_chunks, pcd_nonground_chunks_major_downsampling, pcd_nonground_minor, T_pcd, center_positions, center_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                         positions, first_position, sampled_indices_global,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                         chunk_size\u001b[39m=\u001b[39;49mchunk_size, major_voxel_size\u001b[39m=\u001b[39;49mmajor_voxel_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                         alpha\u001b[39m=\u001b[39;49malpha, beta\u001b[39m=\u001b[39;49mbeta, gamma\u001b[39m=\u001b[39;49mgamma, theta\u001b[39m=\u001b[39;49mtheta,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                         proximity_threshold\u001b[39m=\u001b[39;49mproximity_threshold, ncuts_threshold\u001b[39m=\u001b[39;49mT, cams \u001b[39m=\u001b[39;49m cams, cam_ids \u001b[39m=\u001b[39;49m cam_ids, out_folder\u001b[39m=\u001b[39;49mout_folder_ncuts, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                         ground_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, sequence\u001b[39m=\u001b[39;49msequence, patchwise_indices\u001b[39m=\u001b[39;49mpatchwise_indices, adjacent_frames_cam\u001b[39m=\u001b[39;49m(\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m), adjacent_frames_tarl\u001b[39m=\u001b[39;49m(\u001b[39m5\u001b[39;49m,\u001b[39m5\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                 eval_nuscenes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_nuscenes.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m                 name \u001b[39m=\u001b[39m file_name\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/ncuts_utils.py:68\u001b[0m, in \u001b[0;36mncuts_chunk\u001b[0;34m(dataset, indices, pcd_nonground_chunks, pcd_ground_chunks, pcd_nonground_chunks_major_downsampling, pcd_nonground_minor, T_pcd, center_positions, center_ids, positions, first_position, sampled_indices_global, chunk_size, major_voxel_size, alpha, beta, gamma, theta, proximity_threshold, ncuts_threshold, cams, cam_ids, out_folder, ground_mode, sequence, patchwise_indices, adjacent_frames_cam, adjacent_frames_tarl)\u001b[0m\n\u001b[1;32m     65\u001b[0m         sam_features_major_list \u001b[39m=\u001b[39m image_based_features_per_patch(dataset, pcd_nonground_minor, chunk_indices, chunk_major, major_voxel_size, T_pcd, \n\u001b[1;32m     66\u001b[0m                                 cam_indices_global, cams, cam_ids\u001b[39m=\u001b[39mcam_ids, hpr_radius\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, sam\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dino\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, rm_perp\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39melif\u001b[39;00m gamma \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m beta:\n\u001b[0;32m---> 68\u001b[0m         point2dino_list \u001b[39m=\u001b[39m image_based_features_per_patch(dataset, pcd_nonground_minor, chunk_indices, chunk_major, major_voxel_size, T_pcd, \n\u001b[1;32m     69\u001b[0m                                         cam_indices_global, cams, cam_ids\u001b[39m=\u001b[39;49mcam_ids, hpr_radius\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, num_dino_features\u001b[39m=\u001b[39;49m\u001b[39m384\u001b[39;49m, sam\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dino\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, rm_perp\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n\u001b[1;32m     70\u001b[0m         dinov2_features_major_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     71\u001b[0m         \u001b[39mfor\u001b[39;00m point2dino \u001b[39min\u001b[39;00m point2dino_list:\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/chunk_generation.py:244\u001b[0m, in \u001b[0;36mimage_based_features_per_patch\u001b[0;34m(dataset, pcd, chunk_indices, chunk_nc, voxel_size, T_pcd2world, cam_indices, cams, cam_ids, hpr_radius, num_dino_features, hpr_masks, sam, dino, rm_perp)\u001b[0m\n\u001b[1;32m    242\u001b[0m     bound_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39masarray(pcd_camframe\u001b[39m.\u001b[39mpoints) \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mhpr_bounds, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39masarray(pcd_camframe\u001b[39m.\u001b[39mpoints) \u001b[39m<\u001b[39m hpr_bounds, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))[\u001b[39m0\u001b[39m]\n\u001b[1;32m    243\u001b[0m     pcd_camframe_hpr \u001b[39m=\u001b[39m get_subpcd(pcd_camframe, bound_indices)\n\u001b[0;32m--> 244\u001b[0m     visible_indices \u001b[39m=\u001b[39m hidden_point_removal_o3d(np\u001b[39m.\u001b[39;49masarray(pcd_camframe_hpr\u001b[39m.\u001b[39;49mpoints), camera\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m], radius_factor\u001b[39m=\u001b[39;49mhpr_radius)\n\u001b[1;32m    245\u001b[0m     visible_indices \u001b[39m=\u001b[39m bound_indices[visible_indices]\n\u001b[1;32m    246\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/hidden_points_removal.py:23\u001b[0m, in \u001b[0;36mhidden_point_removal_o3d\u001b[0;34m(points_np, camera, radius_factor)\u001b[0m\n\u001b[1;32m     20\u001b[0m diameter \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(np\u001b[39m.\u001b[39masarray(points_o3d\u001b[39m.\u001b[39mget_max_bound()) \u001b[39m-\u001b[39m \n\u001b[1;32m     21\u001b[0m                           np\u001b[39m.\u001b[39masarray(points_o3d\u001b[39m.\u001b[39mget_min_bound()))\n\u001b[1;32m     22\u001b[0m radius \u001b[39m=\u001b[39m diameter \u001b[39m*\u001b[39m radius_factor\n\u001b[0;32m---> 23\u001b[0m _, pt_map \u001b[39m=\u001b[39m points_o3d\u001b[39m.\u001b[39;49mhidden_point_removal(camera, radius)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m pt_map\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = 0.0\n",
    "theta = 0.0\n",
    "beta = 0.0\n",
    "gamma = 0.1\n",
    "proximity_threshold = 1.0\n",
    "colors = generate_random_colors_map(600)\n",
    "T = 0.05\n",
    "cams = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\"]\n",
    "cam_ids = [0]\n",
    "\n",
    "#out_dbscan = 'out_dbscan/'\n",
    "#if os.path.exists(out_dbscan) == True : \n",
    "#        shutil.rmtree(out_dbscan)\n",
    "        \n",
    "#os.makedirs(out_dbscan)\n",
    "\n",
    "out_nuscenes = 'out_nuscenes/'\n",
    "if os.path.exists(out_nuscenes) == True : \n",
    "        shutil.rmtree(out_nuscenes)\n",
    "\n",
    "os.makedirs(out_nuscenes)\n",
    "        \n",
    "out_nuscenes_instance = 'out_nuscenes_instance/'\n",
    "if os.path.exists(out_nuscenes_instance) == True : \n",
    "        shutil.rmtree(out_nuscenes_instance)\n",
    "os.makedirs(out_nuscenes_instance)\n",
    "\n",
    "lower_limit = 0 ##use this for experiments to run limit chunks numberss\n",
    "upper_limit = 5 ##use this for experiments to run limit chunks numberss\n",
    "\n",
    "instances = np.hstack((nuscenes_labels_orig['instance_nonground'],nuscenes_labels_orig['instance_ground']))\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "print(len(center_ids))\n",
    "for sequence in range(len(center_ids))[lower_limit:upper_limit]:\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                merged_chunk, file_name, pcd_chunk, pcd_chunk_ground, inliers, inliers_ground = ncuts_chunk(dataset, indices, pcd_nonground_chunks, \n",
    "                        pcd_ground_chunks, pcd_nonground_chunks_major_downsampling, pcd_nonground_minor, T_pcd, center_positions, center_ids,\n",
    "                        positions, first_position, sampled_indices_global,\n",
    "                        chunk_size=chunk_size, major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha, beta=beta, gamma=gamma, theta=theta,\n",
    "                        proximity_threshold=proximity_threshold, ncuts_threshold=T, cams = cams, cam_ids = cam_ids, out_folder=out_folder_ncuts, \n",
    "                        ground_mode=False, sequence=sequence, patchwise_indices=patchwise_indices, adjacent_frames_cam=(4,5), adjacent_frames_tarl=(5,5))\n",
    "\n",
    "                eval_nuscenes = True\n",
    "\n",
    "                name = file_name.split('/')[-1]\n",
    "                o3d.io.write_point_cloud(file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "                if eval_nuscenes == True :\n",
    "                        seg_ground = nuscenes_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                        inst_ground = nuscenes_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                        nuscenes_chunk_instance = color_pcd_by_labels(pcd_chunk,nuscenes_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                        nuscenes_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                        o3d.io.write_point_cloud(out_nuscenes_instance + name, nuscenes_chunk_instance + nuscenes_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "                \n",
    "        else : \n",
    "                obstacle_out,file_name = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "                \n",
    "                \n",
    "                ground_out,file_name = ncuts_chunk(dataset,indices_ground,pcd_ground_chunks,None,\n",
    "                        pcd_ground_chunks_major_downsampling,\n",
    "                        pcd_ground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "\n",
    "                o3d.io.write_point_cloud(file_name, obstacle_out + ground_out, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "                print(\"Pointcloud written to file\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000011.pcd']\n",
      "['000011.pcd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out_dbscan = 'out_dbscan/'\n",
    "out_nuscenes = 'out_nuscenes/'\n",
    "out_nuscenes_instance = 'out_nuscenes_instance/'\n",
    "\n",
    "\n",
    "point_clouds = get_merge_pcds(out_folder_ncuts)\n",
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "\n",
    "\n",
    "#Merge parts of map\n",
    "if eval_nuscenes == True : \n",
    "    point_clouds_nuscenes_instances = get_merge_pcds(out_nuscenes_instance)\n",
    "    merge_nuscenes_instance = merge_unite_gt(point_clouds_nuscenes_instances)\n",
    "    o3d.io.write_point_cloud(out_folder + \"merge_part_nuscenes_instance.pcd\", merge_nuscenes_instance, write_ascii=False, compressed=False, print_progress=False)\n",
    "else:\n",
    "    merge_nuscenes_instance = o3d.io.read_point_cloud('/Users/laurenzheidrich/Documents/Studium/Hiwi_TUM.nosync/Programming/unsup_3d_instances/point-to-pixel-mapping/pcd_preprocessed_nuscenes/merge_part_nuscenes_instance.pcd')\n",
    "\n",
    "\n",
    "\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for file ncuts\n",
      "{'panoptic': 0.1954022988505747, 'precision': 0.5, 'recall': 0.25, 'fScore': 0.3333333333333333, 'usr': 0.0, 'osr': 0.0, 'noise': 0.5, 'missed': 0.75, 'mean': 0.5862068965517241}\n",
      "lstq value :  0.16390875421949833\n",
      "Average Precision @ 0.25 0.5\n",
      "Average Precision @ 0.5 0.0625\n",
      "Average Precision @ 0.55 0.0625\n",
      "Average Precision @ 0.7 0.0\n",
      "Average Precision @ 0.75 0.0Average Precision @ 0.6\n",
      " 0.0\n",
      "Average Precision @ 0.8 Average Precision @ 0.850.0 \n",
      "0.0\n",
      "Average Precision @ 0.9 0.0\n",
      "Average Precision @ 0.65Average Precision @ 0.95  0.0\n",
      "0.0\n",
      "AP @ 0.25 50.0\n",
      "AP @ 0.5 6.25\n",
      "AP @ [0.5:0.95] 1.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "#unique_colors, labels_dbscan = np.unique(np.asarray(merge_dbscan.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_nuscenes = np.unique(np.asarray(merge_nuscenes_instance.colors),axis=0, return_inverse=True)\n",
    "\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "def remove_semantics(labels,preds):\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "        return new_ncuts_labels\n",
    "\n",
    "new_ncuts_labels = remove_semantics(labels_nuscenes,labels_ncuts)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_ncuts.min_points = 50\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,new_ncuts_labels,labels_nuscenes)\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "o3d.visualization.draw_geometries([merge_vis])\n",
    "o3d.visualization.draw_geometries([merge_nuscenes_instance])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
