{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "\n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    sam_folder_name=\"sam_pred_medium\",\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "            KittiGTMovingObjectFilter(\n",
    "                os.path.join(\n",
    "                    DATASET_PATH,\n",
    "                    \"sequences\",\n",
    "                    \"%.2d\" % SEQUENCE_NUM,\n",
    "                    \"labels\",\n",
    "                )\n",
    "            ),\n",
    "            RangeFilter(3, 25),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n",
      "num points:  13060577 in non-ground pcd\n",
      "num points:  2520058 in non-ground pcd with downsampling of 0.05\n"
     ]
    }
   ],
   "source": [
    "ind_start = 0\n",
    "ind_end = 200\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "\n",
    "pcd_ground, pcd_nonground, all_poses, T_pcd = aggregate_pointcloud(dataset, ind_start, ind_end, ground_segmentation=\"patchwork\", icp=True)\n",
    "first_position = T_pcd[:3,3]\n",
    "\n",
    "pcd_ground_minor = pcd_ground.voxel_down_sample(voxel_size=minor_voxel_size)\n",
    "pcd_nonground_minor = pcd_nonground.voxel_down_sample(voxel_size=minor_voxel_size)\n",
    "\n",
    "num_points = np.asarray(pcd_nonground.points).shape[0]\n",
    "print(\"num points: \", num_points, \"in non-ground pcd\")\n",
    "\n",
    "num_points_minor = np.asarray(pcd_nonground_minor.points).shape[0]\n",
    "print(\"num points: \", num_points_minor, \"in non-ground pcd with downsampling of\", minor_voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positions = []\n",
    "for p in all_poses:\n",
    "    all_positions.append(tuple(p[:3,3]))\n",
    "\n",
    "sampled_indices_local = list(subsample_positions(all_positions, voxel_size=1))\n",
    "sampled_indices_global = list(subsample_positions(all_positions, voxel_size=1) + ind_start)\n",
    "\n",
    "poses = np.array(all_poses)[sampled_indices_local]\n",
    "positions = np.array(all_positions)[sampled_indices_local]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (442779, 3) to (7121, 3) points (non-ground)\n",
      "Downsampled from (207133, 3) to (4518, 3) points (ground)\n",
      "Downsampled from (386957, 3) to (6429, 3) points (non-ground)\n",
      "Downsampled from (224163, 3) to (4362, 3) points (ground)\n",
      "Downsampled from (437386, 3) to (7591, 3) points (non-ground)\n",
      "Downsampled from (252908, 3) to (6083, 3) points (ground)\n",
      "Downsampled from (375263, 3) to (5949, 3) points (non-ground)\n",
      "Downsampled from (232640, 3) to (4455, 3) points (ground)\n",
      "Downsampled from (324121, 3) to (6411, 3) points (non-ground)\n",
      "Downsampled from (176602, 3) to (3706, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "\n",
    "pcd_nonground_chunks, indices, center_positions, center_ids, chunk_bounds = chunks_from_pointcloud(pcd_nonground_minor, T_pcd, positions, first_position, sampled_indices_global, chunk_size, overlap)\n",
    "pcd_ground_chunks, _, _, _, _ = chunks_from_pointcloud(pcd_ground_minor, T_pcd, positions, first_position, sampled_indices_global, chunk_size, overlap)\n",
    "\n",
    "pcd_nonground_chunks_major_downsampling = []\n",
    "pcd_ground_chunks_major_downsampling = []\n",
    "\n",
    "for nonground, ground in zip(pcd_nonground_chunks, pcd_ground_chunks):\n",
    "    pcd_nonground_chunks_major_downsampling.append(nonground.voxel_down_sample(voxel_size=major_voxel_size))\n",
    "    pcd_ground_chunks_major_downsampling.append(ground.voxel_down_sample(voxel_size=major_voxel_size))\n",
    "    print(\"Downsampled from\", np.asarray(nonground.points).shape, \"to\", np.asarray(pcd_nonground_chunks_major_downsampling[-1].points).shape, \"points (non-ground)\")\n",
    "    print(\"Downsampled from\", np.asarray(ground.points).shape, \"to\", np.asarray(pcd_ground_chunks_major_downsampling[-1].points).shape, \"points (ground)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of sequence  0\n",
      "7121 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 83 cut regions\n",
      "Ratio of points in top 3 groups: 0.22918129476197163\n",
      "Pointcloud written to file\n",
      "Start of sequence  1\n",
      "6429 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 54 cut regions\n",
      "Ratio of points in top 3 groups: 0.2914916783325556\n",
      "Pointcloud written to file\n",
      "Start of sequence  2\n",
      "7591 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 51 cut regions\n",
      "Ratio of points in top 3 groups: 0.25727835594783294\n",
      "Pointcloud written to file\n",
      "Start of sequence  3\n",
      "5949 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 44 cut regions\n",
      "Ratio of points in top 3 groups: 0.2908051773407295\n",
      "Pointcloud written to file\n",
      "Start of sequence  4\n",
      "6411 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 57 cut regions\n",
      "Ratio of points in top 3 groups: 0.22835751052877867\n",
      "Pointcloud written to file\n"
     ]
    }
   ],
   "source": [
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "\n",
    "for sequence in range(len(center_ids)):\n",
    "\n",
    "    print(\"Start of sequence \", sequence)\n",
    "\n",
    "    first_id = patchwise_indices[sequence][0]\n",
    "    center_id = center_ids[sequence]\n",
    "    center_position = center_positions[sequence]\n",
    "    chunk_indices = indices[sequence]\n",
    "\n",
    "    cam_indices_global, hpr_mask_indices = get_indices_feature_reprojection(sampled_indices_global, first_id, adjacent_frames=(16,13)) \n",
    "    \n",
    "    pcd_chunk = pcd_nonground_chunks[sequence]\n",
    "    pcd_ground_chunk = pcd_ground_chunks[sequence]\n",
    "    chunk_major = pcd_nonground_chunks_major_downsampling[sequence]\n",
    "\n",
    "    points_major = np.asarray(chunk_major.points)\n",
    "    num_points_major = points_major.shape[0]   \n",
    "\n",
    "    print(num_points_major, \"points in downsampled chunk (major)\")\n",
    "\n",
    "    #tarl_features = tarl_features_per_patch(dataset, chunk_major, center_id, T_pcd, center_position, sampled_indices_global, chunk_size, major_voxel_size)\n",
    "\n",
    "    cams = [\"cam2\", \"cam3\"]\n",
    "\n",
    "    sam_features_minor, chunk_minor = image_based_features_per_patch(dataset, pcd_nonground_minor, chunk_indices, T_pcd, cam_indices_global, cams, cam_id=0, hpr_radius=2000, dino=False, rm_perp=0.0)\n",
    "    #point2dino\n",
    "    #dinov2_features_minor = dinov2_mean(point2dino)\n",
    "    \n",
    "    sam_features_major = -1 * np.ones((num_points_major, sam_features_minor.shape[1]))\n",
    "    #dinov2_features_major = np.zeros((num_points_major, dinov2_features_minor.shape[1])) \n",
    "\n",
    "    sam_features_major = kDTree_1NN_feature_reprojection(sam_features_major, chunk_major, sam_features_minor, chunk_minor)\n",
    "    #dinov2_features_major = kDTree_1NN_feature_reprojection(dinov2_features_major, chunk_major, dinov2_features_minor, chunk_minor)\n",
    "\n",
    "    zero_rows = np.sum(~np.array(sam_features_major).any(1))\n",
    "    ratio = zero_rows / num_points_major\n",
    "\n",
    "    if ratio > 0.3:\n",
    "        print(\"The ratio of points without image-based features is\", ratio, \". Skipping this chunk.\")\n",
    "        continue\n",
    "\n",
    "    spatial_distance = cdist(points_major, points_major)\n",
    "    #dinov2_distance = cdist(dinov2_features_major, dinov2_features_major)\n",
    "    #tarl_distance = cdist(tarl_features, tarl_features)\n",
    "\n",
    "    proximity_threshold = 1 # meters that points can be apart from each other and still be considered neighbors\n",
    "    alpha = 0.0 # weight of the spatial proximity term \n",
    "    beta = 4.0 # weight of the label similarity term\n",
    "    gamma = 0.0 # weight of the dinov2 feature similarity term\n",
    "    theta = 0.0 # weight of the tarl feature similarity term\n",
    "\n",
    "    sam_edge_weights, mask = sam_label_distance(sam_features_major, spatial_distance, proximity_threshold, beta)\n",
    "    #spatial_edge_weights = mask * np.exp(-alpha * spatial_distance)\n",
    "    #dinov2_edge_weights = mask * np.exp(-gamma * dinov2_distance)\n",
    "    #tarl_edge_weights = mask * np.exp(-theta * tarl_distance)\n",
    "\n",
    "    A = sam_edge_weights #spatial_edge_weights * sam_edge_weights * dinov2_edge_weights * tarl_edge_weights\n",
    "    print(\"Adjacency Matrix built\")\n",
    "\n",
    "    # Remove isolated points\n",
    "    chunk_major, A = remove_isolated_points(chunk_major, A)\n",
    "    print(num_points_major - np.asarray(chunk_major.points).shape[0], \"isolated points removed\")\n",
    "    num_points_major = np.asarray(chunk_major.points).shape[0]\n",
    "\n",
    "    print(\"Start of normalized Cuts\")\n",
    "    grouped_labels = normalized_cut(A, np.arange(num_points_major), T = 0.08)\n",
    "    num_groups = len(grouped_labels)\n",
    "    print(\"There are\", num_groups, \"cut regions\")\n",
    "\n",
    "    sorted_groups = sorted(grouped_labels, key=lambda x: len(x))\n",
    "    num_points_top3 = np.sum([len(g) for g in sorted_groups[-3:]])\n",
    "    top3_ratio = num_points_top3 / num_points_major\n",
    "    print(\"Ratio of points in top 3 groups:\", top3_ratio)\n",
    "\n",
    "    random_colors = generate_random_colors(600)\n",
    "\n",
    "    pcd_color = np.zeros((num_points_major, 3))\n",
    "\n",
    "    for i, s in enumerate(grouped_labels):\n",
    "        for j in s:\n",
    "            pcd_color[j] = np.array(random_colors[i]) / 255\n",
    "\n",
    "    pcd_chunk.paint_uniform_color([0, 0, 0])\n",
    "    colors = kDTree_1NN_feature_reprojection(np.asarray(pcd_chunk.colors), pcd_chunk, pcd_color, chunk_major)\n",
    "    pcd_chunk.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    inliers = get_statistical_inlier_indices(pcd_ground_chunk)\n",
    "    ground_inliers = get_subpcd(pcd_ground_chunk, inliers)\n",
    "    mean_hight = np.mean(np.asarray(ground_inliers.points)[:,2])\n",
    "    cut_hight = get_subpcd(ground_inliers, np.where(np.asarray(ground_inliers.points)[:,2] < (mean_hight + 0.2))[0])\n",
    "    cut_hight.paint_uniform_color([0, 0, 0])\n",
    "\n",
    "    merged_chunk = pcd_chunk + cut_hight\n",
    "\n",
    "    index_file = str(center_id).zfill(6) + '.pcd'\n",
    "    file = os.path.join(\"test_data\", index_file)\n",
    "\n",
    "    o3d.io.write_point_cloud(file, merged_chunk, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "    print(\"Pointcloud written to file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the chunks to one large Map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000117.pcd', '000158.pcd', '000168.pcd']\n"
     ]
    }
   ],
   "source": [
    "point_clouds = []\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(\"test_data\")\n",
    "files.sort()\n",
    "\n",
    "# Filter files with a .pcd extension\n",
    "pcd_files = [file for file in files if file.endswith(\".pcd\")][2:5]\n",
    "print(pcd_files)\n",
    "# Load each point cloud and append to the list\n",
    "for pcd_file in pcd_files:\n",
    "    file_path = os.path.join(\"test_data\", pcd_file)\n",
    "    point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "    point_clouds.append(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "o3d.io.write_point_cloud(\"test_data/merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kDTree_1NN_feature_reprojection(features_to, pcd_to, features_from, pcd_from, labels=None,max_radius=None, no_feature_label=[1,0,0]):\n",
    "    '''\n",
    "    Args:\n",
    "        pcd_from: point cloud to be projected\n",
    "        pcd_to: point cloud to be projected to\n",
    "        search_method: search method (\"radius\", \"knn\")\n",
    "        search_param: search parameter (radius or k)\n",
    "    Returns:\n",
    "        features_to: features projected on pcd_to\n",
    "    '''\n",
    "    from_tree = o3d.geometry.KDTreeFlann(pcd_from)\n",
    "\n",
    "    for i, point in enumerate(np.asarray(pcd_to.points)):\n",
    "\n",
    "        [_, idx, _] = from_tree.search_knn_vector_3d(point, 1)\n",
    "        if max_radius is not None:\n",
    "            if np.linalg.norm(point - np.asarray(pcd_from.points)[idx[0]]) > max_radius:\n",
    "                features_to[i,:] = no_feature_label\n",
    "                if labels is not None : \n",
    "                    labels[i] = -1\n",
    "            else:\n",
    "                features_to[i,:] = features_from[idx[0]]\n",
    "        else:\n",
    "            features_to[i,:] = features_from[idx[0]]\n",
    "    if labels is not None : \n",
    "        return features_to,labels\n",
    "    else : \n",
    "        return features_to, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def color_pcd_by_labels(pcd, labels):\n",
    "    \n",
    "    colors = generate_random_colors(500)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(np.zeros(np.asarray(pcd.points).shape))\n",
    "    \n",
    "    unique_labels = list(np.unique(labels)) \n",
    "    for i in range(len(pcd_colored.points)):\n",
    "        if labels[i] != (-1):\n",
    "            color = colors[unique_labels.index(labels[i])]\n",
    "            pcd_colored.colors[i] = np.array(color) / 255\n",
    "\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28611/14227775.py:14: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  labeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n"
     ]
    }
   ],
   "source": [
    "from open3d.pipelines import registration\n",
    "\n",
    "merge = o3d.io.read_point_cloud(\"test_data/merge_part.pcd\")\n",
    "merge.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\n",
    "i = 150\n",
    "local_pcd = o3d.geometry.PointCloud()\n",
    "local_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\n",
    "\n",
    "## label visualization \n",
    "labeled_pcd = o3d.geometry.PointCloud()\n",
    "labeled_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "labeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n",
    "panoptic_labels = dataset[i].panoptic_labels # semantics + panoptics combined \n",
    "semantic_labels = dataset[i].semantic_labels\n",
    "instance_labels = dataset[i].instance_labels\n",
    "\n",
    "\n",
    "transform = dataset.get_pose(i)\n",
    "\n",
    "\n",
    "\n",
    "local_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "reg_p2l = registration.registration_icp(local_pcd, merge, 0.9, transform, registration.TransformationEstimationPointToPlane(), registration.ICPConvergenceCriteria(max_iteration=1000))\n",
    "transform = reg_p2l.transformation\n",
    "local_pcd.transform(transform)\n",
    "\n",
    "local_pcd.normals = o3d.utility.Vector3dVector([])\n",
    "\n",
    "local_pcd.paint_uniform_color([0, 0, 0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors, labels = kDTree_1NN_feature_reprojection(np.asarray(local_pcd.colors), local_pcd, np.asarray(merge.colors), merge,panoptic_labels, max_radius=0.2)\n",
    "labeled_pcd = color_pcd_by_labels(labeled_pcd,labels.reshape(-1,))\n",
    "local_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "o3d.io.write_point_cloud(\"test_data/test.pcd\", local_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "labeled_pcd.translate([0,120,0])\n",
    "o3d.visualization.draw_geometries([local_pcd,labeled_pcd])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
