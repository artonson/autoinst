{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist\n",
    "import sklearn\n",
    "from sklearn.cluster import Birch, KMeans, MeanShift, DBSCAN, SpectralClustering\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from normalized_cut import normalized_cut\n",
    "\n",
    "from point_cloud_utils import get_pcd, transform_pcd\n",
    "from aggregate_pointcloud import aggregate_pointcloud, aggregate_features\n",
    "from reproject_merged_pointcloud import reproject_points_to_label, merge_associations, merge_features\n",
    "from visualization_utils import generate_random_colors\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/laurenzheidrich/Downloads/','fused_dataset')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "            KittiGTMovingObjectFilter(\n",
    "                os.path.join(\n",
    "                    DATASET_PATH,\n",
    "                    \"sequences\",\n",
    "                    \"%.2d\" % SEQUENCE_NUM,\n",
    "                    \"labels\",\n",
    "                )\n",
    "            ),\n",
    "            RangeFilter(3, 25),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the point cloud and the left and right image of the stereo camera. If labels for those images are available they can be read in, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 0\n",
    "ind_end = 200\n",
    "voxel_size = 0.35\n",
    "\n",
    "pcd, T_pcd, all_poses = aggregate_pointcloud(dataset, ind_start, ind_end, clip_to_imageframe=False, return_poses=True)\n",
    "first_position = all_poses[0][:3,3]\n",
    "\n",
    "num_points = np.asarray(pcd.points).shape[0]\n",
    "print(\"num points: \", num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positions = []\n",
    "for p in all_poses:\n",
    "    all_positions.append(tuple(p[:3,3]))\n",
    "\n",
    "sampled_indices_local = list(subsample_positions(all_positions, voxel_size=1))\n",
    "sampled_indices_global = list(subsample_positions(all_positions, voxel_size=1) + ind_start)\n",
    "\n",
    "poses = np.array(all_poses)[sampled_indices_local]\n",
    "positions = np.array(all_positions)[sampled_indices_local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = np.array([10, 14, 10]) #meters\n",
    "overlap = 3 #meters\n",
    "\n",
    "pcd_chunks, center_positions, center_ids = chunks_from_pointcloud(pcd, T_pcd, positions, poses, first_position, \n",
    "                                                                  sampled_indices_global, chunk_size, overlap)\n",
    "\n",
    "pcd_chunks_downsampled = []\n",
    "\n",
    "voxel_size = 0.35\n",
    "for chunk in pcd_chunks:\n",
    "    pcd_downsample = chunk.voxel_down_sample(voxel_size=voxel_size)\n",
    "    pcd_chunks_downsampled.append(pcd_downsample)\n",
    "    print(\"Downsampled from\", np.asarray(chunk.points).shape, \"to\", np.asarray(pcd_downsample.points).shape, \"points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in range(len(center_ids)):\n",
    "\n",
    "    print(\"Start of sequence \", sequence)\n",
    "\n",
    "    first_id = patchwise_indices[sequence][0]\n",
    "    center_id = center_ids[sequence]\n",
    "    center_position = center_positions[sequence]\n",
    "\n",
    "    pcd_chunk = pcd_chunks[sequence]\n",
    "    downsampled_chunk = pcd_chunks_downsampled[sequence]\n",
    "\n",
    "    points = np.asarray(downsampled_chunk.points)\n",
    "    num_points = np.asarray(downsampled_chunk.points).shape[0]    \n",
    "\n",
    "    print(num_points, \"points in downsampled chunk\")\n",
    "\n",
    "    tarl_features = tarl_features_per_patch(dataset, downsampled_chunk, center_id, T_pcd, center_position,\n",
    "                                            sampled_indices_global, chunk_size, voxel_size)\n",
    "\n",
    "    cams = [\"cam2\", \"cam3\"]\n",
    "    sam_feature_reprojections, dinov2_feature_reprojections = image_based_features_per_patch(dataset, downsampled_chunk, T_pcd, sampled_indices_global, first_id, cams, cam_id=0)\n",
    "\n",
    "    sam_features = merge_associations(sam_feature_reprojections, len(downsampled_chunk.points))\n",
    "    dinov2_features = merge_features(dinov2_feature_reprojections, len(downsampled_chunk.points))\n",
    "\n",
    "    spatial_distance = cdist(points, points)\n",
    "    dinov2_distance = cdist(dinov2_features, dinov2_features)\n",
    "    tarl_distance = cdist(tarl_features, tarl_features)\n",
    "\n",
    "    proximity_threshold = 2 # meters that points can be apart from each other and still be considered neighbors\n",
    "    alpha = 2.3 # weight of the spatial proximity term  2.3\n",
    "    beta = 0.9 # weight of the label similarity term 1.1\n",
    "    gamma = 0.5 #0.3 # weight of the dinov2 feature similarity term 1.5\n",
    "    theta = 1.4 # weight of the tarl feature similarity term\n",
    "\n",
    "    sam_edge_weights, mask = sam_label_distance(sam_features, spatial_distance, proximity_threshold, num_points, beta)\n",
    "    spatial_edge_weights = np.exp(-alpha * (mask * spatial_distance))\n",
    "    dinov2_edge_weights = np.exp(-gamma * (mask * dinov2_distance))\n",
    "    tarl_edge_weights = np.exp(-theta * (mask * tarl_distance))\n",
    "\n",
    "    A = spatial_edge_weights * sam_edge_weights * dinov2_edge_weights * tarl_edge_weights\n",
    "    print(\"Adjacency Matrix built\")\n",
    "\n",
    "    # Remove isolated points\n",
    "    isolated_mask = ~np.all(A == 0, axis=1)\n",
    "    A = A[isolated_mask][:, isolated_mask]\n",
    "    downsampled_chunk = downsampled_chunk.select_by_index(np.where(isolated_mask == True)[0])\n",
    "    print(num_points - np.asarray(downsampled_chunk.points).shape[0], \"isolated points removed\")\n",
    "    num_points = np.asarray(downsampled_chunk.points).shape[0]\n",
    "\n",
    "    print(\"Start of normalized Cuts\")\n",
    "    grouped_labels = normalized_cut(A, np.arange(num_points), T = 0.00001)\n",
    "\n",
    "    print(\"There are\", len(grouped_labels), \"cut regions\")\n",
    "\n",
    "    random_colors = generate_random_colors(600)\n",
    "\n",
    "    pcd_color = np.zeros((num_points, 3))\n",
    "\n",
    "    for i, s in enumerate(grouped_labels):\n",
    "        for j in s:\n",
    "            pcd_color[j] = np.array(random_colors[i]) / 255\n",
    "\n",
    "    downsampled_chunk.colors = o3d.utility.Vector3dVector(pcd_color)\n",
    "\n",
    "    pcd_chunk.paint_uniform_color([0, 0, 0])\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(downsampled_chunk)\n",
    "\n",
    "    i=0\n",
    "    for point in np.asarray(pcd_chunk.points):\n",
    "        [_, idx, _] = pcd_tree.search_knn_vector_3d(point, 1)\n",
    "        np.asarray(pcd_chunk.colors)[i,:] = np.asarray(downsampled_chunk.colors)[idx[0], :]\n",
    "        i+=1\n",
    "\n",
    "    index_file = str(center_id).zfill(6) + '.pcd'\n",
    "    file = os.path.join(\"test_data\", index_file)\n",
    "    o3d.io.write_point_cloud(file, pcd_chunk, write_ascii=False, compressed=False, print_progress=False)\n",
    "    \n",
    "    print(\"Pointcloud written to file\")\n",
    "    print(\"End of sequence \", sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
