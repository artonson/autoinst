{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_chunks_unite_instances2, remove_semantics, get_merge_pcds, merge_unite_gt\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import shutil\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None,semantics=False):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 and semantics == False : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "    if semantics : \n",
    "        pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    else : \n",
    "        pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/255)\n",
    "    return pcd_colored\n",
    "    \n",
    "def divide_indices_into_chunks(max_index, chunk_size=1000):\n",
    "    chunks = []\n",
    "    for start in range(0, max_index, chunk_size):\n",
    "        end = min(start + chunk_size, max_index)\n",
    "        chunks.append((start, end))\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets2/semantic_kitti/')\n",
    "end_inds = {0:4541,1:1100,2:4661,3:800,4:271,5:2761,6:1101,7:1100,8:4071,9:1591,10:1201}\n",
    "SEQUENCE_NUM = 0\n",
    "old = False  \n",
    "\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = 'pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_folder_ncuts) == False :\n",
    "        os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "\n",
    "\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "        \n",
    "if os.path.exists(out_kitti_instance) == False : \n",
    "        os.makedirs(out_kitti_instance)\n",
    " \n",
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.1\n",
    "proximity_threshold = 1.0\n",
    "tarl_norm = False\n",
    "ncuts_threshold = 0.005\n",
    "        \n",
    "out_name = 'tarl_only' + str(SEQUENCE_NUM) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur idx 4\n",
      "ind start 4000\n",
      "ind end 4661\n",
      "PointCloud with 9588558 points.\n",
      "chunk and downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:29<00:00, 21.65it/s]\n",
      "100%|██████████| 631/631 [00:21<00:00, 29.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (295054, 3) to (5556, 3) points (non-ground)\n",
      "Downsampled from (276045, 3) to (4905, 3) points (ground)\n",
      "Downsampled from (366729, 3) to (6955, 3) points (non-ground)\n",
      "Downsampled from (331133, 3) to (6079, 3) points (ground)\n",
      "Downsampled from (360301, 3) to (6248, 3) points (non-ground)\n",
      "Downsampled from (406894, 3) to (6523, 3) points (ground)\n",
      "Downsampled from (476949, 3) to (7853, 3) points (non-ground)\n",
      "Downsampled from (340785, 3) to (5662, 3) points (ground)\n",
      "Downsampled from (354459, 3) to (6041, 3) points (non-ground)\n",
      "Downsampled from (329276, 3) to (5788, 3) points (ground)\n",
      "Downsampled from (403509, 3) to (6075, 3) points (non-ground)\n",
      "Downsampled from (312004, 3) to (5091, 3) points (ground)\n",
      "Downsampled from (482147, 3) to (6593, 3) points (non-ground)\n",
      "Downsampled from (359209, 3) to (5257, 3) points (ground)\n",
      "Downsampled from (270854, 3) to (3689, 3) points (non-ground)\n",
      "Downsampled from (397530, 3) to (6036, 3) points (ground)\n",
      "Downsampled from (342510, 3) to (5104, 3) points (non-ground)\n",
      "Downsampled from (267538, 3) to (4686, 3) points (ground)\n",
      "Downsampled from (334411, 3) to (5876, 3) points (non-ground)\n",
      "Downsampled from (256048, 3) to (4487, 3) points (ground)\n",
      "Downsampled from (343189, 3) to (5065, 3) points (non-ground)\n",
      "Downsampled from (239645, 3) to (4265, 3) points (ground)\n",
      "Downsampled from (233645, 3) to (4047, 3) points (non-ground)\n",
      "Downsampled from (333370, 3) to (6038, 3) points (ground)\n",
      "Downsampled from (322792, 3) to (4233, 3) points (non-ground)\n",
      "Downsampled from (285531, 3) to (4818, 3) points (ground)\n",
      "Downsampled from (375041, 3) to (5136, 3) points (non-ground)\n",
      "Downsampled from (300455, 3) to (4736, 3) points (ground)\n",
      "Downsampled from (384724, 3) to (5408, 3) points (non-ground)\n",
      "Downsampled from (299215, 3) to (4619, 3) points (ground)\n",
      "Downsampled from (286981, 3) to (4427, 3) points (non-ground)\n",
      "Downsampled from (272217, 3) to (4384, 3) points (ground)\n",
      "Downsampled from (237565, 3) to (3937, 3) points (non-ground)\n",
      "Downsampled from (269465, 3) to (4371, 3) points (ground)\n",
      "Downsampled from (122917, 3) to (1871, 3) points (non-ground)\n",
      "Downsampled from (295821, 3) to (4665, 3) points (ground)\n",
      "Downsampled from (298573, 3) to (6011, 3) points (non-ground)\n",
      "Downsampled from (252394, 3) to (4857, 3) points (ground)\n",
      "Downsampled from (415890, 3) to (6552, 3) points (non-ground)\n",
      "Downsampled from (226945, 3) to (4168, 3) points (ground)\n",
      "Downsampled from (477024, 3) to (6313, 3) points (non-ground)\n",
      "Downsampled from (248146, 3) to (4498, 3) points (ground)\n",
      "Downsampled from (471431, 3) to (6073, 3) points (non-ground)\n",
      "Downsampled from (282420, 3) to (4870, 3) points (ground)\n",
      "Downsampled from (367148, 3) to (4953, 3) points (non-ground)\n",
      "Downsampled from (235418, 3) to (4148, 3) points (ground)\n",
      "Downsampled from (254404, 3) to (3864, 3) points (non-ground)\n",
      "Downsampled from (248296, 3) to (4242, 3) points (ground)\n",
      "Downsampled from (367623, 3) to (4446, 3) points (non-ground)\n",
      "Downsampled from (265557, 3) to (4081, 3) points (ground)\n",
      "Downsampled from (304649, 3) to (3678, 3) points (non-ground)\n",
      "Downsampled from (249695, 3) to (3831, 3) points (ground)\n",
      "Downsampled from (372264, 3) to (4682, 3) points (non-ground)\n",
      "Downsampled from (258713, 3) to (4060, 3) points (ground)\n",
      "Downsampled from (457652, 3) to (5412, 3) points (non-ground)\n",
      "Downsampled from (251023, 3) to (4018, 3) points (ground)\n",
      "Downsampled from (431401, 3) to (5670, 3) points (non-ground)\n",
      "Downsampled from (289714, 3) to (4646, 3) points (ground)\n",
      "Downsampled from (192132, 3) to (4099, 3) points (non-ground)\n",
      "Downsampled from (441533, 3) to (7432, 3) points (ground)\n",
      "Downsampled from (274277, 3) to (4327, 3) points (non-ground)\n",
      "Downsampled from (332291, 3) to (5568, 3) points (ground)\n",
      "Downsampled from (228999, 3) to (4051, 3) points (non-ground)\n",
      "Downsampled from (299665, 3) to (5107, 3) points (ground)\n",
      "Downsampled from (251232, 3) to (4471, 3) points (non-ground)\n",
      "Downsampled from (307689, 3) to (5085, 3) points (ground)\n",
      "Downsampled from (341310, 3) to (4886, 3) points (non-ground)\n",
      "Downsampled from (241626, 3) to (4212, 3) points (ground)\n",
      "total sequence number 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center 4595\n",
      "Start of sequence 30\n",
      "4327 points in downsampled chunk (major)\n",
      "label shape (376, 1241)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  653.1563885211945  s\n",
      "There are 9 cut regions\n",
      "NCuts took  2.498717784881592  s\n",
      "Ratio of points in top 3 groups: 0.7938525537323781\n",
      "Dino load  656.7840938568115  s\n",
      "Ncuts percentage  0.0\n",
      "Construction  99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [10:58<32:54, 658.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write instance file pcd_preprocessed/output_chunks/out_kitti_instance2/4/004595.pcd\n",
      "center 4612\n",
      "Start of sequence 31\n",
      "4051 points in downsampled chunk (major)\n",
      "label shape (376, 1241)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  588.7343058586121  s\n",
      "There are 17 cut regions\n",
      "NCuts took  4.953286170959473  s\n",
      "Ratio of points in top 3 groups: 0.8612688225129598\n",
      "Dino load  594.6021783351898  s\n",
      "Ncuts percentage  1.0\n",
      "Construction  99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [20:53<20:42, 621.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write instance file pcd_preprocessed/output_chunks/out_kitti_instance2/4/004612.pcd\n",
      "center 4629\n",
      "Start of sequence 32\n",
      "4471 points in downsampled chunk (major)\n",
      "label shape (376, 1241)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  797.8358774185181  s\n",
      "There are 10 cut regions\n",
      "NCuts took  4.17555570602417  s\n",
      "Ratio of points in top 3 groups: 0.9689107582196377\n",
      "Dino load  802.9667413234711  s\n",
      "Ncuts percentage  1.0\n",
      "Construction  99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [34:18<11:44, 704.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write instance file pcd_preprocessed/output_chunks/out_kitti_instance2/4/004629.pcd\n",
      "center 4646\n",
      "Start of sequence 33\n",
      "4886 points in downsampled chunk (major)\n",
      "label shape (376, 1241)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  547.5776963233948  s\n",
      "There are 10 cut regions\n",
      "NCuts took  4.115172386169434  s\n",
      "Ratio of points in top 3 groups: 0.9928366762177651\n",
      "Dino load  553.0466420650482  s\n",
      "Ncuts percentage  1.0\n",
      "Construction  99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [43:32<00:00, 653.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write instance file pcd_preprocessed/output_chunks/out_kitti_instance2/4/004646.pcd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##load data if already stored \n",
    "\n",
    "\n",
    "\n",
    "chunks_idcs = divide_indices_into_chunks(len(dataset)) \n",
    "\n",
    "for cur_idx, cidcs in enumerate(chunks_idcs[4:]): \n",
    "        ind_start, ind_end = cidcs[0], cidcs[1]\n",
    "        cur_idx = int(ind_start/1000) \n",
    "        print('cur idx',cur_idx)\n",
    "        print(\"ind start\",ind_start)\n",
    "        print('ind end',ind_end)\n",
    "        \n",
    "        if os.path.exists(f'{out_folder}all_poses_{SEQUENCE_NUM}_{cur_idx}.npz') == False:\n",
    "                process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                        major_voxel_size=major_voxel_size,icp=False,\n",
    "                                        out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                        ground_segmentation_method=ground_segmentation_method,cur_idx=cur_idx)\n",
    "        \n",
    "        if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_{cur_idx}.pcd') == False:\n",
    "                print('load and downsample')\n",
    "                pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                        all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                                ground_mode=ground_segmentation_method,cur_idx=cur_idx)\n",
    "                #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "                o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_{cur_idx}.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_{cur_idx}.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "                np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_{cur_idx}.npz',\n",
    "                                                        instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                        instance_ground=kitti_labels['instance_ground'],\n",
    "                                                        seg_ground = kitti_labels['seg_ground'],\n",
    "                                                        seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                        )\n",
    "        \n",
    "        pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_{cur_idx}.pcd')\n",
    "        pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_{cur_idx}.pcd')\n",
    "        print(pcd_ground_minor)\n",
    "        kitti_labels_orig = {}\n",
    "        with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_{cur_idx}.npz') as data :\n",
    "                kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "                kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "                kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "                kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "        \n",
    "                \n",
    "        \n",
    "        with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_{cur_idx}.npz') as data:\n",
    "                all_poses = data['all_poses']\n",
    "                T_pcd = data['T_pcd']\n",
    "                first_position = T_pcd[:3, 3]\n",
    "                \n",
    "        if os.path.exists(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_{cur_idx}.npz') == False : \n",
    "                print(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_{cur_idx}.npz')\n",
    "                poses, positions, \\\n",
    "        \tsampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start,sequence_num=SEQUENCE_NUM,\n",
    "        \t                                                                        out_folder=out_folder,cur_idx=cur_idx)\n",
    "        \n",
    "        with np.load(f'{out_folder}subsampled_data{SEQUENCE_NUM}_{cur_idx}.npz') as data:\n",
    "                poses=data['poses']\n",
    "                positions=data['positions']\n",
    "                sampled_indices_local = data['sampled_indices_local']\n",
    "                sampled_indices_global=data['sampled_indices_global']\n",
    "        \n",
    "        print(\"chunk and downsample\")\n",
    "        pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "        pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "        indices,indices_ground, center_positions, \\\n",
    "        center_ids, chunk_bounds, kitti_labels, obbs = chunk_and_downsample_point_clouds(dataset,pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                                    first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                                    overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)\n",
    "                                                                    \n",
    "        \n",
    "        \n",
    "        # Generate 30 different colors\n",
    "        \n",
    "        \n",
    "        COLORS = generate_random_colors(400)\n",
    "        COLORS = [(col[0]/255.,col[1]/255.,col[2]/255.) for col in COLORS]\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "\n",
    "        \n",
    "        limit = -1 ##use this for experiments to run limit chunks numberss\n",
    "        \n",
    "        \n",
    "        patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "        out_data = []\n",
    "        semantics = np.hstack((kitti_labels_orig['seg_nonground'].reshape(-1,),kitti_labels_orig['seg_ground'].reshape(-1,)))\n",
    "        \n",
    "        instances = np.hstack((kitti_labels_orig['instance_nonground'].reshape(-1,),kitti_labels_orig['instance_ground'].reshape(-1,)))\n",
    "                        \n",
    "        merge_pcd = o3d.geometry.PointCloud()    \n",
    "        \n",
    "        out_kitti_instance_cur = out_kitti_instance + str(cur_idx) + '/'\n",
    "        out_folder_ncuts_cur = out_folder_ncuts + str(cur_idx) + '/'\n",
    "        if os.path.exists(out_kitti_instance_cur) == False : \n",
    "                #shutil.rmtree(out_kitti_instance_cur)\n",
    "                os.makedirs(out_kitti_instance_cur)\n",
    "                \n",
    "        if os.path.exists(out_folder_ncuts_cur) == False : \n",
    "                os.makedirs(out_folder_ncuts_cur)\n",
    "        \n",
    "        print(\"total sequence number\",len(center_ids))\n",
    "        for sequence in tqdm(range(30,len(center_ids))):\n",
    "                        print('center',center_ids[sequence])\n",
    "                        merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,list(indices),pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                                pcd_nonground_chunks_major_downsampling,\n",
    "                                pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                                positions,first_position,list(sampled_indices_global),\n",
    "                                chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                                alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                                proximity_threshold=proximity_threshold,\n",
    "                                out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                                patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold,obb=obbs[sequence])\n",
    "                        \n",
    "                                \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                        inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                        \n",
    "                        file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "        \n",
    "                        kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['semantic'][sequence].reshape(-1,),\n",
    "                                                colors=COLORS,gt_labels=semantics,semantics=True\n",
    "                                                )\n",
    "                        \n",
    "                        kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                                colors=colors,gt_labels=instances)\n",
    "                                                \n",
    "                        kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,inst_ground.reshape(-1,),\n",
    "                                                colors=colors,gt_labels=instances)\n",
    "                                                \n",
    "                        kitti_chunk_semantic_ground = color_pcd_by_labels(pcd_chunk_ground,seg_ground.reshape(-1,),\n",
    "                                                colors=COLORS,gt_labels=semantics,semantics=True)\n",
    "                        \n",
    "                        #o3d.visualization.draw_geometries([kitti_chunk_instance + kitti_chunk_instance_ground])\n",
    "                        #o3d.visualization.draw_geometries([pcd_chunk + pcd_chunk_ground])\n",
    "                        #semantic_labels = np.hstack(( kitti_labels['nonground']['semantic'][sequence].reshape(-1,),seg_ground.reshape(-1,)))\n",
    "                        #np.savez(out_kitti_semantic + file_name.split('.')[0] + '.npz',labels=semantic_labels)\n",
    "                        \n",
    "                        o3d.io.write_point_cloud(out_folder_ncuts_cur + file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                        print('write instance file',out_kitti_instance_cur + file_name)\n",
    "                        #o3d.io.write_point_cloud(out_kitti_instance_cur + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                        #o3d.io.write_point_cloud(out_kitti_semantic + file_name, kitti_chunk + kitti_chunk_semantic_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000015.pcd', '000031.pcd', '000051.pcd', '000075.pcd', '000098.pcd', '000119.pcd', '000139.pcd', '000157.pcd', '000175.pcd', '000194.pcd', '000212.pcd', '000230.pcd', '000248.pcd', '000266.pcd', '000285.pcd', '000304.pcd', '000322.pcd', '000339.pcd', '000356.pcd', '000373.pcd', '000391.pcd', '000410.pcd', '000430.pcd', '000451.pcd', '000472.pcd', '000495.pcd', '000523.pcd', '000546.pcd', '000569.pcd', '000589.pcd', '000607.pcd', '000625.pcd', '000643.pcd', '000661.pcd', '000679.pcd', '000697.pcd', '000714.pcd', '000731.pcd', '000749.pcd', '000768.pcd', '000786.pcd', '000803.pcd', '000820.pcd', '000837.pcd', '000855.pcd', '000876.pcd', '000909.pcd', '000942.pcd', '000966.pcd', '000990.pcd']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [05:36<00:00,  6.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001042.pcd', '001073.pcd', '001102.pcd', '001129.pcd', '001161.pcd', '001191.pcd', '001215.pcd', '001238.pcd', '001260.pcd', '001286.pcd', '001324.pcd', '001353.pcd', '001377.pcd', '001402.pcd', '001426.pcd', '001449.pcd', '001471.pcd', '001491.pcd', '001510.pcd', '001528.pcd', '001546.pcd', '001564.pcd', '001583.pcd', '001603.pcd', '001624.pcd', '001646.pcd', '001668.pcd', '001690.pcd', '001710.pcd', '001729.pcd', '001753.pcd', '001804.pcd', '001829.pcd', '001848.pcd', '001865.pcd', '001880.pcd', '001896.pcd', '001912.pcd', '001927.pcd', '001942.pcd', '001958.pcd', '001980.pcd']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [04:44<00:00,  6.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['002033.pcd', '002055.pcd', '002075.pcd', '002093.pcd', '002111.pcd', '002128.pcd', '002145.pcd', '002163.pcd', '002181.pcd', '002199.pcd', '002216.pcd', '002233.pcd', '002250.pcd', '002267.pcd', '002284.pcd', '002301.pcd', '002318.pcd', '002335.pcd', '002353.pcd', '002371.pcd', '002390.pcd', '002411.pcd', '002435.pcd', '002459.pcd', '002480.pcd', '002499.pcd', '002518.pcd', '002541.pcd', '002576.pcd', '002601.pcd', '002621.pcd', '002649.pcd', '002678.pcd', '002700.pcd', '002720.pcd', '002741.pcd', '002763.pcd', '002783.pcd', '002802.pcd', '002821.pcd', '002840.pcd', '002859.pcd', '002878.pcd', '002897.pcd', '002916.pcd', '002935.pcd', '002954.pcd', '002972.pcd', '002990.pcd']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [06:22<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['003018.pcd', '003036.pcd', '003055.pcd', '003074.pcd', '003094.pcd', '003115.pcd', '003135.pcd', '003153.pcd', '003171.pcd', '003189.pcd', '003207.pcd', '003226.pcd', '003245.pcd', '003266.pcd', '003289.pcd', '003330.pcd', '003361.pcd', '003385.pcd', '003418.pcd', '003443.pcd', '003465.pcd', '003490.pcd', '003514.pcd', '003534.pcd', '003553.pcd', '003572.pcd', '003589.pcd', '003609.pcd', '003638.pcd', '003661.pcd', '003680.pcd', '003701.pcd', '003726.pcd', '003748.pcd', '003769.pcd', '003793.pcd', '003819.pcd', '003840.pcd', '003858.pcd', '003876.pcd', '003894.pcd', '003911.pcd', '003928.pcd', '003946.pcd', '003963.pcd', '003980.pcd', '003998.pcd']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [05:39<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['004018.pcd', '004037.pcd', '004065.pcd', '004094.pcd', '004116.pcd', '004136.pcd', '004156.pcd', '004187.pcd', '004215.pcd', '004234.pcd', '004252.pcd', '004269.pcd', '004286.pcd', '004302.pcd', '004318.pcd', '004334.pcd', '004350.pcd', '004367.pcd', '004385.pcd', '004402.pcd', '004420.pcd', '004438.pcd', '004457.pcd', '004473.pcd', '004491.pcd', '004508.pcd', '004525.pcd', '004542.pcd', '004560.pcd', '004578.pcd', '004595.pcd', '004612.pcd', '004629.pcd', '004646.pcd']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [03:08<00:00,  5.72s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(len(divide_indices_into_chunks(len(dataset)))) : \n",
    "\t\n",
    "\tout_kitti_instance_cur = out_kitti_instance + str(i) + '/'\n",
    "\tout_folder_ncuts_cur = out_folder_ncuts + str(i) + '/'\n",
    "\t\n",
    "\tpoint_clouds = get_merge_pcds(out_folder_ncuts_cur)\n",
    "\tif len(point_clouds) == 0 : \n",
    "\t\tcontinue\n",
    "\tpoint_clouds_kitti_instances = get_merge_pcds(out_kitti_instance_cur)\n",
    "\tmerge_pred = merge_chunks_unite_instances2(point_clouds)\n",
    "\t#merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "\t\n",
    "\t#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_semantic7.pcd\", merge_kitti_semantic, write_ascii=False, compressed=False, print_progress=False)\n",
    "\to3d.io.write_point_cloud(out_folder_ncuts + str(SEQUENCE_NUM) + \"_\" + str(i) +  \"_pred_all.pcd\", merge_pred, write_ascii=False, compressed=False, print_progress=False)\n",
    "\t#o3d.io.write_point_cloud(out_kitti_instance + \"merge_part_kitti_instance\" + str(SEQUENCE_NUM) + \"_\" + str(i) +  \".pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Metrics for file ncuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 716/716 [00:00<00:00, 41538.10it/s]\n",
      "Processing: 100%|██████████| 716/716 [01:59<00:00,  6.00it/s]\n",
      "100%|██████████| 376/376 [00:00<00:00, 69302.97it/s]\n",
      "Processing: 100%|██████████| 376/376 [00:55<00:00,  6.76it/s]\n",
      "100%|██████████| 689/689 [00:00<00:00, 105546.95it/s]\n",
      "Processing: 100%|██████████| 689/689 [02:19<00:00,  4.94it/s]\n",
      "100%|██████████| 549/549 [00:00<00:00, 90585.09it/s]\n",
      "Processing: 100%|██████████| 549/549 [01:33<00:00,  5.87it/s]\n",
      "100%|██████████| 269/269 [00:00<00:00, 1940.70it/s]\n",
      "Processing: 100%|██████████| 269/269 [00:29<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison @ 0.5 0.8883248730964467\n",
      "Recall @ 0.5 0.7322175732217573\n",
      "F Score @ 0.5 0.8027522935779815\n",
      "Mean @ 0.5 0.9080574000428899\n",
      "Panoptic @ 0.5 0.7289451605848886\n",
      "S_assoc score 0.6966849185625403\n",
      "AP @ 0.25 73.283\n",
      "AP @ 0.5 63.111\n",
      "AP @ [0.5:0.95] 47.249\n"
     ]
    }
   ],
   "source": [
    "metrics_ncuts = Metrics('ncuts')\n",
    "\n",
    "for i in range(len(divide_indices_into_chunks(len(dataset)))) : \n",
    "\n",
    "\t\tif os.path.exists(out_folder_ncuts + str(SEQUENCE_NUM) + \"_\" + str(i) +  \"_pred_all.pcd\") == False : \n",
    "\t\t\tcontinue\n",
    "\t\tall_pred = o3d.io.read_point_cloud(out_folder_ncuts + str(SEQUENCE_NUM) + \"_\" + str(i) +  \"_pred_all.pcd\")\n",
    "\t\tcur_gt = o3d.io.read_point_cloud(out_kitti_instance + \"merge_part_kitti_instance\" + str(SEQUENCE_NUM) + \"_\" + str(i) +  \".pcd\")\n",
    "\t\t\t\n",
    "\t\tunique_colors, labels_ncuts_all = np.unique(np.asarray(all_pred.colors), axis=0, return_inverse=True)\n",
    "\t\tunique_colors, labels_kitti = np.unique(np.asarray(cur_gt.colors),axis=0, return_inverse=True)\n",
    "\t\t\n",
    "\t\tlabels_ncuts = remove_semantics(labels_kitti,labels_ncuts_all)\n",
    "\t\tmetrics_ncuts.add_stats(labels_ncuts_all,labels_ncuts,labels_kitti)\n",
    "\t\n",
    "\n",
    "\n",
    "metrics_ncuts.compute_stats_final()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
