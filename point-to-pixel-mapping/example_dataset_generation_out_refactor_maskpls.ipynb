{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/anaconda3/envs/torch/lib/python3.9/site-packages/MinkowskiEngine-0.5.4-py3.9-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics_class import Metrics\n",
    "import shutil\n",
    "from predict_maskpls import RefinerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "ind_start = 0\n",
    "ind_end = 1100\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False \n",
    "out_folder_ncuts = 'test_data/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif os.path.exists('{out_folder}all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\\n        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\\n                                major_voxel_size=major_voxel_size,icp=False,\\n                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\\n                                ground_segmentation_method=ground_segmentation_method)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "if os.path.exists('{out_folder}all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        \n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed.npz',panoptic_nonground=kitti_labels['panoptic_nonground'],\n",
    "                                                panoptic_ground=kitti_labels['panoptic_ground'],\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}.pcd')\n",
    "\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}.npz') as data :\n",
    "        kitti_labels_orig['panoptic_ground'] = data['panoptic_ground']\n",
    "        kitti_labels_orig['panoptic_nonground'] = data['panoptic_nonground']\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_{0}.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npcd_new = o3d.geometry.PointCloud()\\npts_num = 1000000\\npcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\\n\\nmap_labelled = color_pcd_by_labels(pcd_new,                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\\n\\no3d.visualization.draw_geometries([map_labelled])\\n#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pts_num = 1000000\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses, positions, \\\n",
    "sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (523285, 3) to (7646, 3) points (non-ground)\n",
      "Downsampled from (257594, 3) to (5502, 3) points (ground)\n",
      "Downsampled from (392323, 3) to (6659, 3) points (non-ground)\n",
      "Downsampled from (273555, 3) to (4539, 3) points (ground)\n",
      "Downsampled from (429859, 3) to (7470, 3) points (non-ground)\n",
      "Downsampled from (291612, 3) to (6157, 3) points (ground)\n",
      "Downsampled from (381642, 3) to (5813, 3) points (non-ground)\n",
      "Downsampled from (255212, 3) to (4655, 3) points (ground)\n",
      "Downsampled from (414475, 3) to (7677, 3) points (non-ground)\n",
      "Downsampled from (237620, 3) to (4305, 3) points (ground)\n",
      "Downsampled from (463157, 3) to (8880, 3) points (non-ground)\n",
      "Downsampled from (226253, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (506123, 3) to (9688, 3) points (non-ground)\n",
      "Downsampled from (228215, 3) to (4918, 3) points (ground)\n",
      "Downsampled from (389712, 3) to (6633, 3) points (non-ground)\n",
      "Downsampled from (308744, 3) to (4290, 3) points (ground)\n",
      "Downsampled from (280190, 3) to (4670, 3) points (non-ground)\n",
      "Downsampled from (445550, 3) to (6148, 3) points (ground)\n",
      "Downsampled from (317852, 3) to (6098, 3) points (non-ground)\n",
      "Downsampled from (379220, 3) to (5586, 3) points (ground)\n",
      "Downsampled from (387816, 3) to (7721, 3) points (non-ground)\n",
      "Downsampled from (359782, 3) to (5497, 3) points (ground)\n",
      "Downsampled from (184448, 3) to (3774, 3) points (non-ground)\n",
      "Downsampled from (389151, 3) to (5520, 3) points (ground)\n",
      "Downsampled from (199395, 3) to (4127, 3) points (non-ground)\n",
      "Downsampled from (416037, 3) to (5994, 3) points (ground)\n",
      "Downsampled from (408664, 3) to (6446, 3) points (non-ground)\n",
      "Downsampled from (375810, 3) to (6250, 3) points (ground)\n",
      "Downsampled from (476070, 3) to (8020, 3) points (non-ground)\n",
      "Downsampled from (303409, 3) to (6179, 3) points (ground)\n",
      "Downsampled from (382381, 3) to (6338, 3) points (non-ground)\n",
      "Downsampled from (335270, 3) to (5700, 3) points (ground)\n",
      "Downsampled from (330746, 3) to (6146, 3) points (non-ground)\n",
      "Downsampled from (327581, 3) to (5693, 3) points (ground)\n",
      "Downsampled from (406053, 3) to (7046, 3) points (non-ground)\n",
      "Downsampled from (206707, 3) to (4643, 3) points (ground)\n",
      "Downsampled from (422975, 3) to (7520, 3) points (non-ground)\n",
      "Downsampled from (209102, 3) to (4738, 3) points (ground)\n",
      "Downsampled from (401315, 3) to (6104, 3) points (non-ground)\n",
      "Downsampled from (363511, 3) to (5407, 3) points (ground)\n",
      "Downsampled from (300792, 3) to (4939, 3) points (non-ground)\n",
      "Downsampled from (396420, 3) to (6060, 3) points (ground)\n",
      "Downsampled from (313196, 3) to (5781, 3) points (non-ground)\n",
      "Downsampled from (251931, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (309416, 3) to (5698, 3) points (non-ground)\n",
      "Downsampled from (274970, 3) to (5225, 3) points (ground)\n",
      "Downsampled from (274156, 3) to (4913, 3) points (non-ground)\n",
      "Downsampled from (284434, 3) to (4914, 3) points (ground)\n",
      "Downsampled from (295151, 3) to (5374, 3) points (non-ground)\n",
      "Downsampled from (254407, 3) to (4843, 3) points (ground)\n",
      "Downsampled from (298362, 3) to (5378, 3) points (non-ground)\n",
      "Downsampled from (349049, 3) to (5351, 3) points (ground)\n",
      "Downsampled from (212601, 3) to (3902, 3) points (non-ground)\n",
      "Downsampled from (434219, 3) to (6130, 3) points (ground)\n",
      "Downsampled from (478729, 3) to (7473, 3) points (non-ground)\n",
      "Downsampled from (299350, 3) to (5988, 3) points (ground)\n",
      "Downsampled from (552680, 3) to (7790, 3) points (non-ground)\n",
      "Downsampled from (327195, 3) to (5910, 3) points (ground)\n",
      "Downsampled from (603758, 3) to (8666, 3) points (non-ground)\n",
      "Downsampled from (429185, 3) to (6377, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def DBSCAN_clustering_logic(cur_pcd, pcd_all, eps=1.0, min_samples=100):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on the point cloud data.\n",
    "\n",
    "    :param cur_pcd: Current point cloud for clustering.\n",
    "    :param pcd_all: All point cloud data.\n",
    "    :param eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "    :param min_samples: The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "    :return: Cluster labels for each point in the point cloud.\n",
    "    \"\"\"\n",
    "    not_road_points = np.asarray(cur_pcd.points)\n",
    "    #clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(not_road_points)\n",
    "    clustering = DBSCAN(min_cluster_size=100).fit(not_road_points)\n",
    "    labels_not_road = clustering.labels_\n",
    "    colors_gen = generate_random_colors(500)\n",
    "    \n",
    "    # Reproject cluster labels to the original point cloud size\n",
    "    cluster_labels = np.ones((len(pcd_all.points), 1)) * -1\n",
    "    labels_non_ground = kDTree_1NN_feature_reprojection(cluster_labels, pcd_all, labels_not_road.reshape(-1,1), cur_pcd)\n",
    "    colors = np.zeros((labels_non_ground.shape[0],3))\n",
    "    unique_labels = list(np.unique(labels_non_ground))\n",
    "    for j in unique_labels:\n",
    "            cur_idcs = np.where(labels_non_ground == j)[0]\n",
    "            \n",
    "            colors[cur_idcs] = np.array(colors_gen[unique_labels.index(j)])\n",
    "    pcd_all.colors = o3d.utility.Vector3dVector(colors / 255.)\n",
    "    return pcd_all\n",
    "\n",
    "def dbscan_clustering(pcd_chunks_major_downsampled, pcds, center_ids,ground_clouds):\n",
    "    labels_clustering = []\n",
    "    for i in range(len(pcd_chunks_major_downsampled)):\n",
    "        cur_pcd = pcd_chunks_major_downsampled[i]\n",
    "        pcd_all = pcds[i]\n",
    "        ground_cloud = ground_clouds[i]\n",
    "        cluster_labels = DBSCAN_clustering_logic(cur_pcd, pcd_all)  # Implement your DBSCAN logic here\n",
    "        ground_labels = np.ones((np.asarray(ground_cloud.points).shape[0],1)) * -1\n",
    "        cluster_labels = np.concatenate((cluster_labels,ground_labels),0)\n",
    "        labels_clustering.append(cluster_labels)\n",
    "        \n",
    "    return labels_clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "\n",
    "\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "        #if labels[i] != (-1):\n",
    "        #    pcd_colored.colors[i] = np.array(colors[labels[i]]) / 255\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/ 255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence 0\n",
      "sequence 1\n",
      "sequence 2\n",
      "sequence 3\n",
      "sequence 4\n",
      "sequence 5\n",
      "sequence 6\n",
      "sequence 7\n",
      "sequence 8\n",
      "sequence 9\n",
      "sequence 10\n",
      "sequence 11\n",
      "sequence 12\n",
      "sequence 13\n",
      "sequence 14\n",
      "sequence 15\n",
      "sequence 16\n",
      "sequence 17\n",
      "sequence 18\n",
      "sequence 19\n",
      "sequence 20\n",
      "sequence 21\n",
      "sequence 22\n",
      "sequence 23\n",
      "sequence 24\n",
      "sequence 25\n",
      "sequence 26\n",
      "sequence 27\n",
      "sequence 28\n",
      "sequence 29\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "\n",
    "\n",
    "\n",
    "out_dbscan = 'out_dbscan/'\n",
    "if os.path.exists(out_dbscan) == True : \n",
    "        shutil.rmtree(out_dbscan)\n",
    "        \n",
    "os.makedirs(out_dbscan)\n",
    "\n",
    "out_kitti = 'out_kitti/'\n",
    "if os.path.exists(out_kitti) == True : \n",
    "        shutil.rmtree(out_kitti)\n",
    "\n",
    "os.makedirs(out_kitti)\n",
    "        \n",
    "out_kitti_instance = 'out_kitti_instance/'\n",
    "#if os.path.exists(out_kitti_instance) == True : \n",
    "#        shutil.rmtree(out_kitti_instance)\n",
    "#os.makedirs(out_kitti_instance)\n",
    "\n",
    "        \n",
    "out_refined = 'out_refined/'\n",
    "if os.path.exists(out_refined) == True : \n",
    "        shutil.rmtree(out_refined)\n",
    "os.makedirs(out_refined)\n",
    "\n",
    "limit = 2 ##use this for experiments to run limit chunks numberss\n",
    "\n",
    "maskpls = RefinerModel()\n",
    "eval_refiner = True \n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "for sequence in range(len(center_ids)):\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                if eval_refiner == False : \n",
    "                        merged_chunk,file_name, pcd_chunk, pcd_chunk_ground, inliers_ground = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                                pcd_nonground_chunks_major_downsampling,\n",
    "                                pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                                positions,first_position,sampled_indices_global,\n",
    "                                chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                                alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                                proximity_threshold=proximity_threshold,\n",
    "                                out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                                patchwise_indices=patchwise_indices)\n",
    "                        o3d.io.write_point_cloud(file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                        kitti_labels['ground']['panoptic'][sequence] = kitti_labels['ground']['panoptic'][sequence][inliers_ground]\n",
    "                        kitti_labels['ground']['instance'][sequence] = kitti_labels['ground']['instance'][sequence][inliers_ground]\n",
    "                        #kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['panoptic'][sequence].reshape(-1,),\n",
    "                        #                        colors=colors,gt_labels=kitti_labels_orig['panoptic_nonground'])\n",
    "                        #kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                        #                        colors=colors,gt_labels=kitti_labels_orig['instance_nonground'])\n",
    "                        #o3d.io.write_point_cloud(out_kitti + name, kitti_chunk + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                        #o3d.io.write_point_cloud(out_kitti_instance + name, kitti_chunk_instance + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                else :  \n",
    "                        print(\"sequence\",sequence)\n",
    "                        cur_pcd = o3d.io.read_point_cloud(out_kitti_instance + name)\n",
    "                        predicted_refined = maskpls.forward_and_project(cur_pcd)\n",
    "                        #maskpls.project_pseudo_labels(cur_pcd,center_ids[sequence],name)\n",
    "                        o3d.io.write_point_cloud(out_refined + name, predicted_refined,write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                #pcd_dbscan = DBSCAN_clustering_logic(pcd_nonground_chunks_major_downsampling[sequence],\n",
    "                #                                pcd_nonground_chunks[sequence],\n",
    "                #                                eps=0.6, min_samples=10)\n",
    "                \n",
    "                \n",
    "                #kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,kitti_labels['ground']['instance'][sequence].reshape(-1,))\n",
    "                #o3d.io.write_point_cloud(out_dbscan + name, pcd_dbscan + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                \n",
    "                \n",
    "        else : \n",
    "                obstacle_out,file_name = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "                \n",
    "                \n",
    "                ground_out,file_name = ncuts_chunk(dataset,indices_ground,pcd_ground_chunks,None,\n",
    "                        pcd_ground_chunks_major_downsampling,\n",
    "                        pcd_ground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "\n",
    "                o3d.io.write_point_cloud(file_name, obstacle_out + ground_out, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "                print(\"Pointcloud written to file\")\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge \n",
    "\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "def remove_semantics(labels,preds):\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "        return new_ncuts_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['000062.pcd', '000090.pcd', '000121.pcd', '000161.pcd', '000190.pcd', '000216.pcd', '000245.pcd', '000275.pcd', '000330.pcd', '000366.pcd', '000389.pcd', '000412.pcd', '000437.pcd', '000477.pcd', '000513.pcd', '000537.pcd', '000562.pcd', '000584.pcd', '000606.pcd', '000634.pcd', '000769.pcd', '000790.pcd', '000809.pcd', '000829.pcd', '000850.pcd', '000872.pcd', '000906.pcd', '000944.pcd', '000975.pcd', '001029.pcd']\n",
      "['000062.pcd', '000090.pcd', '000121.pcd', '000161.pcd', '000190.pcd', '000216.pcd', '000245.pcd', '000275.pcd', '000330.pcd', '000366.pcd', '000389.pcd', '000412.pcd', '000437.pcd', '000477.pcd', '000513.pcd', '000537.pcd', '000562.pcd', '000584.pcd', '000606.pcd', '000634.pcd', '000769.pcd', '000790.pcd', '000809.pcd', '000829.pcd', '000850.pcd', '000872.pcd', '000906.pcd', '000944.pcd', '000975.pcd', '001029.pcd']\n"
     ]
    }
   ],
   "source": [
    "out_dbscan = 'out_dbscan/'\n",
    "out_kitti = 'out_kitti/'\n",
    "out_kitti_instance = 'out_kitti_instance/'\n",
    "\n",
    "\n",
    "point_clouds = get_merge_pcds(out_folder_ncuts)\n",
    "#point_clouds_dbscan = get_merge_pcds(out_dbscan)\n",
    "#point_clouds_kitti = get_merge_pcds(out_kitti)[:-1]\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)[:-1]\n",
    "point_clouds_refined = get_merge_pcds(out_refined)[:-1]\n",
    "\n",
    "#merge = merge_chunks_unite_instances(point_clouds)\n",
    "#merge_dbscan = merge_chunks_unite_instances(point_clouds_dbscan)\n",
    "#merge_kitti = merge_unite_gt(point_clouds_kitti)\n",
    "merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "merge_refined = merge_chunks_unite_instances(point_clouds_refined)\n",
    "\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_refined.pcd\", merge_refined, write_ascii=False, compressed=False, print_progress=False)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_dbscan.pcd\", merge_dbscan, write_ascii=False, compressed=False, print_progress=False)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti.pcd\", merge_kitti, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_instance.pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "#unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "unique_colors, labels_refined = np.unique(np.asarray(merge_refined.colors),axis=0, return_inverse=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noptional cell for loading stored files\\nimport open3d as o3d\\n\\nout_folder = 'pcd_preprocessed/'\\nmerge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\\nmerge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\\nmerge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\\nmerge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\\nmerge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\\n\\nprint(merge)\\nprint(merge_kitti)\\nprint(merge_exp2)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "optional cell for loading stored files\n",
    "import open3d as o3d\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "merge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\n",
    "merge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\n",
    "merge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\n",
    "merge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\n",
    "\n",
    "print(merge)\n",
    "print(merge_kitti)\n",
    "print(merge_exp2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panoptic': 0.7887763627032877, 'precision': 0.8775510204081632, 'recall': 0.8037383177570093, 'fScore': 0.8390243902439024, 'usr': 0.04081632653061224, 'osr': 0.009345794392523364, 'noise': 0.10204081632653061, 'missed': 0.14953271028037382, 'mean': 0.9401113625242673}\n",
      "APs for  refined\n",
      "mAP@0.25  0.8598130841121495\n",
      "mAP@0.5  0.8037383177570093\n",
      "mAP  0.7487019730010385\n"
     ]
    }
   ],
   "source": [
    "#new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "new_refined = remove_semantics(labels_kitti,labels_refined)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_refined = Metrics(name='refined')\n",
    "#metrics_dbscan = Metrics(name='dbscan')\n",
    "metrics_test = Metrics(name='test')\n",
    "\n",
    "#metrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\n",
    "metrics_refined.update_stats(new_refined,labels_kitti)\n",
    "\n",
    "#metrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\n",
    "#metrics_dbscan.compute_all_aps()\n",
    "#metrics_ncuts.compute_all_aps()\n",
    "metrics_refined.compute_all_aps()\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = 'pcd_preprocessed/'\n",
    "merge_refined = o3d.io.read_point_cloud(out_folder + 'merge_refined.pcd')\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\n",
    "\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "unique_colors, labels_refined = np.unique(np.asarray(merge_refined.colors),axis=0, return_inverse=True)\n",
    "\n",
    "new_refined = remove_semantics(labels_kitti,labels_refined)\n",
    "o3d.visualization.draw_geometries([color_pcd_by_labels(merge_refined,new_refined)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([color_pcd_by_labels(merge_refined,new_refined)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
