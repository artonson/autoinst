{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/anaconda3/envs/torch/lib/python3.9/site-packages/MinkowskiEngine-0.5.4-py3.9-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import shutil\n",
    "from open3d.pipelines import registration\n",
    "from predict_maskpls import RefinerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "ind_start = 0\n",
    "ind_end = 1100\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = 'pcd_preprocessed/output_chunks/'\n",
    "\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "\n",
    "\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "        #if labels[i] != (-1):\n",
    "        #    pcd_colored.colors[i] = np.array(colors[labels[i]]) / 255\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/ 255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor_maskpls.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor_maskpls.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         shutil\u001b[39m.\u001b[39mrmtree(out_refined)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor_maskpls.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(out_refined)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor_maskpls.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m maskpls \u001b[39m=\u001b[39m RefinerModel()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor_maskpls.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m eval_refiner \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor_maskpls.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m out_data \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/predict_maskpls.py:51\u001b[0m, in \u001b[0;36mRefinerModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(w, map_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_state_dict(w[\u001b[39m\"\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbackbone\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfs_dict \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance2/'\n",
    "\n",
    "        \n",
    "out_refined = out_chunks + 'out_refined/'\n",
    "if os.path.exists(out_refined) == True : \n",
    "        shutil.rmtree(out_refined)\n",
    "os.makedirs(out_refined)\n",
    "\n",
    "\n",
    "maskpls = RefinerModel()\n",
    "eval_refiner = True \n",
    "\n",
    "out_data = []\n",
    "\n",
    "center_ids = os.listdir(out_kitti_instance)\n",
    "for sequence in range(len(center_ids)):\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                name = center_ids[sequence]\n",
    "                print(\"sequence\",sequence)\n",
    "                cur_pcd = o3d.io.read_point_cloud(out_kitti_instance + name)\n",
    "                predicted_refined = maskpls.forward_and_project(cur_pcd)\n",
    "                #maskpls.project_pseudo_labels(cur_pcd,center_ids[sequence],name)\n",
    "                o3d.io.write_point_cloud(out_refined + name, predicted_refined,write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                        #pcd_dbscan = DBSCAN_clustering_logic(cur_pcd,\n",
    "                        #                        eps=0.3, min_samples=10)\n",
    "                        #o3d.io.write_point_cloud(out_dbscan + name, pcd_dbscan + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                \n",
    "                #kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,kitti_labels['ground']['instance'][sequence].reshape(-1,))\n",
    "                #o3d.io.write_point_cloud(out_dbscan + name, pcd_dbscan + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge \n",
    "\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "def remove_semantics(labels,preds):\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "        return new_ncuts_labels\n",
    "\n",
    "def remove_semantics_pcd(pcd,labels,preds):\n",
    "        cols = np.asarray(pcd.colors)\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "                        cols[pred_idcs] = np.array([0,0,0])\n",
    "                        \n",
    "        pcd.colors = o3d.utility.Vector3dVector(cols)   \n",
    "        return pcd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd', '000220.pcd', '000249.pcd', '000278.pcd', '000336.pcd', '000368.pcd', '000391.pcd']\n",
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd', '000220.pcd', '000249.pcd', '000278.pcd', '000336.pcd', '000368.pcd', '000391.pcd', '000415.pcd', '000441.pcd', '000483.pcd', '000515.pcd', '000540.pcd', '000565.pcd', '000587.pcd', '000610.pcd', '000650.pcd', '000774.pcd', '000794.pcd', '000813.pcd', '000833.pcd', '000854.pcd', '000877.pcd', '000915.pcd', '000949.pcd', '000982.pcd', '001048.pcd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_kitti = out_chunks + 'out_kitti/'\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance/'\n",
    "\n",
    "\n",
    "#point_clouds_kitti = get_merge_pcds(out_kitti)[:-1]\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)[:-1]\n",
    "point_clouds_refined = get_merge_pcds(out_refined)[:-1]\n",
    "\n",
    "#merge = merge_chunks_unite_instances(point_clouds)\n",
    "#merge_dbscan = merge_chunks_unite_instances(point_clouds_dbscan)\n",
    "#merge_kitti = merge_unite_gt(point_clouds_kitti)\n",
    "#merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "merge_refined = merge_chunks_unite_instances(point_clouds_refined)\n",
    "\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_refined.pcd\", merge_refined, write_ascii=False, compressed=False, print_progress=False)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_dbscan.pcd\", merge_dbscan, write_ascii=False, compressed=False, print_progress=False)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti.pcd\", merge_kitti, write_ascii=False, compressed=False, print_progress=False)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_instance.pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "#unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noptional cell for loading stored files\\nimport open3d as o3d\\n\\nout_folder = 'pcd_preprocessed/'\\nmerge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\\nmerge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\\nmerge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\\nmerge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\\nmerge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\\n\\nprint(merge)\\nprint(merge_kitti)\\nprint(merge_exp2)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "optional cell for loading stored files\n",
    "import open3d as o3d\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "merge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\n",
    "merge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\n",
    "merge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\n",
    "merge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\n",
    "\n",
    "print(merge)\n",
    "print(merge_kitti)\n",
    "print(merge_exp2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance7.pcd')\n",
    "merge_refined = o3d.io.read_point_cloud(out_folder + 'merge_refined.pcd')\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "unique_colors, labels_refined = np.unique(np.asarray(merge_refined.colors),axis=0, return_inverse=True)\n",
    "\n",
    "new_refined = remove_semantics_pcd(merge_refined,labels_kitti,labels_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_colors, labels_refined = np.unique(np.asarray(new_refined.colors),axis=0, return_inverse=True)\n",
    "label_to_confidence = {}\n",
    "pcd_cols = np.asarray(new_refined.colors) \n",
    "for label in list(np.unique(labels_refined)):\n",
    "\tidcs = np.where(labels_refined == label)[0]\n",
    "\tcur_color = pcd_cols[idcs[0]]\n",
    "\tkey = str(int(cur_color[0] * 255)) + '|' + str(int(cur_color[1] * 255)) + '|' + str(int(cur_color[2] * 255))\n",
    "\tlabel_to_confidence[label] = maskpls.confs_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for file refined\n",
      "{'panoptic': 0.759014368240107, 'precision': 0.86, 'recall': 0.7962962962962963, 'fScore': 0.826923076923077, 'usr': 0.05, 'osr': 0.018518518518518517, 'noise': 0.09, 'missed': 0.12962962962962962, 'mean': 0.9178778406624549}\n",
      "calc AP for overlap @0.25\n",
      "Average Precision @ 0.25 0.8498736961043124\n",
      "calc AP for overlap @0.5\n",
      "Average Precision @ 0.5 0.7260979532907539\n",
      "calc AP for overlap @0.55\n",
      "Average Precision @ 0.55 0.6949233306985517\n",
      "calc AP for overlap @0.6\n",
      "Average Precision @ 0.6 0.6949233306985517\n",
      "calc AP for overlap @0.65\n",
      "Average Precision @ 0.65 0.6949233306985517\n",
      "calc AP for overlap @0.7\n",
      "Average Precision @ 0.7 0.5918976092733214\n",
      "calc AP for overlap @0.75\n",
      "Average Precision @ 0.75 0.5795877708458368\n",
      "calc AP for overlap @0.8\n",
      "Average Precision @ 0.8 0.5640699974851524\n",
      "calc AP for overlap @0.85\n",
      "Average Precision @ 0.85 0.5301729079190256\n",
      "calc AP for overlap @0.9\n",
      "Average Precision @ 0.9 0.4534579560214868\n",
      "calc AP for overlap @0.95\n",
      "Average Precision @ 0.95 0.29502391374298775\n",
      "AP @ 0.25 0.8498736961043124\n",
      "AP @ 0.5 0.7260979532907539\n",
      "AP @ [0.5:0.95] 0.5825078100674219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([81, 81, 81, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_refined = Metrics(name='refined')\n",
    "\n",
    "\n",
    "metrics_refined.update_stats(labels_refined,labels_kitti,label_to_confidence,calc_all=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19170491,)\n",
      "(19170491,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_refined.shape) \n",
    "print(labels_kitti.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([merge_refined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Read PCD failed: unable to open file: pcd_preprocessed/merge_part_kitti_instance.pcd\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "out_folder = 'pcd_preprocessed/'\n",
    "merge_refined = o3d.io.read_point_cloud(out_folder + 'merge_refined.pcd')\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\n",
    "#unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "#unique_colors, labels_refined = np.unique(np.asarray(merge_refined.colors),axis=0, return_inverse=True)\n",
    "\n",
    "#new_refined = remove_semantics(labels_kitti,labels_refined)\n",
    "#o3d.visualization.draw_geometries([color_pcd_by_labels(merge_refined,new_refined)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([merge_refined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Read PCD failed: unable to open file: pcd_preprocessed/ncuts_tarl_spatial1_all.pcd\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "fn = out_folder + \"merge_refined.pcd\"\n",
    "fn2 = out_folder + 'ncuts_tarl_spatial1_all.pcd'\n",
    "pcd = o3d.io.read_point_cloud(fn)\n",
    "pcd_ncuts = o3d.io.read_point_cloud(fn2)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
