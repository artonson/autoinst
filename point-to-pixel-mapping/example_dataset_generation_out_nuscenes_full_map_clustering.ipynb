{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset_utils import create_nuscenes_odometry_dataset\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_unite_gt, remove_semantics, merge_chunks_unite_instances2\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "lib_path = os.path.expanduser('~') + '/unsup_3d_instances/pipeline/segmentation/utils/voxel_clustering_dependencies/build/'\n",
    "sys.path.insert(0, lib_path+ \"clustering\")\n",
    "felsenzwalb_path = '/home/cedric/UnScene3D_collaboration_fork/lib/utils/cpp_utils/build/lib.linux-x86_64-cpython-39/'\n",
    "import felzenszwalb_cpp\n",
    "import pycluster\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN\n",
    "import hdbscan\n",
    "\n",
    "#cvc clustering setup \n",
    "#params = [2,0.4,1.5]\n",
    "params = [0.1,0.2,0.5]\n",
    "cvc = pycluster.CVC_cluster(params)\n",
    "\n",
    "def uniform_down_sample_with_indices(points, every_k_points):\n",
    "        # Create a new point cloud for the downsampled output\n",
    "\n",
    "        # List to hold the indices of the points that are kept\n",
    "        indices = []\n",
    "\n",
    "        # Iterate over the points and keep every k-th point\n",
    "        for i in range(0, points.shape[0], every_k_points):\n",
    "            indices.append(i)\n",
    "\n",
    "        return indices\n",
    "\n",
    "def downsample_chunk(points):\n",
    "        num_points_to_sample = 30000\n",
    "        every_k_points = int(\n",
    "            points.shape[0] /\n",
    "            num_points_to_sample)\n",
    "        indeces = uniform_down_sample_with_indices(\n",
    "            points, every_k_points)\n",
    "\n",
    "\n",
    "        return points[indeces]\n",
    "\n",
    "def clustering_logic(pcd_nonground_chunk, pcd_ground_chunk,\n",
    "                        eps=0.3, min_samples=10,method='hdbscan'):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on the point cloud data.\n",
    "\n",
    "    :param cur_pcd: Current point cloud for clustering.\n",
    "    :param pcd_all: All point cloud data.\n",
    "    :param eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "    :param min_samples: The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "    :return: Cluster labels for each point in the point cloud.\n",
    "    \"\"\"\n",
    "    \n",
    "    inliers = get_statistical_inlier_indices(pcd_ground_chunk)\n",
    "    ground_inliers = get_subpcd(pcd_ground_chunk, inliers)\n",
    "    mean_hight = np.mean(np.asarray(ground_inliers.points)[:,2])\n",
    "    in_idcs = np.where(np.asarray(ground_inliers.points)[:,2] < (mean_hight + 0.2))[0]\n",
    "    cut_hight = get_subpcd(ground_inliers, in_idcs)\n",
    "    cut_hight.paint_uniform_color([0, 0, 0])\n",
    "    \n",
    "    in_idcs = None\n",
    "    \n",
    "    #in_idcs = np.where(np.asarray(pcd_nonground_chunk.points)[:,2] > (mean_hight + 0.05))[0]\n",
    "    #pcd_nonground_corrected = get_subpcd(pcd_nonground_chunk, in_idcs)\n",
    "    pcd_nonground_corrected = pcd_nonground_chunk\n",
    "    \n",
    "    pcd_nonground_downsampled = o3d.geometry.PointCloud()\n",
    "    pts_downsampled = downsample_chunk(np.asarray(pcd_nonground_corrected.points))\n",
    "    pcd_nonground_downsampled.points = o3d.utility.Vector3dVector(pts_downsampled)\n",
    "    \n",
    "    #clustering = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    #clustering = HDBSCAN(min_cluster_size=10).fit(pts_downsampled)\n",
    "    if method == 'hdbscan': \n",
    "        clustering = hdbscan.HDBSCAN(algorithm='best', alpha=1., approx_min_span_tree=True,\n",
    "                                    gen_min_span_tree=True, leaf_size=100,\n",
    "                                    metric='euclidean', min_cluster_size=10, min_samples=None\n",
    "                                )\n",
    "        clustering.fit(pts_downsampled)\n",
    "        \n",
    "        labels_not_road = clustering.labels_\n",
    "        \n",
    "    elif method == 'felzenswalb':    \n",
    "        pcd_nonground_downsampled.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "        #print(\"estimated normals\")\n",
    "        ## Optionally, you can orient the normals\n",
    "        #o3d.geometry.PointCloud.orient_normals_consistent_tangent_plane(pcd, k=10)\n",
    "        #print(\"create mesh\")\n",
    "        # Apply Poisson reconstruction\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_nonground_downsampled, depth=9)\n",
    "        #print(\"converted\")\n",
    "        # Optionally, you can remove low density vertices\n",
    "        #print(\"Mesh remove\")\n",
    "        vertices_to_remove = densities < np.quantile(densities, 0.05)\n",
    "        mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "\n",
    "        normals = np.asarray(mesh.vertex_normals)\n",
    "        norm_colors = (normals - normals.min(axis=0)) / (normals.max(axis=0) - normals.min(axis=0))\n",
    "        mesh.vertex_colors = o3d.utility.Vector3dVector(norm_colors)\n",
    "\n",
    "        vertices = np.array(mesh.vertices).astype(np.single)\n",
    "        colors = np.array(mesh.vertex_colors).astype(np.single)\n",
    "        faces = np.array(mesh.triangles).astype(np.intc)\n",
    "        \n",
    "        o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "        min_vert_num = 2000\n",
    "\n",
    "        comps, connectivity = felzenszwalb_cpp.segment_mesh(vertices, faces, colors, 0.5, min_vert_num)  # orig was min_vert_num=50\n",
    "        \n",
    "        \n",
    "        # Filter out small segments and floaters\n",
    "        mesh_points = np.array(mesh.vertices)\n",
    "        vertices_tree = KDTree(mesh_points)\n",
    "        segment_ids, segment_counts = np.unique(comps, return_counts=True)\n",
    "        \n",
    "\n",
    "        filtered_comps = comps.copy()\n",
    "        for segment_id, segment_count in zip(segment_ids, segment_counts):\n",
    "                \n",
    "                if (segment_id not in connectivity) or (segment_count < min_vert_num):\n",
    "                        tmp = segment_id.copy()\n",
    "                        _, closest_point_ids = vertices_tree.query(mesh_points[comps == segment_id][0], k=segment_count+1)\n",
    "                        target_segment_id = comps[closest_point_ids][np.nonzero(comps[closest_point_ids] - tmp)[0][0]]\n",
    "\n",
    "                        # update at location \n",
    "                        filtered_comps[comps == segment_id] = target_segment_id\n",
    "\n",
    "        seg_connectivity = connectivity\n",
    "        # Associate each point to a segment\n",
    "        kdtree = KDTree(vertices)\n",
    "        _, idx = kdtree.query(pts_downsampled)\n",
    "        labels_not_road = filtered_comps[idx]\n",
    "        print(\"pts shape\",pts_downsampled.shape)\n",
    "        print('labels shape',labels_not_road.shape)\n",
    "        \n",
    "\n",
    "    \n",
    "    else : \n",
    "        capr = None\n",
    "        hash_table = None\n",
    "        cluster_indices = None\n",
    "        cluster_id = None\n",
    "        capr = cvc.calculateAPR(pts_downsampled)\n",
    "        hash_table = cvc.build_hash_table(capr)\n",
    "        cluster_indices = cvc.cluster(hash_table,capr)\n",
    "        cluster_id = cvc.most_frequent_value(cluster_indices)\n",
    "        labels_not_road = np.ones((pts_downsampled.shape[0], 1)) * -1\n",
    "        \n",
    "        for i in range(len(cluster_id)):\n",
    "                for j in range(len(cluster_indices)):\n",
    "                        if cluster_indices[j] == cluster_id[i]:\n",
    "                                ##append point to cloud with certain colour \n",
    "                                labels_not_road[j] = cluster_id[i]\n",
    "                                #pt_colors[nonground_idcs[j]] = color  \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "        #labels_not_road = np.asarray(cluster_indices) \n",
    "        \n",
    "    colors_gen = generate_random_colors(5000)\n",
    "    \n",
    "    # Reproject cluster labels to the original point cloud size\n",
    "    cluster_labels = np.ones((len(pcd_nonground_corrected.points), 1)) * -1\n",
    "    labels_non_ground = kDTree_1NN_feature_reprojection(cluster_labels, pcd_nonground_corrected, labels_not_road.reshape(-1,1), pcd_nonground_downsampled )\n",
    "    colors = np.zeros((labels_non_ground.shape[0],3))\n",
    "    unique_labels = list(np.unique(labels_non_ground))\n",
    "    \n",
    "    for j in unique_labels:\n",
    "            cur_idcs = np.where(labels_non_ground == j)[0]\n",
    "            \n",
    "            colors[cur_idcs] = np.array(colors_gen[unique_labels.index(j)])\n",
    "        \n",
    "    pcd_nonground_corrected.colors = o3d.utility.Vector3dVector(colors / 255.)\n",
    "    \n",
    "    #o3d.visualization.draw_geometries([pcd_nonground_corrected])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pcd_nonground_corrected, cut_hight, in_idcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on nuscenes sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "34149 panoptic,\n",
      "Done loading in 25.403 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.0 seconds.\n",
      "======\n",
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 2008.45it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 1397.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (52875, 3) to (5441, 3) points (non-ground)\n",
      "Downsampled from (89592, 3) to (4781, 3) points (ground)\n",
      "Downsampled from (41061, 3) to (3683, 3) points (non-ground)\n",
      "Downsampled from (100167, 3) to (5656, 3) points (ground)\n",
      "Downsampled from (52702, 3) to (4771, 3) points (non-ground)\n",
      "Downsampled from (70635, 3) to (5649, 3) points (ground)\n",
      "Downsampled from (31829, 3) to (3068, 3) points (non-ground)\n",
      "Downsampled from (60375, 3) to (4868, 3) points (ground)\n",
      "4\n",
      "Start of sequence 0\n",
      "5441 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.9854621887207031  s\n",
      "There are 46 cut regions\n",
      "NCuts took  28.678466081619263  s\n",
      "Ratio of points in top 3 groups: 0.3819150891380261\n",
      "Dino load  29.945714950561523  s\n",
      "Ncuts percentage  96.0\n",
      "Construction  3.0\n",
      "labels [ 0 10]\n",
      "write instance chunk\n",
      "Start of sequence 1\n",
      "3683 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.5200095176696777  s\n",
      "There are 35 cut regions\n",
      "NCuts took  4.187375783920288  s\n",
      "Ratio of points in top 3 groups: 0.33613901710562044\n",
      "Dino load  4.917949438095093  s\n",
      "Ncuts percentage  85.0\n",
      "Construction  11.0\n",
      "labels [ 0 10 14 15 17 20 22]\n",
      "write instance chunk\n",
      "Start of sequence 2\n",
      "4771 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.5951683521270752  s\n",
      "There are 37 cut regions\n",
      "NCuts took  9.91050100326538  s\n",
      "Ratio of points in top 3 groups: 0.280863550618319\n",
      "Dino load  10.743508338928223  s\n",
      "Ncuts percentage  92.0\n",
      "Construction  6.0\n",
      "labels [ 0 23]\n",
      "write instance chunk\n",
      "Start of sequence 3\n",
      "3068 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.25613880157470703  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/85 [01:38<2:18:11, 98.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 cut regions\n",
      "NCuts took  1.2503724098205566  s\n",
      "Ratio of points in top 3 groups: 0.36766623207301175\n",
      "Dino load  1.6717450618743896  s\n",
      "Ncuts percentage  75.0\n",
      "Construction  15.0\n",
      "labels [0]\n",
      "write instance chunk\n",
      "current sequence 1\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "34149 panoptic,\n",
      "Done loading in 26.268 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.0 seconds.\n",
      "======\n",
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1653.45it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1359.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (46995, 3) to (4722, 3) points (non-ground)\n",
      "Downsampled from (110781, 3) to (6945, 3) points (ground)\n",
      "Downsampled from (55520, 3) to (6460, 3) points (non-ground)\n",
      "Downsampled from (69191, 3) to (5552, 3) points (ground)\n",
      "Downsampled from (41801, 3) to (3573, 3) points (non-ground)\n",
      "Downsampled from (91869, 3) to (6276, 3) points (ground)\n",
      "Downsampled from (29233, 3) to (3183, 3) points (non-ground)\n",
      "Downsampled from (72212, 3) to (4872, 3) points (ground)\n",
      "4\n",
      "Start of sequence 0\n",
      "4722 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.5527403354644775  s\n",
      "There are 43 cut regions\n",
      "NCuts took  14.353246212005615  s\n",
      "Ratio of points in top 3 groups: 0.49428208386277\n",
      "Dino load  15.151844024658203  s\n",
      "Ncuts percentage  95.0\n",
      "Construction  4.0\n",
      "labels [ 0  4  9 15 20 28 30 33 36 50 81]\n",
      "write instance chunk\n",
      "Start of sequence 1\n",
      "6460 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  1.083406925201416  s\n",
      "There are 63 cut regions\n",
      "NCuts took  35.49811601638794  s\n",
      "Ratio of points in top 3 groups: 0.3804953560371517\n",
      "Dino load  36.86823844909668  s\n",
      "Ncuts percentage  96.0\n",
      "Construction  3.0\n",
      "labels [ 0  3 33 34 52 56 57 58 59 60 61 64]\n",
      "write instance chunk\n",
      "Start of sequence 2\n",
      "3573 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.4130432605743408  s\n",
      "There are 38 cut regions\n",
      "NCuts took  7.896957159042358  s\n",
      "Ratio of points in top 3 groups: 0.489504617968094\n",
      "Dino load  8.510213851928711  s\n",
      "Ncuts percentage  93.0\n",
      "Construction  5.0\n",
      "labels [ 0 54]\n",
      "write instance chunk\n",
      "Start of sequence 3\n",
      "3183 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.28975820541381836  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/85 [03:45<2:39:24, 115.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 cut regions\n",
      "NCuts took  4.436415910720825  s\n",
      "Ratio of points in top 3 groups: 0.5592208608231228\n",
      "Dino load  4.875720024108887  s\n",
      "Ncuts percentage  91.0\n",
      "Construction  6.0\n",
      "labels [ 0 55 65 66 69 72]\n",
      "write instance chunk\n",
      "current sequence 2\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "34149 panoptic,\n",
      "Done loading in 25.339 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.3 seconds.\n",
      "======\n",
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1145.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1262.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (55445, 3) to (4552, 3) points (non-ground)\n",
      "Downsampled from (125510, 3) to (5482, 3) points (ground)\n",
      "1\n",
      "Start of sequence 0\n",
      "4552 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.5251758098602295  s\n",
      "There are 41 cut regions\n",
      "NCuts took  6.752872705459595  s\n",
      "Ratio of points in top 3 groups: 0.26823374340949035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3/85 [04:45<2:02:43, 89.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dino load  7.547144174575806  s\n",
      "Ncuts percentage  89.0\n",
      "Construction  7.000000000000001\n",
      "labels [ 0 11 12 39 41 42 45 46 48]\n",
      "write instance chunk\n",
      "current sequence 3\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "34149 panoptic,\n",
      "Done loading in 30.624 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.3 seconds.\n",
      "======\n",
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 1550.83it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 1544.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (28949, 3) to (3162, 3) points (non-ground)\n",
      "Downsampled from (72297, 3) to (6231, 3) points (ground)\n",
      "Downsampled from (3679, 3) to (873, 3) points (non-ground)\n",
      "Downsampled from (71124, 3) to (5515, 3) points (ground)\n",
      "Downsampled from (16483, 3) to (3059, 3) points (non-ground)\n",
      "Downsampled from (52150, 3) to (4468, 3) points (ground)\n",
      "Downsampled from (27282, 3) to (4363, 3) points (non-ground)\n",
      "Downsampled from (47025, 3) to (4949, 3) points (ground)\n",
      "Downsampled from (14005, 3) to (2903, 3) points (non-ground)\n",
      "Downsampled from (60816, 3) to (6369, 3) points (ground)\n",
      "Downsampled from (20432, 3) to (2492, 3) points (non-ground)\n",
      "Downsampled from (42933, 3) to (4350, 3) points (ground)\n",
      "6\n",
      "Start of sequence 0\n",
      "3162 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.2668311595916748  s\n",
      "There are 41 cut regions\n",
      "NCuts took  4.3257811069488525  s\n",
      "Ratio of points in top 3 groups: 0.31846932321315624\n",
      "Dino load  4.744314670562744  s\n",
      "Ncuts percentage  91.0\n",
      "Construction  6.0\n",
      "labels [ 0  4  9 11 12 13 14 18 22 23 24 25 26 28 34 37 42 45 46 56 65 77 82 88\n",
      " 92 94]\n",
      "write instance chunk\n",
      "Start of sequence 1\n",
      "873 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.015229463577270508  s\n",
      "There are 40 cut regions\n",
      "NCuts took  0.9206597805023193  s\n",
      "Ratio of points in top 3 groups: 0.2898052691867125\n",
      "Dino load  0.998539924621582  s\n",
      "Ncuts percentage  92.0\n",
      "Construction  2.0\n",
      "labels [  0  28  34  42  61  76  81  84  93 110 129]\n",
      "write instance chunk\n",
      "Start of sequence 2\n",
      "3059 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.257244348526001  s\n",
      "There are 29 cut regions\n",
      "NCuts took  3.5629384517669678  s\n",
      "Ratio of points in top 3 groups: 0.528604118993135\n",
      "Dino load  3.955711841583252  s\n",
      "Ncuts percentage  90.0\n",
      "Construction  7.000000000000001\n",
      "labels [  0 100 115 118 131 133 136 138 139 144 145 149 150 151 152 154 159 163\n",
      " 174]\n",
      "write instance chunk\n",
      "Start of sequence 3\n",
      "4363 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.6615946292877197  s\n",
      "There are 27 cut regions\n",
      "NCuts took  4.463144063949585  s\n",
      "Ratio of points in top 3 groups: 0.3719917487966995\n",
      "Dino load  5.2538347244262695  s\n",
      "Ncuts percentage  85.0\n",
      "Construction  13.0\n",
      "labels [  0  74 124 133 140 142 146 151 152 153 155 157 160 161 163 164 165 167\n",
      " 168 169 170 171 172 173 174 175 176 178 179 181 182 187 191]\n",
      "write instance chunk\n",
      "Start of sequence 4\n",
      "2903 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.22470617294311523  s\n",
      "There are 43 cut regions\n",
      "NCuts took  3.2683117389678955  s\n",
      "Ratio of points in top 3 groups: 0.27454357561143644\n",
      "Dino load  3.5847604274749756  s\n",
      "Ncuts percentage  91.0\n",
      "Construction  6.0\n",
      "labels [  0 146 172 173 184 186 188 191 194 196 207 209]\n",
      "write instance chunk\n",
      "Start of sequence 5\n",
      "2492 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.15840721130371094  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4/85 [06:04<1:55:31, 85.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35 cut regions\n",
      "NCuts took  2.152585029602051  s\n",
      "Ratio of points in top 3 groups: 0.5481540930979133\n",
      "Dino load  2.4134745597839355  s\n",
      "Ncuts percentage  89.0\n",
      "Construction  7.000000000000001\n",
      "labels [  0 123 186 188 190 193 196 207 209]\n",
      "write instance chunk\n",
      "current sequence 4\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "34149 panoptic,\n",
      "Done loading in 29.387 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.6 seconds.\n",
      "======\n",
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:02<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1416.52it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1551.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (36096, 3) to (4374, 3) points (non-ground)\n",
      "Downsampled from (83723, 3) to (5310, 3) points (ground)\n",
      "Downsampled from (65678, 3) to (8559, 3) points (non-ground)\n",
      "Downsampled from (80238, 3) to (5256, 3) points (ground)\n",
      "Downsampled from (134343, 3) to (7670, 3) points (non-ground)\n",
      "Downsampled from (75163, 3) to (4582, 3) points (ground)\n",
      "3\n",
      "Start of sequence 0\n",
      "4374 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  0.48395514488220215  s\n",
      "There are 49 cut regions\n",
      "NCuts took  12.92922592163086  s\n",
      "Ratio of points in top 3 groups: 0.3637402834933699\n",
      "Dino load  13.596349239349365  s\n",
      "Ncuts percentage  95.0\n",
      "Construction  4.0\n",
      "labels [0]\n",
      "write instance chunk\n",
      "Start of sequence 1\n",
      "8559 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  2.3150711059570312  s\n",
      "There are 50 cut regions\n",
      "NCuts took  36.73370718955994  s\n",
      "Ratio of points in top 3 groups: 0.32094870896132727\n",
      "Dino load  39.472909688949585  s\n",
      "Ncuts percentage  93.0\n",
      "Construction  6.0\n",
      "labels [ 0 16 17 19 20 21 22 23 24 26 28 29 31 35]\n",
      "write instance chunk\n",
      "Start of sequence 2\n",
      "7670 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  1.615454912185669  s\n",
      "There are 33 cut regions\n",
      "NCuts took  14.90977931022644  s\n",
      "Ratio of points in top 3 groups: 0.29178617992177314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5/85 [08:18<2:17:27, 103.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dino load  17.027214765548706  s\n",
      "Ncuts percentage  88.0\n",
      "Construction  9.0\n",
      "labels [ 0 13 18 25 26 27 29 30 32 33 34 37 38 39 40 41 42 44 45 46 47 48 49 50\n",
      " 52 53 54 55 57 58 61]\n",
      "write instance chunk\n",
      "current sequence 5\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "34149 panoptic,\n",
      "Done loading in 25.476 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.3 seconds.\n",
      "======\n",
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:09<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done downsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2347.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2595.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (42482, 3) to (8964, 3) points (non-ground)\n",
      "Downsampled from (68355, 3) to (9965, 3) points (ground)\n",
      "Downsampled from (68513, 3) to (11543, 3) points (non-ground)\n",
      "Downsampled from (102851, 3) to (10663, 3) points (ground)\n",
      "Downsampled from (100210, 3) to (13266, 3) points (non-ground)\n",
      "Downsampled from (121556, 3) to (11702, 3) points (ground)\n",
      "Downsampled from (30596, 3) to (3235, 3) points (non-ground)\n",
      "Downsampled from (116756, 3) to (8429, 3) points (ground)\n",
      "4\n",
      "Start of sequence 0\n",
      "8964 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  2.481574773788452  s\n",
      "There are 55 cut regions\n",
      "NCuts took  22.686243057250977  s\n",
      "Ratio of points in top 3 groups: 0.34381972333779565\n",
      "Dino load  25.37269687652588  s\n",
      "Ncuts percentage  89.0\n",
      "Construction  10.0\n",
      "labels [ 0  3  4 10 21 23 29 30 40 41 45 49 54 62]\n",
      "write instance chunk\n",
      "Start of sequence 1\n",
      "11543 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  3.8213717937469482  s\n",
      "There are 62 cut regions\n",
      "NCuts took  69.79376888275146  s\n",
      "Ratio of points in top 3 groups: 0.33587455600797017\n",
      "Dino load  73.94576859474182  s\n",
      "Ncuts percentage  94.0\n",
      "Construction  5.0\n",
      "labels [ 0  6 23 32 42 47 57 60 63 64 65 66 68 69 76]\n",
      "write instance chunk\n",
      "Start of sequence 2\n",
      "13266 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  5.501819133758545  s\n"
     ]
    }
   ],
   "source": [
    "#DATASET_PATH = '/media/cedric/Datasets1/nuScenes_mini_v2/nuScenes'\n",
    "DATASET_PATH = '/media/cedric/Datasets1/nuScenes_train'\n",
    "\n",
    "\n",
    "dist_threshold = 5 #moving object filter threshold \n",
    "dataset_type = 'v1.0-trainval'\n",
    "\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False \n",
    "out_folder_ncuts = 'test_data/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "out_folder = 'pcd_preprocessed_nuscenes/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "out_dbscan = f'{out_folder}out_nuscenes_dbscan/'\n",
    "map_out_pred = f'{out_folder}out_nuscenes_dbscan/maps/'\n",
    "\n",
    "if os.path.exists(map_out_pred) == False : \n",
    "                os.makedirs(map_out_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_nuscenes_instances = f'{out_folder}out_nuscenes_instance/'\n",
    "map_out_instances = f'{out_folder}out_nuscenes_instance/maps/'\n",
    "\n",
    "alpha = 1.0\n",
    "theta = 0.0\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "T = 0.05\n",
    "seqs = list(range(0,85)) ##currently downloaded up to 95 range \n",
    "\n",
    "all_instances = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors = generate_random_colors_map(600,0)\n",
    "for SEQUENCE_NUM in tqdm(seqs) : \n",
    "        print('current sequence',SEQUENCE_NUM)\n",
    "        dataset = create_nuscenes_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True, sam_folder_name=\"SAM\", \n",
    "                        dinov2_folder_name=\"Dinov2\",dist_threshold=dist_threshold,dataset_type=dataset_type)\n",
    "        \n",
    "        ind_start = 0\n",
    "        ind_end = len(dataset)  \n",
    "                        \n",
    "        #if os.path.exists(f'{out_folder}all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)\n",
    "        \n",
    "        \n",
    "        #if os.path.exists(f'{out_folder}pcd_ground_minor' + str(SEQUENCE_NUM) + '.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}nuscenes_labels_preprocessed.npz',\n",
    "                                                instance_nonground= labels['instance_nonground'],\n",
    "                                                instance_ground= labels['instance_ground'],\n",
    "                                                seg_ground = labels['seg_ground'],\n",
    "                                                seg_nonground= labels['seg_nonground']\n",
    "                                                )\n",
    "        \n",
    "        \n",
    "        pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor.pcd')\n",
    "        pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor.pcd')\n",
    "        \n",
    "        nuscenes_labels_orig = {}\n",
    "        with np.load(f'{out_folder}nuscenes_labels_preprocessed.npz') as data :\n",
    "                nuscenes_labels_orig['instance_ground'] = data['instance_ground']\n",
    "                nuscenes_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "                nuscenes_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "                nuscenes_labels_orig['seg_ground'] = data['seg_ground']\n",
    "        \n",
    "                \n",
    "        \n",
    "        with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "                all_poses = data['all_poses']\n",
    "                T_pcd = data['T_pcd']\n",
    "                first_position = T_pcd[:3, 3]\n",
    "        \n",
    "        \n",
    "        pcd_new = o3d.geometry.PointCloud()\n",
    "        pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points))\n",
    "        \n",
    "        map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                        nuscenes_labels_orig['instance_nonground'].reshape(-1,1))\n",
    "        \n",
    "        #o3d.visualization.draw_geometries([map_labelled])\n",
    "        \n",
    "        poses, positions, \\\n",
    "        sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)\n",
    "        \n",
    "        pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "        pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "        indices,indices_ground, center_positions, \\\n",
    "        center_ids, chunk_bounds, nuscenes_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                                    first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                                    overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=nuscenes_labels_orig)\n",
    "                                                                    \n",
    "                                                                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        cams = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\"]\n",
    "        cam_ids = [0]\n",
    "        \n",
    "        #out_dbscan = 'out_dbscan/'\n",
    "        #if os.path.exists(out_dbscan) == True : \n",
    "        #        shutil.rmtree(out_dbscan)\n",
    "        out_dbscan_cur = out_dbscan + str(SEQUENCE_NUM) + '/'\n",
    "        if os.path.exists(out_dbscan_cur) == True : \n",
    "                shutil.rmtree(out_dbscan_cur)\n",
    "        os.makedirs(out_dbscan_cur)\n",
    "        \n",
    "        \n",
    "        \n",
    "        instances = np.hstack((nuscenes_labels_orig['instance_nonground'].reshape(-1,),nuscenes_labels_orig['instance_ground'].reshape(-1,)))\n",
    "        \n",
    "        patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "        out_data = []\n",
    "        print(len(center_ids))\n",
    "        for sequence in range(len(center_ids)):\n",
    "                        obstacle_chunk, ground_chunk, in_idcs = clustering_logic(pcd_nonground_chunks[sequence],pcd_ground_chunks[sequence],\n",
    "                        eps=0.4, min_samples=10,method='dbscan')\n",
    "                \n",
    "                        #kitti_chunk_instance = color_pcd_by_labels(obstacle_chunk,kitti_labels['nonground']['instance'][sequence][in_idcs].reshape(-1,),\n",
    "                        \n",
    "                        #o3d.visualization.draw_geometries([obstacle_chunk + ground_chunk])\n",
    "                        #print(kitti_chunk_instance,obstacle_chunk)\n",
    "                        \n",
    "                        name =  str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                        \n",
    "                        o3d.io.write_point_cloud(out_dbscan_cur + name, obstacle_chunk + ground_chunk, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = generate_random_colors_map(400,0)\n",
    "\n",
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                        \n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dbscan = 'out_dbscan/'\n",
    "\n",
    "for i in seqs: \n",
    "    print('cur seq',i)\n",
    "    out_instance_cur = out_nuscenes_instances + str(i) + '/'\n",
    "    out_dbscan_cur = out_dbscan + str(i) + '/'\n",
    "    \n",
    "    point_clouds = get_merge_pcds(out_dbscan_cur)\n",
    "    merge = merge_chunks_unite_instances(point_clouds)\n",
    "    \n",
    "    point_clouds_nuscenes_instances = get_merge_pcds(out_instance_cur)\n",
    "    merge_nuscenes_instance = merge_unite_gt(point_clouds_nuscenes_instances)\n",
    "    #o3d.visualization.draw_geometries([merge_nuscenes_instance])\n",
    "    unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "    unique_colors, labels_nuscenes = np.unique(np.asarray(merge_nuscenes_instance.colors),axis=0, return_inverse=True)\n",
    "        \n",
    "    pred_instance = remove_semantics(labels_nuscenes,labels_ncuts)\n",
    "    \n",
    "    o3d.io.write_point_cloud(map_out_instances + \"merge_part_nuscenes_instance\" + str(i)  + \".pcd\", merge_nuscenes_instance, write_ascii=False, compressed=False, print_progress=False)\n",
    "    o3d.io.write_point_cloud(map_out_pred + \"merge_part_nuscenes_ncuts\" + str(i)  + \".pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "    o3d.io.write_point_cloud(map_out_pred + \"merge_part_nuscenes_ncuts_instances_\" + str(i)  + \".pcd\", color_pcd_by_labels(merge,pred_instance), write_ascii=False, compressed=False, print_progress=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_pcd_pred = o3d.geometry.PointCloud()\n",
    "merge_pcd_instance = o3d.geometry.PointCloud()\n",
    "merge_instances_only = o3d.geometry.PointCloud()\n",
    "\n",
    "for i in seqs : \n",
    "\tmerge_pcd_pred +=  o3d.io.read_point_cloud(map_out_pred + \"merge_part_nuscenes_ncuts\" + str(i)  + \".pcd\")\n",
    "\tcur_gt = o3d.io.read_point_cloud(map_out_instances + \"merge_part_nuscenes_instance\" + str(i)  + \".pcd\")\n",
    "\tmerge_pcd_instance += cur_gt\n",
    "\tmerge_instances_only += o3d.io.read_point_cloud(map_out_pred + \"merge_part_nuscenes_ncuts_instances_\" + str(i)  + \".pcd\")\n",
    "\t\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge_pcd_pred.colors), axis=0, return_inverse=True)\n",
    "#unique_colors, labels_dbscan = np.unique(np.asarray(merge_dbscan.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_nuscenes = np.unique(np.asarray(merge_pcd_instance.colors),axis=0, return_inverse=True)\n",
    "\n",
    "\n",
    "#new_ncuts_labels = remove_semantics(labels_nuscenes,labels_ncuts)\n",
    "unique_colors, new_ncuts_labels = np.unique(np.asarray(merge_instances_only.colors), axis=0, return_inverse=True)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='dbscan')\n",
    "metrics_ncuts.min_points = 50\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,new_ncuts_labels,labels_nuscenes)\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
