{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset_utils import create_nuscenes_odometry_dataset\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_unite_gt, remove_semantics, merge_chunks_unite_instances2\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import KDTree\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils.UIS.utils import *\n",
    "from utils.UIS.minkunet import *\n",
    "from utils.UIS.collations import *\n",
    "from utils.UIS.corr_utils import *\n",
    "from utils.UIS.pcd_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN\n",
    "import hdbscan\n",
    "import yaml \n",
    "import scipy \n",
    "\n",
    "config = 'utils/UIS/instance_seg.yaml'\n",
    "cfg = yaml.safe_load(open(config))\n",
    "params = cfg\n",
    "\n",
    "set_deterministic()\n",
    "model = MinkUNet(in_channels=4, out_channels=96).type(torch.FloatTensor)\n",
    "#checkpoint = torch.load(cfg['model']['checkpoint'], map_location=torch.device('cuda'))\n",
    "checkpoint = torch.load('utils/UIS/epoch199_model_segcontrast.pt', map_location=torch.device('cuda'))\n",
    "model.cuda()\n",
    "#model.load_state_dict(checkpoint[cfg['model']['checkpoint_key']])\n",
    "model.load_state_dict(checkpoint[cfg['model']['checkpoint_key']])\n",
    "model.dropout = nn.Identity()\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "        param.require_grads = False\n",
    "\n",
    "\n",
    "def uniform_down_sample_with_indices(points, every_k_points):\n",
    "        # Create a new point cloud for the downsampled output\n",
    "\n",
    "        # List to hold the indices of the points that are kept\n",
    "        indices = []\n",
    "\n",
    "        # Iterate over the points and keep every k-th point\n",
    "        for i in range(0, points.shape[0], every_k_points):\n",
    "            indices.append(i)\n",
    "\n",
    "        return indices\n",
    "\n",
    "def downsample_chunk(points):\n",
    "        num_points_to_sample = 30000\n",
    "        every_k_points = int(\n",
    "            points.shape[0] /\n",
    "            num_points_to_sample)\n",
    "        indeces = uniform_down_sample_with_indices(\n",
    "            points, every_k_points)\n",
    "\n",
    "\n",
    "        return points[indeces]\n",
    "        \n",
    "def segcontrast_preprocessing(p,sem_labels,resolution=0.05,num_points='inf'):\n",
    "    coord_p, feats_p, cluster_p = point_set_to_coord_feats(p, sem_labels, resolution, num_points)\n",
    "    return coord_p, feats_p, cluster_p\n",
    "\n",
    "\n",
    "def UIS3D_clustering(pcd_nonground_chunk, pcd_ground_chunk,center_id,center_position,\n",
    "                        eps=0.3, min_samples=10,tarl=False):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on the point cloud data.\n",
    "\n",
    "    :param cur_pcd: Current point cloud for clustering.\n",
    "    :param pcd_all: All point cloud data.\n",
    "    :param eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "    :param min_samples: The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "    :return: Cluster labels for each point in the point cloud.\n",
    "    \"\"\"\n",
    "    \n",
    "    inliers = get_statistical_inlier_indices(pcd_ground_chunk)\n",
    "    ground_inliers = get_subpcd(pcd_ground_chunk, inliers)\n",
    "    mean_hight = np.mean(np.asarray(ground_inliers.points)[:,2])\n",
    "    in_idcs = np.where(np.asarray(ground_inliers.points)[:,2] < (mean_hight + 0.2))[0]\n",
    "    cut_hight = get_subpcd(ground_inliers, in_idcs)\n",
    "    cut_hight.paint_uniform_color([0, 0, 0])\n",
    "    \n",
    "    in_idcs = None\n",
    "    \n",
    "    #in_idcs = np.where(np.asarray(pcd_nonground_chunk.points)[:,2] > (mean_hight + 0.05))[0]\n",
    "    #pcd_nonground_corrected = get_subpcd(pcd_nonground_chunk, in_idcs)\n",
    "    pcd_nonground_corrected = pcd_nonground_chunk\n",
    "    \n",
    "    merge_orig = pcd_nonground_corrected + cut_hight\n",
    "    \n",
    "    pcd_nonground_downsampled = o3d.geometry.PointCloud()\n",
    "    pts_downsampled = downsample_chunk(np.asarray(pcd_nonground_corrected.points))\n",
    "    pcd_nonground_downsampled.points = o3d.utility.Vector3dVector(pts_downsampled)\n",
    "    \n",
    "    ground_downsampled = o3d.geometry.PointCloud()\n",
    "    pts_downsampled_ground = downsample_chunk(np.asarray(cut_hight.points))\n",
    "    ground_downsampled.points = o3d.utility.Vector3dVector(pts_downsampled_ground)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #clustering = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    #clustering = HDBSCAN(min_cluster_size=10).fit(pts_downsampled)\n",
    "    clustering = hdbscan.HDBSCAN(algorithm='best', alpha=1., approx_min_span_tree=True,\n",
    "                                gen_min_span_tree=True, leaf_size=100,\n",
    "                                metric='euclidean', min_cluster_size=10, min_samples=None\n",
    "                            )\n",
    "    clustering.fit(pts_downsampled)\n",
    "    \n",
    "    \n",
    "    merged_chunk = pcd_nonground_downsampled + ground_downsampled\n",
    "    \n",
    "    labels_nonground = clustering.labels_.reshape(-1,1) + 2\n",
    "    points = np.asarray(merged_chunk.points)\n",
    "    labels = np.ones((points.shape[0], 1)) * -1\n",
    "    \n",
    "    ground_labels = np.zeros(points.shape[0]) * -1\n",
    "    non_ground_size = np.asarray(pcd_nonground_downsampled.points).shape[0]\n",
    "    ground_labels[:non_ground_size] = 1\n",
    "    labels[:non_ground_size] = labels_nonground\n",
    "    pcd_cur = color_pcd_by_labels(merged_chunk,labels)\n",
    "    #o3d.visualization.draw_geometries([pcd_cur])\n",
    "    ins, num_pts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    mask = np.ones(labels.shape[0], dtype=bool)\n",
    "    mask[non_ground_size:] = False\n",
    "    points = np.concatenate((points,np.ones((points.shape[0],1))),1)\n",
    "    mean_x = points[:,0].mean() \n",
    "    mean_y = points[:,1].mean() \n",
    "    mean_z = points[:,2].mean() \n",
    "    \n",
    "    points[:,0] -= mean_x\n",
    "    points[:,1] -= mean_y\n",
    "    points[:,2] -= mean_z\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###local features from tarl : note can not be used as network saliency is needed \n",
    " \n",
    "    coord_p,feats_p,cluster_p = segcontrast_preprocessing(points,labels)\n",
    "    \n",
    "    slc_full = np.zeros((points.shape[0],), dtype=int)\n",
    "    pred_ins_full = np.zeros((points.shape[0],), dtype=int)\n",
    "    for cluster in ins: \n",
    "            cls_points = np.where(cluster_p == cluster)[0]\n",
    "            \n",
    "            if cluster == 0 or len(cls_points) <= 100:\n",
    "                continue\n",
    "            # get cluster\n",
    "            cluster_center = coord_p[cls_points].mean(axis=0)\n",
    "\n",
    "            # crop a ROI around the cluster\n",
    "            window_points = crop_region(coord_p,cluster_p, cluster, 20)\n",
    "\n",
    "            # skip when ROI is empty        \n",
    "            if not np.sum(window_points):\n",
    "                continue\n",
    "\n",
    "            # get closest point to the center\n",
    "            center_dists = np.sqrt(np.sum((coord_p[window_points] - cluster_center)**2, axis=-1))\n",
    "            cluster_center = np.argmin(center_dists)\n",
    "\n",
    "            # build input only with the ROI points\n",
    "            x_forward = numpy_to_sparse_tensor(coord_p[window_points][np.newaxis, :, :], feats_p[window_points][np.newaxis, :, :])\n",
    "            \n",
    "            # forward pass ROI \n",
    "            model.eval()\n",
    "            x_forward.F.requires_grad = True\n",
    "            out = model(x_forward.sparse())\n",
    "            out = out.slice(x_forward)\n",
    "\n",
    "            # reset grads to compute saliency\n",
    "            x_forward.F.grad = None\n",
    "\n",
    "            # compute saliency for the point in the center\n",
    "            slc = get_cluster_saliency(x_forward, out, np.where(cluster_p[window_points] == cluster)[0])\n",
    "            slc_ = slc.copy()\n",
    "\n",
    "            # place the computed saliency into the full point cloud for comparison\n",
    "            slc_full[window_points] = np.maximum(slc_full[window_points], slc)\n",
    "\n",
    "            # build graph representation\n",
    "            G = build_graph(out.F.detach().cpu().numpy(),\n",
    "                            slc[:,np.newaxis],\n",
    "                            coord_p[window_points],\n",
    "                            cluster_center,\n",
    "                            np.sum(cluster_p == cluster),\n",
    "                            params,\n",
    "                            ground_labels[window_points],\n",
    "                            np.where(cluster_p[window_points] == cluster)[0],\n",
    "                        )\n",
    "            # perform graph cut\n",
    "            #G = scipy.sparse.csr_matrix(G) -> try out this line \n",
    "            ins_points = graph_cut(G)\n",
    "            # create point-wise prediction matrix\n",
    "            pred_ins = np.zeros((len(x_forward),)).astype(int)\n",
    "            if len(ins_points) != 0:\n",
    "                pred_ins[ins_points] = cluster\n",
    "            \n",
    "            # ignore assigned ground labels\n",
    "            ins_ground = ground_labels[window_points] == -1\n",
    "            pred_ins[ins_ground] = 0\n",
    "\n",
    "            pred_ins_full[window_points] = np.maximum(pred_ins_full[window_points], pred_ins)\n",
    "        \n",
    "    #pcd_cur = color_pcd_by_labels(merged_chunk,pred_ins_full)\n",
    "    #o3d.visualization.draw_geometries([pcd_cur])\n",
    "    \n",
    "    colors_gen = generate_random_colors(500)\n",
    "    \n",
    "    # Reproject cluster labels to the original point cloud size\n",
    "    cluster_labels = np.ones((len(merge_orig.points), 1)) * -1\n",
    "    labels_orig = kDTree_1NN_feature_reprojection(cluster_labels, merge_orig, pred_ins_full.reshape(-1,1), merged_chunk)\n",
    "    colors = np.zeros((labels_orig.shape[0],3))\n",
    "    unique_labels = list(np.unique(labels_orig))\n",
    "    \n",
    "    for j in unique_labels:\n",
    "            cur_idcs = np.where(labels_orig == j)[0]\n",
    "            if j == 0 : \n",
    "                colors[cur_idcs] = np.array([0,0,0])\n",
    "                \n",
    "            else : \n",
    "                colors[cur_idcs] = np.array(colors_gen[unique_labels.index(j)])\n",
    "                \n",
    "        \n",
    "    merge_orig.colors = o3d.utility.Vector3dVector(colors / 255.)\n",
    "    \n",
    "    return merge_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on nuscenes sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET_PATH = '/media/cedric/Datasets1/nuScenes_mini_v2/nuScenes'\n",
    "DATASET_PATH = '/media/cedric/Datasets1/nuScenes_train'\n",
    "\n",
    "\n",
    "dist_threshold = 5 #moving object filter threshold \n",
    "dataset_type = 'v1.0-trainval'\n",
    "\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False \n",
    "out_folder_ncuts = 'test_data/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "out_folder = 'pcd_preprocessed_nuscenes/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "out_3duis = f'{out_folder}out_nuscenes_3duis/'\n",
    "map_out_pred = f'{out_folder}out_nuscenes_3duis/maps/'\n",
    "\n",
    "if os.path.exists(map_out_pred) == False : \n",
    "                os.makedirs(map_out_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_nuscenes_instances = f'{out_folder}out_nuscenes_instance/'\n",
    "map_out_instances = f'{out_folder}out_nuscenes_instance/maps/'\n",
    "\n",
    "alpha = 1.0\n",
    "theta = 0.0\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "T = 0.05\n",
    "seqs = list(range(0,85)) ##currently downloaded up to 95 range \n",
    "\n",
    "all_instances = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors = generate_random_colors_map(600,0)\n",
    "for SEQUENCE_NUM in tqdm(seqs) : \n",
    "        print('current sequence',SEQUENCE_NUM)\n",
    "        dataset = create_nuscenes_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True, sam_folder_name=\"SAM\", \n",
    "                        dinov2_folder_name=\"Dinov2\",dist_threshold=dist_threshold,dataset_type=dataset_type)\n",
    "        \n",
    "        ind_start = 0\n",
    "        ind_end = len(dataset)  \n",
    "                        \n",
    "        #if os.path.exists(f'{out_folder}all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)\n",
    "        \n",
    "        \n",
    "        #if os.path.exists(f'{out_folder}pcd_ground_minor' + str(SEQUENCE_NUM) + '.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}nuscenes_labels_preprocessed.npz',\n",
    "                                                instance_nonground= labels['instance_nonground'],\n",
    "                                                instance_ground= labels['instance_ground'],\n",
    "                                                seg_ground = labels['seg_ground'],\n",
    "                                                seg_nonground= labels['seg_nonground']\n",
    "                                                )\n",
    "        \n",
    "        \n",
    "        pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor.pcd')\n",
    "        pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor.pcd')\n",
    "        \n",
    "        nuscenes_labels_orig = {}\n",
    "        with np.load(f'{out_folder}nuscenes_labels_preprocessed.npz') as data :\n",
    "                nuscenes_labels_orig['instance_ground'] = data['instance_ground']\n",
    "                nuscenes_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "                nuscenes_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "                nuscenes_labels_orig['seg_ground'] = data['seg_ground']\n",
    "        \n",
    "                \n",
    "        \n",
    "        with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "                all_poses = data['all_poses']\n",
    "                T_pcd = data['T_pcd']\n",
    "                first_position = T_pcd[:3, 3]\n",
    "        \n",
    "        \n",
    "        pcd_new = o3d.geometry.PointCloud()\n",
    "        pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points))\n",
    "        \n",
    "        map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                        nuscenes_labels_orig['instance_nonground'].reshape(-1,1))\n",
    "        \n",
    "        #o3d.visualization.draw_geometries([map_labelled])\n",
    "        \n",
    "        poses, positions, \\\n",
    "        sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)\n",
    "        \n",
    "        pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "        pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "        indices,indices_ground, center_positions, \\\n",
    "        center_ids, chunk_bounds, nuscenes_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                                    first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                                    overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=nuscenes_labels_orig)\n",
    "                                                                    \n",
    "                                                                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        cams = [\"CAM_FRONT\", \"CAM_FRONT_LEFT\", \"CAM_FRONT_RIGHT\"]\n",
    "        cam_ids = [0]\n",
    "        \n",
    "        #out_dbscan = 'out_dbscan/'\n",
    "        #if os.path.exists(out_dbscan) == True : \n",
    "        #        shutil.rmtree(out_dbscan)\n",
    "        out_3duis_cur = out_3duis + str(SEQUENCE_NUM) + '/'\n",
    "        if os.path.exists(out_3duis_cur) == True : \n",
    "                shutil.rmtree(out_3duis_cur)\n",
    "        os.makedirs(out_3duis_cur)\n",
    "        \n",
    "        \n",
    "        \n",
    "        instances = np.hstack((nuscenes_labels_orig['instance_nonground'].reshape(-1,),nuscenes_labels_orig['instance_ground'].reshape(-1,)))\n",
    "        \n",
    "        patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "        out_data = []\n",
    "        print(len(center_ids))\n",
    "        for sequence in range(len(center_ids)):\n",
    "                        pcd_3duis = UIS3D_clustering(pcd_nonground_chunks[sequence],pcd_ground_chunks[sequence],center_ids[sequence],\n",
    "                        center_positions[sequence],\n",
    "                        eps=0.4, min_samples=10)\n",
    "                \n",
    "                        #kitti_chunk_instance = color_pcd_by_labels(obstacle_chunk,kitti_labels['nonground']['instance'][sequence][in_idcs].reshape(-1,),\n",
    "                        \n",
    "                        #o3d.visualization.draw_geometries([obstacle_chunk + ground_chunk])\n",
    "                        #print(kitti_chunk_instance,obstacle_chunk)\n",
    "                        \n",
    "                        name =  str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                        \n",
    "                        o3d.io.write_point_cloud(out_3duis_cur + name, pcd_3duis, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = generate_random_colors_map(400,0)\n",
    "\n",
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                        \n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dbscan = 'out_dbscan/'\n",
    "\n",
    "for i in seqs: \n",
    "    print('cur seq',i)\n",
    "    out_instance_cur = out_nuscenes_instances + str(i) + '/'\n",
    "    out_3duis_cur = out_3duis + str(i) + '/'\n",
    "    \n",
    "    point_clouds = get_merge_pcds(out_3duis_cur)\n",
    "    merge = merge_chunks_unite_instances(point_clouds)\n",
    "    \n",
    "    point_clouds_nuscenes_instances = get_merge_pcds(out_instance_cur)\n",
    "    merge_nuscenes_instance = merge_unite_gt(point_clouds_nuscenes_instances)\n",
    "    #o3d.visualization.draw_geometries([merge_nuscenes_instance])\n",
    "    unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "    unique_colors, labels_nuscenes = np.unique(np.asarray(merge_nuscenes_instance.colors),axis=0, return_inverse=True)\n",
    "        \n",
    "    pred_instance = remove_semantics(labels_nuscenes,labels_ncuts)\n",
    "    \n",
    "    o3d.io.write_point_cloud(map_out_instances + \"merge_part_nuscenes_instance\" + str(i)  + \".pcd\", merge_nuscenes_instance, write_ascii=False, compressed=False, print_progress=False)\n",
    "    o3d.io.write_point_cloud(map_out_pred + \"merge_part_nuscenes_3duis\" + str(i)  + \".pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "    o3d.io.write_point_cloud(map_out_pred + \"merge_part_nuscenes_3duis_instances_\" + str(i)  + \".pcd\", color_pcd_by_labels(merge,pred_instance), write_ascii=False, compressed=False, print_progress=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_pcd_pred = o3d.geometry.PointCloud()\n",
    "merge_pcd_instance = o3d.geometry.PointCloud()\n",
    "merge_instances_only = o3d.geometry.PointCloud()\n",
    "\n",
    "for i in seqs : \n",
    "\tmerge_pcd_pred +=  o3d.io.read_point_cloud(map_out_pred + \"merge_part_nuscenes_3duis\" + str(i)  + \".pcd\")\n",
    "\tcur_gt = o3d.io.read_point_cloud(map_out_instances + \"merge_part_nuscenes_instance\" + str(i)  + \".pcd\")\n",
    "\tmerge_pcd_instance += cur_gt\n",
    "\tmerge_instances_only += o3d.io.read_point_cloud(map_out_pred + \"merge_part_nuscenes_3duis_instances_\" + str(i)  + \".pcd\")\n",
    "\t\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge_pcd_pred.colors), axis=0, return_inverse=True)\n",
    "#unique_colors, labels_dbscan = np.unique(np.asarray(merge_dbscan.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_nuscenes = np.unique(np.asarray(merge_pcd_instance.colors),axis=0, return_inverse=True)\n",
    "\n",
    "\n",
    "#new_ncuts_labels = remove_semantics(labels_nuscenes,labels_ncuts)\n",
    "unique_colors, new_ncuts_labels = np.unique(np.asarray(merge_instances_only.colors), axis=0, return_inverse=True)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='dbscan')\n",
    "metrics_ncuts.min_points = 50\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,new_ncuts_labels,labels_nuscenes)\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
