{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "ind_start = 0\n",
    "ind_end = 1100\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = 'pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_folder + 'all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz',\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 11580178 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "print(pcd_ground_minor)\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz') as data :\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npcd_new = o3d.geometry.PointCloud()\\npts_num = 1000000\\npcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\\n\\nmap_labelled = color_pcd_by_labels(pcd_new,                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\\n\\no3d.visualization.draw_geometries([map_labelled])\\n#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pts_num = 1000000\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses, positions, \\\n",
    "sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (541161, 3) to (7776, 3) points (non-ground)\n",
      "Downsampled from (243917, 3) to (5294, 3) points (ground)\n",
      "Downsampled from (454490, 3) to (7216, 3) points (non-ground)\n",
      "Downsampled from (262770, 3) to (4499, 3) points (ground)\n",
      "Downsampled from (479361, 3) to (7341, 3) points (non-ground)\n",
      "Downsampled from (304983, 3) to (6061, 3) points (ground)\n",
      "Downsampled from (479273, 3) to (6272, 3) points (non-ground)\n",
      "Downsampled from (246003, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (473079, 3) to (8385, 3) points (non-ground)\n",
      "Downsampled from (221993, 3) to (4446, 3) points (ground)\n",
      "Downsampled from (488393, 3) to (9063, 3) points (non-ground)\n",
      "Downsampled from (220415, 3) to (5078, 3) points (ground)\n",
      "Downsampled from (545707, 3) to (8986, 3) points (non-ground)\n",
      "Downsampled from (292301, 3) to (4209, 3) points (ground)\n",
      "Downsampled from (409731, 3) to (6703, 3) points (non-ground)\n",
      "Downsampled from (441195, 3) to (4976, 3) points (ground)\n",
      "Downsampled from (300320, 3) to (4742, 3) points (non-ground)\n",
      "Downsampled from (509260, 3) to (6199, 3) points (ground)\n",
      "Downsampled from (350224, 3) to (6187, 3) points (non-ground)\n",
      "Downsampled from (372916, 3) to (5525, 3) points (ground)\n",
      "Downsampled from (452246, 3) to (7807, 3) points (non-ground)\n",
      "Downsampled from (385946, 3) to (5562, 3) points (ground)\n",
      "Downsampled from (262978, 3) to (4456, 3) points (non-ground)\n",
      "Downsampled from (451230, 3) to (6189, 3) points (ground)\n",
      "Downsampled from (260853, 3) to (4469, 3) points (non-ground)\n",
      "Downsampled from (540630, 3) to (6637, 3) points (ground)\n",
      "Downsampled from (477380, 3) to (7261, 3) points (non-ground)\n",
      "Downsampled from (438394, 3) to (6594, 3) points (ground)\n",
      "Downsampled from (484851, 3) to (7762, 3) points (non-ground)\n",
      "Downsampled from (389528, 3) to (6532, 3) points (ground)\n",
      "Downsampled from (406142, 3) to (6391, 3) points (non-ground)\n",
      "Downsampled from (339234, 3) to (5270, 3) points (ground)\n",
      "Downsampled from (322094, 3) to (5849, 3) points (non-ground)\n",
      "Downsampled from (273519, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (383759, 3) to (6583, 3) points (non-ground)\n",
      "Downsampled from (196088, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (471693, 3) to (7780, 3) points (non-ground)\n",
      "Downsampled from (309908, 3) to (6091, 3) points (ground)\n",
      "Downsampled from (570103, 3) to (5949, 3) points (non-ground)\n",
      "Downsampled from (939537, 3) to (9495, 3) points (ground)\n",
      "Downsampled from (567185, 3) to (7039, 3) points (non-ground)\n",
      "Downsampled from (480866, 3) to (7211, 3) points (ground)\n",
      "Downsampled from (324509, 3) to (5945, 3) points (non-ground)\n",
      "Downsampled from (214718, 3) to (4765, 3) points (ground)\n",
      "Downsampled from (296982, 3) to (5076, 3) points (non-ground)\n",
      "Downsampled from (295734, 3) to (5203, 3) points (ground)\n",
      "Downsampled from (311607, 3) to (5367, 3) points (non-ground)\n",
      "Downsampled from (283045, 3) to (4829, 3) points (ground)\n",
      "Downsampled from (336036, 3) to (5544, 3) points (non-ground)\n",
      "Downsampled from (254495, 3) to (4716, 3) points (ground)\n",
      "Downsampled from (351770, 3) to (5478, 3) points (non-ground)\n",
      "Downsampled from (493796, 3) to (6512, 3) points (ground)\n",
      "Downsampled from (333876, 3) to (5378, 3) points (non-ground)\n",
      "Downsampled from (579172, 3) to (6166, 3) points (ground)\n",
      "Downsampled from (576526, 3) to (8127, 3) points (non-ground)\n",
      "Downsampled from (359545, 3) to (6037, 3) points (ground)\n",
      "Downsampled from (796774, 3) to (9306, 3) points (non-ground)\n",
      "Downsampled from (383977, 3) to (6355, 3) points (ground)\n",
      "Downsampled from (790877, 3) to (8685, 3) points (non-ground)\n",
      "Downsampled from (627610, 3) to (6811, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def DBSCAN_clustering_logic(cur_pcd, pcd_all, eps=0.3, min_samples=10):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on the point cloud data.\n",
    "\n",
    "    :param cur_pcd: Current point cloud for clustering.\n",
    "    :param pcd_all: All point cloud data.\n",
    "    :param eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "    :param min_samples: The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "    :return: Cluster labels for each point in the point cloud.\n",
    "    \"\"\"\n",
    "    not_road_points = np.asarray(cur_pcd.points)\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(not_road_points)\n",
    "    #clustering = HDBSCAN(min_cluster_size=100).fit(not_road_points)\n",
    "    labels_not_road = clustering.labels_\n",
    "    colors_gen = generate_random_colors(500)\n",
    "    \n",
    "    # Reproject cluster labels to the original point cloud size\n",
    "    cluster_labels = np.ones((len(pcd_all.points), 1)) * -1\n",
    "    labels_non_ground = kDTree_1NN_feature_reprojection(cluster_labels, pcd_all, labels_not_road.reshape(-1,1), cur_pcd)\n",
    "    colors = np.zeros((labels_non_ground.shape[0],3))\n",
    "    unique_labels = list(np.unique(labels_non_ground))\n",
    "    for j in unique_labels:\n",
    "            cur_idcs = np.where(labels_non_ground == j)[0]\n",
    "            \n",
    "            colors[cur_idcs] = np.array(colors_gen[unique_labels.index(j)])\n",
    "    pcd_all.colors = o3d.utility.Vector3dVector(colors / 255.)\n",
    "    return pcd_all\n",
    "\n",
    "def dbscan_clustering(pcd_chunks_major_downsampled, pcds, center_ids,ground_clouds):\n",
    "    labels_clustering = []\n",
    "    for i in range(len(pcd_chunks_major_downsampled)):\n",
    "        cur_pcd = pcd_chunks_major_downsampled[i]\n",
    "        pcd_all = pcds[i]\n",
    "        ground_cloud = ground_clouds[i]\n",
    "        cluster_labels = DBSCAN_clustering_logic(cur_pcd, pcd_all)  # Implement your DBSCAN logic here\n",
    "        ground_labels = np.ones((np.asarray(ground_cloud.points).shape[0],1)) * -1\n",
    "        cluster_labels = np.concatenate((cluster_labels,ground_labels),0)\n",
    "        labels_clustering.append(cluster_labels)\n",
    "        \n",
    "    return labels_clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    background_color = np.array([0,0,0])\n",
    "\n",
    "\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "        #if labels[i] != (-1):\n",
    "        #    pcd_colored.colors[i] = np.array(colors[labels[i]]) / 255\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/ 255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of sequence 0\n",
      "7776 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 31 cut regions\n",
      "Ratio of points in top 3 groups: 0.6132973251028807\n",
      "Start of sequence 1\n",
      "7216 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 22 cut regions\n",
      "Ratio of points in top 3 groups: 0.8264966740576497\n",
      "Start of sequence 2\n",
      "7341 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 23 cut regions\n",
      "Ratio of points in top 3 groups: 0.7618853017300096\n",
      "Start of sequence 3\n",
      "6272 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 18 cut regions\n",
      "Ratio of points in top 3 groups: 0.7975127551020408\n",
      "Start of sequence 4\n",
      "8385 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 21 cut regions\n",
      "Ratio of points in top 3 groups: 0.7163983303518188\n",
      "Start of sequence 5\n",
      "9063 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 20 cut regions\n",
      "Ratio of points in top 3 groups: 0.5404391481849278\n",
      "Start of sequence 6\n",
      "8986 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 21 cut regions\n",
      "Ratio of points in top 3 groups: 0.8147117738704651\n",
      "Start of sequence 7\n",
      "6703 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.0\n",
    "theta = 1.0\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "ncuts_threshold = 0.01\n",
    "        \n",
    "\n",
    "\n",
    "out_kitti = out_chunks + 'out_kitti/'\n",
    "if os.path.exists(out_kitti) == True : \n",
    "        shutil.rmtree(out_kitti)\n",
    "\n",
    "os.makedirs(out_kitti)\n",
    "        \n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance/'\n",
    "if os.path.exists(out_kitti_instance) == True : \n",
    "        shutil.rmtree(out_kitti_instance)\n",
    "os.makedirs(out_kitti_instance)\n",
    "\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic/'\n",
    "if os.path.exists(out_kitti_semantic) == True : \n",
    "        shutil.rmtree(out_kitti_semantic)\n",
    "os.makedirs(out_kitti_semantic)\n",
    "\n",
    "limit = -1 ##use this for experiments to run limit chunks numberss\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "semantics = np.hstack((kitti_labels_orig['seg_nonground'],kitti_labels_orig['seg_ground']))\n",
    "\n",
    "instances = np.hstack((kitti_labels_orig['instance_nonground'],kitti_labels_orig['instance_ground']))\n",
    "                \n",
    "\n",
    "for sequence in range(len(center_ids)):\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold)\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                \n",
    "                \n",
    "                \n",
    "                file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                #o3d.io.write_point_cloud(file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                #pcd_dbscan = DBSCAN_clustering_logic(pcd_nonground_chunks_major_downsampling[sequence],\n",
    "                #                                pcd_nonground_chunks[sequence],\n",
    "                #                                eps=0.6, min_samples=10)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['semantic'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=semantics\n",
    "                                        )\n",
    "                \n",
    "                kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_semantic_ground = color_pcd_by_labels(pcd_chunk_ground,seg_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=semantics)\n",
    "                #o3d.visualization.draw_geometries([kitti_chunk_instance + kitti_chunk_instance_ground])\n",
    "                #o3d.visualization.draw_geometries([kitti_chunk + kitti_chunk_semantic_ground])\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "                #print(kitti_labels['ground']['semantic'][sequence].reshape(-1,).shape)\n",
    "                #print(kitti_labels_orig['seg_ground'].shape)\n",
    "                #print(kitti_chunk_semantic_ground)\n",
    "                \n",
    "                o3d.io.write_point_cloud(out_folder_ncuts + file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_semantic + file_name, kitti_chunk + kitti_chunk_semantic_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd', '000220.pcd', '000249.pcd', '000278.pcd', '000336.pcd', '000368.pcd', '000391.pcd', '000415.pcd', '000441.pcd', '000483.pcd', '000515.pcd', '000540.pcd', '000565.pcd', '000587.pcd', '000610.pcd', '000650.pcd', '000774.pcd', '000794.pcd', '000813.pcd', '000833.pcd', '000854.pcd', '000877.pcd', '000915.pcd', '000949.pcd', '000982.pcd', '001048.pcd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dbscan = out_chunks + 'out_dbscan/'\n",
    "out_kitti = out_chunks + 'out_kitti/'\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance/'\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic/'\n",
    "\n",
    "point_clouds = get_merge_pcds(out_folder_ncuts)[:-1]\n",
    "#point_clouds_kitti = get_merge_pcds(out_kitti)[:-1]\n",
    "#point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)\n",
    "#point_clouds_kitti_semantic = get_merge_pcds(out_kitti_semantic)[:-1]\n",
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "\n",
    "\n",
    "#merge_dbscan = merge_chunks_unite_instances(point_clouds_dbscan)\n",
    "\n",
    "#merge_kitti = merge_unite_gt(point_clouds_kitti)\n",
    "#merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "#merge_kitti_semantic = merge_unite_gt(point_clouds_kitti_semantic)\n",
    "\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_semantic7.pcd\", merge_kitti_semantic, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"tarl_spatial_test.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_instance7.pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noptional cell for loading stored files\\nimport open3d as o3d\\n\\nout_folder = 'pcd_preprocessed/'\\nmerge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\\nmerge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\\nmerge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\\nmerge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\\nmerge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\\n\\nprint(merge)\\nprint(merge_kitti)\\nprint(merge_exp2)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "optional cell for loading stored files\n",
    "import open3d as o3d\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "merge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\n",
    "merge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\n",
    "merge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\n",
    "merge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\n",
    "\n",
    "print(merge)\n",
    "print(merge_kitti)\n",
    "print(merge_exp2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for file ncuts\n",
      "{'panoptic': 0.6445567981103508, 'precision': 0.85, 'recall': 0.6296296296296297, 'fScore': 0.723404255319149, 'usr': 0.1125, 'osr': 0.009259259259259259, 'noise': 0.075, 'missed': 0.2037037037037037, 'mean': 0.8910049856231319}\n",
      "lstq value :  0.6125271870457567\n",
      "Average Precision @ 0.25 0.6345500434166992\n",
      "Average Precision @ 0.5 0.5227843433234283\n",
      "Average Precision @ 0.55 0.5015184590439679\n",
      "Average Precision @ 0.6 0.4672227293847144\n",
      "Average Precision @ 0.65 0.4390970624207204\n",
      "Average Precision @ 0.7 0.40320934245404133\n",
      "Average Precision @ 0.75 0.38019380860779267\n",
      "Average Precision @ 0.85 0.35179566937293477\n",
      "Average Precision @ 0.8 0.36140010442163195\n",
      "Average Precision @ 0.9 0.33701263870176507\n",
      "Average Precision @ 0.95 0.09224409028491193\n",
      "AP @ 0.25 63.455\n",
      "AP @ 0.5 52\n",
      "AP @ [0.5:0.95] 38.565\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metrics' object has no attribute 'compute_all_aps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m metrics_ncuts \u001b[39m=\u001b[39m Metrics(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mncuts\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor.ipynb#X25sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m metrics_ncuts\u001b[39m.\u001b[39mupdate_stats(new_ncuts_labels,labels_kitti)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m metrics_ncuts\u001b[39m.\u001b[39;49mcompute_all_aps()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out_refactor.ipynb#X25sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#o3d.visualization.draw_geometries([merge_vis])\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Metrics' object has no attribute 'compute_all_aps'"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance7.pcd')\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "def remove_semantics(labels,preds):\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "        return new_ncuts_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([merge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
