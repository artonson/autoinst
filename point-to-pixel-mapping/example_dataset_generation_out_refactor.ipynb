{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics_class import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/cedric/Datasets/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "ind_start = 0\n",
    "ind_end = 1100\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False \n",
    "out_folder_ncuts = 'test_data/'\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprocess_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\\n                              major_voxel_size=major_voxel_size,icp=False,\\n                              out_folder=out_folder,sequence_num=SEQUENCE_NUM,\\n                              ground_segmentation_method=ground_segmentation_method)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                              major_voxel_size=major_voxel_size,icp=False,\n",
    "                              out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                              ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npcd_ground_minor, pcd_nonground_minor,\\tall_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,                                                                     ground_mode=ground_segmentation_method)\\n \\no3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\\no3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\\nnp.savez(f'{out_folder}kitti_labels_preprocessed.npz',panoptic_nonground=kitti_labels['panoptic_nonground'],\\n                                        panoptic_ground=kitti_labels['panoptic_ground'],\\n                                        instance_nonground=kitti_labels['instance_nonground'],\\n                                        instance_ground=kitti_labels['instance_ground'],\\n                                        seg_ground = kitti_labels['seg_ground'],\\n                                        seg_nonground=kitti_labels['seg_nonground']\\n                                        )\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##load data if already stored \n",
    "\n",
    "'''\n",
    "pcd_ground_minor, pcd_nonground_minor,\\\n",
    "\tall_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                     ground_mode=ground_segmentation_method)\n",
    " \n",
    "o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "np.savez(f'{out_folder}kitti_labels_preprocessed.npz',panoptic_nonground=kitti_labels['panoptic_nonground'],\n",
    "                                        panoptic_ground=kitti_labels['panoptic_ground'],\n",
    "                                        instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                        instance_ground=kitti_labels['instance_ground'],\n",
    "                                        seg_ground = kitti_labels['seg_ground'],\n",
    "                                        seg_nonground=kitti_labels['seg_nonground']\n",
    "                                        )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor.pcd')\n",
    "\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed.npz') as data :\n",
    "        kitti_labels_orig['panoptic_ground'] = data['panoptic_ground']\n",
    "        kitti_labels_orig['panoptic_nonground'] = data['panoptic_nonground']\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npcd_new = o3d.geometry.PointCloud()\\npts_num = 1000000\\npcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\\n\\nmap_labelled = color_pcd_by_labels(pcd_new,                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\\n\\no3d.visualization.draw_geometries([map_labelled])\\n#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pts_num = 1000000\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses, positions, \\\n",
    "sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (523016, 3) to (7643, 3) points (non-ground)\n",
      "Downsampled from (257407, 3) to (5501, 3) points (ground)\n",
      "Downsampled from (392323, 3) to (6659, 3) points (non-ground)\n",
      "Downsampled from (273555, 3) to (4539, 3) points (ground)\n",
      "Downsampled from (429859, 3) to (7470, 3) points (non-ground)\n",
      "Downsampled from (291612, 3) to (6157, 3) points (ground)\n",
      "Downsampled from (381642, 3) to (5813, 3) points (non-ground)\n",
      "Downsampled from (255212, 3) to (4655, 3) points (ground)\n",
      "Downsampled from (414475, 3) to (7677, 3) points (non-ground)\n",
      "Downsampled from (237620, 3) to (4305, 3) points (ground)\n",
      "Downsampled from (463157, 3) to (8880, 3) points (non-ground)\n",
      "Downsampled from (226253, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (506123, 3) to (9688, 3) points (non-ground)\n",
      "Downsampled from (228215, 3) to (4918, 3) points (ground)\n",
      "Downsampled from (389712, 3) to (6633, 3) points (non-ground)\n",
      "Downsampled from (308744, 3) to (4290, 3) points (ground)\n",
      "Downsampled from (280190, 3) to (4670, 3) points (non-ground)\n",
      "Downsampled from (445550, 3) to (6148, 3) points (ground)\n",
      "Downsampled from (317852, 3) to (6098, 3) points (non-ground)\n",
      "Downsampled from (379220, 3) to (5586, 3) points (ground)\n",
      "Downsampled from (387816, 3) to (7721, 3) points (non-ground)\n",
      "Downsampled from (359782, 3) to (5497, 3) points (ground)\n",
      "Downsampled from (184448, 3) to (3774, 3) points (non-ground)\n",
      "Downsampled from (389151, 3) to (5520, 3) points (ground)\n",
      "Downsampled from (199395, 3) to (4127, 3) points (non-ground)\n",
      "Downsampled from (416037, 3) to (5994, 3) points (ground)\n",
      "Downsampled from (408664, 3) to (6446, 3) points (non-ground)\n",
      "Downsampled from (375810, 3) to (6250, 3) points (ground)\n",
      "Downsampled from (476070, 3) to (8020, 3) points (non-ground)\n",
      "Downsampled from (303409, 3) to (6179, 3) points (ground)\n",
      "Downsampled from (382381, 3) to (6338, 3) points (non-ground)\n",
      "Downsampled from (335270, 3) to (5700, 3) points (ground)\n",
      "Downsampled from (330746, 3) to (6146, 3) points (non-ground)\n",
      "Downsampled from (327581, 3) to (5693, 3) points (ground)\n",
      "Downsampled from (406053, 3) to (7046, 3) points (non-ground)\n",
      "Downsampled from (206707, 3) to (4643, 3) points (ground)\n",
      "Downsampled from (422975, 3) to (7520, 3) points (non-ground)\n",
      "Downsampled from (209102, 3) to (4738, 3) points (ground)\n",
      "Downsampled from (401315, 3) to (6104, 3) points (non-ground)\n",
      "Downsampled from (363511, 3) to (5407, 3) points (ground)\n",
      "Downsampled from (300792, 3) to (4939, 3) points (non-ground)\n",
      "Downsampled from (396420, 3) to (6060, 3) points (ground)\n",
      "Downsampled from (313196, 3) to (5781, 3) points (non-ground)\n",
      "Downsampled from (251931, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (309416, 3) to (5698, 3) points (non-ground)\n",
      "Downsampled from (274970, 3) to (5225, 3) points (ground)\n",
      "Downsampled from (274156, 3) to (4913, 3) points (non-ground)\n",
      "Downsampled from (284434, 3) to (4914, 3) points (ground)\n",
      "Downsampled from (295151, 3) to (5374, 3) points (non-ground)\n",
      "Downsampled from (254407, 3) to (4843, 3) points (ground)\n",
      "Downsampled from (298362, 3) to (5378, 3) points (non-ground)\n",
      "Downsampled from (349049, 3) to (5351, 3) points (ground)\n",
      "Downsampled from (212601, 3) to (3902, 3) points (non-ground)\n",
      "Downsampled from (434219, 3) to (6130, 3) points (ground)\n",
      "Downsampled from (478729, 3) to (7473, 3) points (non-ground)\n",
      "Downsampled from (299350, 3) to (5988, 3) points (ground)\n",
      "Downsampled from (552680, 3) to (7790, 3) points (non-ground)\n",
      "Downsampled from (327195, 3) to (5910, 3) points (ground)\n",
      "Downsampled from (603452, 3) to (8669, 3) points (non-ground)\n",
      "Downsampled from (428943, 3) to (6376, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN\n",
    "\n",
    "def DBSCAN_clustering_logic(cur_pcd, pcd_all, eps=1.0, min_samples=100):\n",
    "    \"\"\"\n",
    "    Perform DBSCAN clustering on the point cloud data.\n",
    "\n",
    "    :param cur_pcd: Current point cloud for clustering.\n",
    "    :param pcd_all: All point cloud data.\n",
    "    :param eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "    :param min_samples: The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "    :return: Cluster labels for each point in the point cloud.\n",
    "    \"\"\"\n",
    "    not_road_points = np.asarray(cur_pcd.points)\n",
    "    #clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(not_road_points)\n",
    "    clustering = HDBSCAN(min_cluster_size=min_samples).fit(not_road_points)\n",
    "    labels_not_road = clustering.labels_\n",
    "    colors_gen = generate_random_colors(500)\n",
    "    \n",
    "    # Reproject cluster labels to the original point cloud size\n",
    "    cluster_labels = np.ones((len(pcd_all.points), 1)) * -1\n",
    "    labels_non_ground = kDTree_1NN_feature_reprojection(cluster_labels, pcd_all, labels_not_road.reshape(-1,1), cur_pcd)\n",
    "    colors = np.zeros((labels_non_ground.shape[0],3))\n",
    "    unique_labels = list(np.unique(labels_non_ground))\n",
    "    for j in unique_labels:\n",
    "            cur_idcs = np.where(labels_non_ground == j)[0]\n",
    "            \n",
    "            colors[cur_idcs] = np.array(colors_gen[unique_labels.index(j)])\n",
    "    pcd_all.colors = o3d.utility.Vector3dVector(colors / 255.)\n",
    "    return pcd_all\n",
    "\n",
    "def dbscan_clustering(pcd_chunks_major_downsampled, pcds, center_ids,ground_clouds):\n",
    "    labels_clustering = []\n",
    "    for i in range(len(pcd_chunks_major_downsampled)):\n",
    "        cur_pcd = pcd_chunks_major_downsampled[i]\n",
    "        pcd_all = pcds[i]\n",
    "        ground_cloud = ground_clouds[i]\n",
    "        cluster_labels = DBSCAN_clustering_logic(cur_pcd, pcd_all)  # Implement your DBSCAN logic here\n",
    "        ground_labels = np.ones((np.asarray(ground_cloud.points).shape[0],1)) * -1\n",
    "        cluster_labels = np.concatenate((cluster_labels,ground_labels),0)\n",
    "        labels_clustering.append(cluster_labels)\n",
    "        \n",
    "    return labels_clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "\n",
    "\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "        #if labels[i] != (-1):\n",
    "        #    pcd_colored.colors[i] = np.array(colors[labels[i]]) / 255\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/ 255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of sequence 0\n",
      "7643 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 66 cut regions\n",
      "Ratio of points in top 3 groups: 0.3433206855946618\n",
      "start of sequence 1\n",
      "6659 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 47 cut regions\n",
      "Ratio of points in top 3 groups: 0.3990088601892176\n",
      "start of sequence 2\n",
      "7470 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 47 cut regions\n",
      "Ratio of points in top 3 groups: 0.37697456492637216\n",
      "start of sequence 3\n",
      "5813 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 48 cut regions\n",
      "Ratio of points in top 3 groups: 0.2650954756580079\n",
      "start of sequence 4\n",
      "7677 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 62 cut regions\n",
      "Ratio of points in top 3 groups: 0.3757978376970171\n",
      "start of sequence 5\n",
      "8880 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 60 cut regions\n",
      "Ratio of points in top 3 groups: 0.2277027027027027\n",
      "start of sequence 6\n",
      "9688 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 26 cut regions\n",
      "Ratio of points in top 3 groups: 0.6463666391412056\n",
      "start of sequence 7\n",
      "6633 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 34 cut regions\n",
      "Ratio of points in top 3 groups: 0.42680536710387457\n",
      "start of sequence 8\n",
      "4670 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 32 cut regions\n",
      "Ratio of points in top 3 groups: 0.43254817987152033\n",
      "start of sequence 9\n",
      "6098 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 36 cut regions\n",
      "Ratio of points in top 3 groups: 0.6121679239094785\n",
      "start of sequence 10\n",
      "7721 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 25 cut regions\n",
      "Ratio of points in top 3 groups: 0.5644346587229634\n",
      "start of sequence 11\n",
      "3774 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 50 cut regions\n",
      "Ratio of points in top 3 groups: 0.4165341812400636\n",
      "start of sequence 12\n",
      "4127 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 37 cut regions\n",
      "Ratio of points in top 3 groups: 0.3477102011146111\n",
      "start of sequence 13\n",
      "6446 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 28 cut regions\n",
      "Ratio of points in top 3 groups: 0.5760161340366119\n",
      "start of sequence 14\n",
      "8020 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 41 cut regions\n",
      "Ratio of points in top 3 groups: 0.408354114713217\n",
      "start of sequence 15\n",
      "6338 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 34 cut regions\n",
      "Ratio of points in top 3 groups: 0.3373303881350584\n",
      "start of sequence 16\n",
      "6146 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 32 cut regions\n",
      "Ratio of points in top 3 groups: 0.41425317279531404\n",
      "start of sequence 17\n",
      "7046 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 48 cut regions\n",
      "Ratio of points in top 3 groups: 0.2223956854953165\n",
      "start of sequence 18\n",
      "7520 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 54 cut regions\n",
      "Ratio of points in top 3 groups: 0.23018617021276597\n",
      "start of sequence 19\n",
      "6104 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 57 cut regions\n",
      "Ratio of points in top 3 groups: 0.42693315858453473\n",
      "start of sequence 20\n",
      "4939 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 42 cut regions\n",
      "Ratio of points in top 3 groups: 0.4138489572788014\n",
      "start of sequence 21\n",
      "5781 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 50 cut regions\n",
      "Ratio of points in top 3 groups: 0.2347344750043245\n",
      "start of sequence 22\n",
      "5698 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 43 cut regions\n",
      "Ratio of points in top 3 groups: 0.21077571077571078\n",
      "start of sequence 23\n",
      "4913 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 36 cut regions\n",
      "Ratio of points in top 3 groups: 0.3388968043964991\n",
      "start of sequence 24\n",
      "5374 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 42 cut regions\n",
      "Ratio of points in top 3 groups: 0.32880535913658354\n",
      "start of sequence 25\n",
      "5378 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 44 cut regions\n",
      "Ratio of points in top 3 groups: 0.3179620676831536\n",
      "start of sequence 26\n",
      "3902 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 39 cut regions\n",
      "Ratio of points in top 3 groups: 0.3326499231163506\n",
      "start of sequence 27\n",
      "7473 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 50 cut regions\n",
      "Ratio of points in top 3 groups: 0.2525090325170614\n",
      "start of sequence 28\n",
      "7790 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 42 cut regions\n",
      "Ratio of points in top 3 groups: 0.32426187419768937\n",
      "start of sequence 29\n",
      "8669 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 46 cut regions\n",
      "Ratio of points in top 3 groups: 0.3204521859499366\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.5\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "out_dbscan = 'out_dbscan/'\n",
    "if os.path.exists(out_dbscan) == False : \n",
    "        os.makedirs(out_dbscan)\n",
    "\n",
    "out_kitti = 'out_kitti/'\n",
    "if os.path.exists(out_kitti) == False : \n",
    "        os.makedirs(out_kitti)\n",
    "        \n",
    "out_kitti_instance = 'out_kitti_instance/'\n",
    "if os.path.exists(out_kitti_instance) == False : \n",
    "        os.makedirs(out_kitti_instance)\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "for sequence in range(len(center_ids)):\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground, inliers_ground = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "                \n",
    "                kitti_labels['ground']['panoptic'][sequence] = kitti_labels['ground']['panoptic'][sequence][inliers_ground]\n",
    "                kitti_labels['ground']['instance'][sequence] = kitti_labels['ground']['instance'][sequence][inliers_ground]\n",
    "                \n",
    "                name = file_name.split('/')[-1]\n",
    "                o3d.io.write_point_cloud(file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                pcd_dbscan = DBSCAN_clustering_logic(pcd_nonground_chunks_major_downsampling[sequence],\n",
    "                                                pcd_nonground_chunks[sequence],\n",
    "                                                eps=0.6, min_samples=10)\n",
    "                \n",
    "                kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['panoptic'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=kitti_labels_orig['panoptic_nonground'])\n",
    "                kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=kitti_labels_orig['instance_nonground'])\n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,kitti_labels['ground']['instance'][sequence].reshape(-1,))\n",
    "                o3d.io.write_point_cloud(out_dbscan + name, pcd_dbscan + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti + name, kitti_chunk + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + name, kitti_chunk_instance + pcd_chunk_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "        else : \n",
    "                obstacle_out,file_name = ncuts_chunk(dataset,indices,pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "                \n",
    "                \n",
    "                ground_out,file_name = ncuts_chunk(dataset,indices_ground,pcd_ground_chunks,None,\n",
    "                        pcd_ground_chunks_major_downsampling,\n",
    "                        pcd_ground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,sampled_indices_global,\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices)\n",
    "\n",
    "                o3d.io.write_point_cloud(file_name, obstacle_out + ground_out, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "                print(\"Pointcloud written to file\")\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000062.pcd', '000090.pcd', '000121.pcd', '000161.pcd', '000190.pcd', '000216.pcd', '000245.pcd', '000275.pcd', '000330.pcd', '000366.pcd', '000389.pcd', '000412.pcd', '000437.pcd', '000477.pcd', '000513.pcd', '000537.pcd', '000562.pcd', '000584.pcd', '000606.pcd', '000634.pcd', '000769.pcd', '000790.pcd', '000809.pcd', '000829.pcd', '000850.pcd', '000872.pcd', '000906.pcd', '000944.pcd', '000975.pcd', '001029.pcd']\n",
      "['000062.pcd', '000090.pcd', '000121.pcd', '000161.pcd', '000190.pcd', '000216.pcd', '000245.pcd', '000275.pcd', '000330.pcd', '000366.pcd', '000389.pcd', '000412.pcd', '000437.pcd', '000477.pcd', '000513.pcd', '000537.pcd', '000562.pcd', '000584.pcd', '000606.pcd', '000634.pcd', '000769.pcd', '000790.pcd', '000809.pcd', '000829.pcd', '000850.pcd', '000872.pcd', '000906.pcd', '000944.pcd', '000975.pcd', '001029.pcd']\n",
      "['000062.pcd', '000090.pcd', '000121.pcd', '000161.pcd', '000190.pcd', '000216.pcd', '000245.pcd', '000275.pcd', '000330.pcd', '000366.pcd', '000389.pcd', '000412.pcd', '000437.pcd', '000477.pcd', '000513.pcd', '000537.pcd', '000562.pcd', '000584.pcd', '000606.pcd', '000634.pcd', '000769.pcd', '000790.pcd', '000809.pcd', '000829.pcd', '000850.pcd', '000872.pcd', '000906.pcd', '000944.pcd', '000975.pcd', '001029.pcd']\n",
      "['000062.pcd', '000090.pcd', '000121.pcd', '000161.pcd', '000190.pcd', '000216.pcd', '000245.pcd', '000275.pcd', '000330.pcd', '000366.pcd', '000389.pcd', '000412.pcd', '000437.pcd', '000477.pcd', '000513.pcd', '000537.pcd', '000562.pcd', '000584.pcd', '000606.pcd', '000634.pcd', '000769.pcd', '000790.pcd', '000809.pcd', '000829.pcd', '000850.pcd', '000872.pcd', '000906.pcd', '000944.pcd', '000975.pcd', '001029.pcd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dbscan = 'out_dbscan/'\n",
    "out_kitti = 'out_kitti/'\n",
    "out_kitti_instance = 'out_kitti_instance/'\n",
    "\n",
    "\n",
    "point_clouds = get_merge_pcds(out_folder_ncuts)[:-1]\n",
    "point_clouds_dbscan = get_merge_pcds(out_dbscan)[:-1]\n",
    "point_clouds_kitti = get_merge_pcds(out_kitti)[:-1]\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)[:-1]\n",
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "merge_dbscan = merge_chunks_unite_instances(point_clouds_dbscan)\n",
    "merge_kitti = merge_unite_gt(point_clouds_kitti)\n",
    "merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_part_dbscan.pcd\", merge_dbscan, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_part_kitti.pcd\", merge_kitti, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_instance.pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 16447617 points.\n",
      "PointCloud with 16447617 points.\n",
      "PointCloud with 16448617 points.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "merge = o3d.io.read_point_cloud(out_folder + 'merge_part.pcd')\n",
    "merge_dbscan = o3d.io.read_point_cloud(out_folder + 'merge_part_dbscan.pcd')\n",
    "merge_kitti = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti.pcd')\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + 'merge_part_kitti_instance.pcd')\n",
    "merge_exp2 = o3d.io.read_point_cloud(out_folder + 'merge_exp2.pcd')\n",
    "\n",
    "print(merge)\n",
    "print(merge_kitti)\n",
    "print(merge_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmetrics_ncuts = Metrics(name='ncuts')\\nmetrics_dbscan = Metrics(name='dbscan')\\nmetrics_test = Metrics(name='test')\\n\\nmetrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\\n\\nmetrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\\n\\nmetrics_dbscan.compute_all_aps()\\nmetrics_ncuts.compute_all_aps()\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_dbscan = np.unique(np.asarray(merge_dbscan.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "def remove_semantics(labels,preds):\n",
    "        gt_idcs = np.where(labels == 0)[0]\n",
    "        new_ncuts_labels = preds.copy()\n",
    "        for i in np.unique(preds):\n",
    "                pred_idcs = np.where(preds == i)[0]\n",
    "                cur_intersect = intersect(pred_idcs,gt_idcs)\n",
    "                if cur_intersect > 0.8:\n",
    "                        new_ncuts_labels[pred_idcs] = 0\n",
    "        return new_ncuts_labels\n",
    "\n",
    "new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "new_dbscan_labels = remove_semantics(labels_kitti,labels_dbscan)\n",
    "\n",
    "\n",
    "'''\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_dbscan = Metrics(name='dbscan')\n",
    "metrics_test = Metrics(name='test')\n",
    "\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\n",
    "\n",
    "metrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\n",
    "\n",
    "metrics_dbscan.compute_all_aps()\n",
    "metrics_ncuts.compute_all_aps()\n",
    "'''\n",
    "#merge_vis = color_pcd_by_labels(merge,labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kitti_pcd = color_pcd_by_labels(merge_dbscan,new_ncuts_labels)\n",
    "o3d.io.write_point_cloud(out_folder + \"ncuts_instances_tarl.pcd\",new_kitti_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "#new_dbscan_pcd = color_pcd_by_labels(merge_dbscan,new_dbscan_labels)\n",
    "#o3d.io.write_point_cloud(out_folder + \"dbscan_instances.pcd\",new_dbscan_pcd, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_dbscan = Metrics(name='dbscan')\n",
    "metrics_test = Metrics(name='test')\n",
    "\n",
    "metrics_ncuts.update_stats(new_ncuts_labels,labels_kitti)\n",
    "#metrics_dbscan.update_stats(new_dbscan_labels,labels_kitti)\n",
    "metrics_ncuts.compute_all_aps()\n",
    "#metrics_dbscan.compute_all_aps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([new_kitti_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/cedric/Datasets/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d.pipelines import registration\n",
    "import numpy as np \n",
    "merge.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\n",
    "for i in range(70,72):\n",
    "\tlocal_pcd = o3d.geometry.PointCloud()\n",
    "\tlocal_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\t\n",
    "\t\n",
    "\t## label visualization \n",
    "\tlabeled_pcd = o3d.geometry.PointCloud()\n",
    "\tlabeled_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\tlabeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n",
    "\tpanoptic_labels = dataset[i].panoptic_labels # semantics + panoptics combined \n",
    "\tsemantic_labels = dataset[i].semantic_labels\n",
    "\tinstance_labels = dataset[i].instance_labels\n",
    "\tintensity = dataset[i].intensity\n",
    "\t\n",
    "\ttransform = dataset.get_pose(i)\n",
    "\tlocal_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\treg_p2l = registration.registration_icp(local_pcd, merge, 0.9, transform, registration.TransformationEstimationPointToPlane(), registration.ICPConvergenceCriteria(max_iteration=1000))\n",
    "\ttransform = reg_p2l.transformation\n",
    "\tlocal_pcd.transform(transform)\n",
    "\t\n",
    "\tlocal_pcd.normals = o3d.utility.Vector3dVector([])\n",
    "\t\n",
    "\tlocal_pcd.paint_uniform_color([0, 0, 0])\n",
    "\t\n",
    "\tcolors, labels,local_labels = kDTree_1NN_feature_reprojection_colors(np.asarray(local_pcd.colors), local_pcd, np.asarray(merge.colors), merge,panoptic_labels, max_radius=0.2)\n",
    "\tlabeled_pcd = color_pcd_by_labels(labeled_pcd,labels.reshape(-1,))\n",
    "\tlocal_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\t#o3d.io.write_point_cloud(\"test.pcd\", local_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tlabeled_pcd.translate([0,120,0])\n",
    "\to3d.visualization.draw_geometries([local_pcd,labeled_pcd])\n",
    "\tunique_colors, labels = np.unique(colors, axis=0, return_inverse=True)\n",
    "\tunseen_mask = np.all(colors == [1,0,0], axis=1)\n",
    "\tlabels[unseen_mask] = -1\n",
    "\tstreet_mask = np.all(colors == [0,0,0], axis=1)\n",
    "\tlabels[street_mask] = 1\n",
    "\t\n",
    "\t#np.savez('output_files/7_tarl/ ' + str(i) + '.npz',labels=labels)\n",
    "\n",
    "\t\n",
    "\n",
    "\t#np.savez('output_files/7_original/' + str(i) + '.npz',ncut_labels=local_labels,kitti_labels=labels,pts=np.asarray(local_pcd.points),           \n",
    "\t#intensities=intensity,kitti_labels_semantic=semantic_labels,kitti_labels_instance=instance_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "with np.load('output_files/7_original/0.npz') as data:\n",
    "            xyz = data['pts'].astype(np.float)\n",
    "            labels = data['ncut_labels'].astype(np.int32)  \n",
    "            kitti_labels = data['kitti_labels']\n",
    "            intensity = data['intensities']\n",
    "            \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "pcd = color_pcd_by_labels(pcd,labels)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
