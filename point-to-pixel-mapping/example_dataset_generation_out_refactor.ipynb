{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_chunks_unite_instances2\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "end_inds = {0:4541,1:1100,2:4661,3:800,4:271,5:2761,6:1101,7:1100,8:4071,9:1591,10:1201}\n",
    "SEQUENCE_NUM = 7\n",
    "old = False \n",
    "if SEQUENCE_NUM == 7 : \n",
    "        old = True \n",
    "ind_start = 0\n",
    "ind_end = end_inds[SEQUENCE_NUM]\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = 'pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_folder + 'all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz',\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n",
    "        o3d.visualization.draw_geometries([pcd_nonground_minor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "print(pcd_ground_minor)\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz') as data :\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pts_num = 1000000\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz') == False : \n",
    "\tprint(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz')\n",
    "\tposes, positions, \\\n",
    "\tsampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start,sequence_num=SEQUENCE_NUM,out_folder=out_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(f'{out_folder}subsampled_data{SEQUENCE_NUM}_0.npz') as data:\n",
    "\tposes=data['poses']\n",
    "\tpositions=data['positions']\n",
    "\tsampled_indices_local = data['sampled_indices_local']\n",
    "\tsampled_indices_global=data['sampled_indices_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 3\n",
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None,semantics=False):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 and semantics == False : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "    if semantics : \n",
    "        pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    else : \n",
    "        pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_2d_list(my_list, target_sublist):\n",
    "    for i, sublist in enumerate(my_list):\n",
    "        if sublist == list(target_sublist): \n",
    "            return i\n",
    "    return None  # Sublist not found in the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_cols(colors,labels,pcd):\n",
    "\tcur_cols = np.asarray(pcd.colors)\n",
    "\tunique_labels = list(np.unique(labels))\n",
    "\tnew_labels = np.zeros_like(labels)\n",
    "\tfor label in unique_labels: \n",
    "\t\tidcs = np.where(labels == label)[0]\n",
    "\t\tcol = cur_cols[idcs[0]]\n",
    "\t\tidx = find_index_2d_list(colors,col)\n",
    "\t\tnew_labels[idcs] = idx \n",
    "\treturn new_labels\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.1\n",
    "proximity_threshold = 1.0\n",
    "ncuts_threshold = 0.01\n",
    "        \n",
    "out_name = 'sam_only' + str(SEQUENCE_NUM) \n",
    "# Generate 30 different colors\n",
    "COLORS_arr = plt.cm.viridis(np.linspace(0, 1, 30)) \n",
    "COLORS = list(list(col) for col in COLORS_arr) \n",
    "COLORS = [list(col[:3]) for col in COLORS]\n",
    "\n",
    "\n",
    "out_kitti = out_chunks + 'out_kitti' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_kitti) == True : \n",
    "        shutil.rmtree(out_kitti)\n",
    "\n",
    "os.makedirs(out_kitti)\n",
    "        \n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "'''\n",
    "if os.path.exists(out_kitti_instance) == True : \n",
    "        shutil.rmtree(out_kitti_instance)\n",
    "os.makedirs(out_kitti_instance)\n",
    "'''\n",
    "\n",
    "\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "'''\n",
    "if os.path.exists(out_kitti_semantic) == True : \n",
    "        shutil.rmtree(out_kitti_semantic)\n",
    "os.makedirs(out_kitti_semantic)\n",
    "'''\n",
    "\n",
    "limit = -1 ##use this for experiments to run limit chunks numberss\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "semantics = np.hstack((kitti_labels_orig['seg_nonground'].reshape(-1,),kitti_labels_orig['seg_ground'].reshape(-1,)))\n",
    "\n",
    "instances = np.hstack((kitti_labels_orig['instance_nonground'],kitti_labels_orig['instance_ground']))\n",
    "                \n",
    "print(\"total sequence number\",len(center_ids))\n",
    "for sequence in range(len(center_ids)):\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,list(indices),pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,list(sampled_indices_global),\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold)\n",
    "                        \n",
    "                        \n",
    "                #ground_out,file_name = ncuts_chunk(dataset,list(indices_ground),pcd_chunk_ground,None,\n",
    "                #        pcd_ground_chunks_major_downsampling,\n",
    "                #        pcd_ground_minor,T_pcd,center_positions,center_ids,\n",
    "                #        positions,first_position,list(sampled_indices_global),\n",
    "                #        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                #        alpha=alpha,beta=0.0,gamma=1.0,theta=0.0,\n",
    "                #        proximity_threshold=25.0,\n",
    "                #        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                #        patchwise_indices=patchwise_indices,ncuts_threshold=0.003)\n",
    "                \n",
    "                #o3d.visualization.draw_geometries([ground_out])\n",
    "                \n",
    "                seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                \n",
    "                file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "\n",
    "                kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['semantic'][sequence].reshape(-1,),\n",
    "                                        colors=COLORS,gt_labels=semantics,semantics=True\n",
    "                                        )\n",
    "                \n",
    "                kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_semantic_ground = color_pcd_by_labels(pcd_chunk_ground,seg_ground.reshape(-1,),\n",
    "                                        colors=COLORS,gt_labels=semantics,semantics=True)\n",
    "                \n",
    "                #o3d.visualization.draw_geometries([kitti_chunk_instance + kitti_chunk_instance_ground])\n",
    "                #o3d.visualization.draw_geometries([pcd_chunk + pcd_chunk_ground])\n",
    "                semantic_labels = np.hstack(( kitti_labels['nonground']['semantic'][sequence].reshape(-1,),seg_ground.reshape(-1,)))\n",
    "                np.savez(out_kitti_semantic + file_name.split('.')[0] + '.npz',labels=semantic_labels)\n",
    "                \n",
    "                o3d.io.write_point_cloud(out_folder_ncuts + file_name, pcd_chunk + pcd_chunk_ground , write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                #o3d.io.write_point_cloud(out_kitti_semantic + file_name, kitti_chunk + kitti_chunk_semantic_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def merge_chunks_unite_instances2(chunks: list, icp=False):\n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    chunk_means = [np.mean(np.asarray(chunk.points), axis=0) for chunk in chunks]\n",
    "\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in tqdm(chunks[1:]):\n",
    "\n",
    "        new_chunk_center = np.asarray(new_chunk.points)\n",
    "        \n",
    "        x,y,z = new_chunk_center[:,0].mean(),new_chunk_center[:,1].mean(),new_chunk_center[:,2].mean()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        pcd_tree = o3d.geometry.KDTreeFlann(merge)\n",
    "        query_point = np.array([x, y, z])  # Replace x, y, z with your point's coordinates\n",
    "        distance_threshold = 35.0  # Adjust this value to your desired distance threshold\n",
    "        \n",
    "        \n",
    "        \n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(query_point, distance_threshold)\n",
    "\n",
    "        # Extract the points within the specified distance\n",
    "        if k > 0:\n",
    "            points_within_distance = np.asarray(merge.points)[idx]\n",
    "        else:\n",
    "            points_within_distance = np.array([])\n",
    "\n",
    "        extracted_pcd = o3d.geometry.PointCloud()\n",
    "        extracted_pcd.points = o3d.utility.Vector3dVector(points_within_distance)\n",
    "        extracted_pcd.colors = o3d.utility.Vector3dVector(np.asarray(merge.colors)[idx])\n",
    "        '''\n",
    "        side_length = 40 \n",
    "        center_point = np.array([x, y, z])  # Replace x, y, z with your point's coordinates\n",
    "        half_side = side_length / 2.0\n",
    "        min_bound = center_point - half_side\n",
    "        max_bound = center_point + half_side\n",
    "        aabb = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound, max_bound=max_bound)\n",
    "\n",
    "        # Crop the point cloud\n",
    "        extracted_pcd = merge.crop(aabb)\n",
    "\n",
    "        \n",
    "        points_1 = np.asarray(extracted_pcd.points)\n",
    "        points_2 = np.asarray(new_chunk.points)\n",
    "\n",
    "        colors_1 = np.asarray(extracted_pcd.colors)\n",
    "        colors_2 = np.asarray(new_chunk.colors)\n",
    "\n",
    "        unique_colors_1 = np.unique(colors_1, axis=0)\n",
    "        unique_colors_2 = np.unique(colors_2, axis=0)\n",
    "\n",
    "        instance2point_1 = {}\n",
    "        for i in range(unique_colors_1.shape[0]):\n",
    "            if not np.all(unique_colors_1[i] == 0.0): # Streets are black\n",
    "                instance2point_1[i] = {}\n",
    "                inds = np.where(np.all(colors_1 == unique_colors_1[i], axis=1))[0]\n",
    "                instance2point_1[i][\"points\"] = points_1[inds]\n",
    "                instance2point_1[i][\"inds\"] = inds\n",
    "\n",
    "        instance2point_2 = {}\n",
    "        for i in range(unique_colors_2.shape[0]):\n",
    "            if not np.all(unique_colors_2[i] == 0.0): # Streets are black\n",
    "                instance2point_2[i] = {}\n",
    "                inds = np.where(np.all(colors_2 == unique_colors_2[i], axis=1))[0]\n",
    "                instance2point_2[i][\"points\"] = points_2[inds]\n",
    "                instance2point_2[i][\"inds\"] = inds\n",
    "        \n",
    "        id_pairs_iou = []\n",
    "        for id_1, entries_1 in instance2point_1.items():\n",
    "            points1 = entries_1[\"points\"]\n",
    "            min_bound = np.min(points1, axis=0)\n",
    "            max_bound = np.max(points1, axis=0)\n",
    "            association = []\n",
    "            for id_2, entries_2 in instance2point_2.items():\n",
    "                points2 = entries_2[\"points\"]\n",
    "                intersection = np.where(np.all(points2 >= min_bound, axis=1) & np.all(points2 <= max_bound, axis=1))[0].shape[0]\n",
    "                if intersection > 0:\n",
    "                    union = len(np.unique(np.concatenate((points1, points2))))\n",
    "                    iou = float(intersection) / float(union)\n",
    "                    if iou > 0.01:\n",
    "                        association.append((id_2, iou))\n",
    "            if len(association) != 0:\n",
    "                for (association_id, iou) in association:\n",
    "                    id_pairs_iou.append((id_1, (association_id, iou)))\n",
    "        \n",
    "        ids_chunk_1 = []\n",
    "        ids_chunk_2 = []\n",
    "        ious = []\n",
    "        for id1, (id2, iou) in id_pairs_iou:\n",
    "            if id2 not in ids_chunk_2:\n",
    "                ids_chunk_1.append(id1)\n",
    "                ids_chunk_2.append(id2)\n",
    "                ious.append(iou)\n",
    "            else:\n",
    "                i = ids_chunk_2.index(id2)\n",
    "                if iou > ious[i]:\n",
    "                    ious[i] = iou\n",
    "                    ids_chunk_1[i] = id1\n",
    "\n",
    "        for id1, id2 in zip(ids_chunk_1, ids_chunk_2):\n",
    "            inds2 = instance2point_2[id2][\"inds\"]\n",
    "            colors_2[inds2] = unique_colors_1[id1]\n",
    "\n",
    "        new_chunk_recolored = o3d.geometry.PointCloud()\n",
    "        new_chunk_recolored.points = new_chunk.points\n",
    "        new_chunk_recolored.colors = o3d.utility.Vector3dVector(colors_2)\n",
    "        last_chunk = new_chunk_recolored\n",
    "\n",
    "        merge += new_chunk_recolored\n",
    "        merge.remove_duplicated_points()\n",
    "\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_kitti = out_chunks + 'out_kitti' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "point_clouds = get_merge_pcds(out_folder_ncuts)[:-1]\n",
    "#point_clouds_kitti = get_merge_pcds(out_kitti)[:-1]\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)[:-1]\n",
    "#point_clouds_kitti_semantic = get_merge_pcds(out_kitti_semantic)[:-1]\n",
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "\n",
    "\n",
    "#merge_dbscan = merge_chunks_unite_instances(point_clouds_dbscan)\n",
    "\n",
    "#merge_kitti = merge_unite_gt(point_clouds_kitti)\n",
    "merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "#merge_kitti_semantic = merge_unite_gt(point_clouds_kitti_semantic)\n",
    "\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_semantic7.pcd\", merge_kitti_semantic, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + out_name + str(SEQUENCE_NUM) + \".pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "print(merge_kitti_instance)\n",
    "print(merge)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_instance\" + str(SEQUENCE_NUM) +  \".pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "merge = o3d.io.read_point_cloud(out_folder + out_name + str(SEQUENCE_NUM) +  \".pcd\")\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + \"merge_part_kitti_instance\" + str(SEQUENCE_NUM) +  \".pcd\")\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "print(merge_kitti_instance)\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_batch(unique_pred, preds, labels, gt_idcs, threshold, new_ncuts_labels):\n",
    "    pred_idcs = np.where(preds == unique_pred)[0]\n",
    "    cur_intersect = np.sum(np.isin(pred_idcs, gt_idcs))\n",
    "    if cur_intersect > threshold * len(pred_idcs): \n",
    "        new_ncuts_labels[pred_idcs] = 0\n",
    "\n",
    "def remove_semantics(labels, preds, threshold=0.8, num_threads=None):\n",
    "    gt_idcs = np.where(labels == 0)[0]\n",
    "    new_ncuts_labels = preds.copy()\n",
    "    unique_preds = np.unique(preds)\n",
    "    \n",
    "    if num_threads is None:\n",
    "        num_threads = min(len(unique_preds), 8)  # Default to 8 threads if not specified\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for i in tqdm(unique_preds):\n",
    "            futures.append(executor.submit(process_batch, i, preds, labels, gt_idcs, threshold, new_ncuts_labels))\n",
    "        \n",
    "        # Wait for all tasks to complete\n",
    "        for future in tqdm(futures, total=len(futures), desc=\"Processing\"):\n",
    "            future.result()  # Get the result to catch any exceptions\n",
    "        \n",
    "    return new_ncuts_labels\n",
    "\n",
    "print('remove semantics')\n",
    "new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "\n",
    "metrics_ncuts.update_stats(labels_ncuts,new_ncuts_labels,labels_kitti)\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
