{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[(0.267004, 0.004874, 0.329415), (0.277018, 0.050344, 0.375715), (0.282656, 0.100196, 0.42216), (0.28229, 0.145912, 0.46151), (0.276194, 0.190074, 0.493001), (0.265145, 0.232956, 0.516599), (0.252194, 0.269783, 0.531579), (0.235526, 0.309527, 0.542944), (0.21813, 0.347432, 0.550038), (0.201239, 0.38367, 0.554294), (0.185556, 0.41857, 0.556753), (0.171176, 0.45253, 0.557965), (0.159194, 0.482237, 0.558073), (0.14618, 0.515413, 0.556823), (0.133743, 0.548535, 0.553541), (0.123463, 0.581687, 0.547445), (0.119483, 0.614817, 0.537692), (0.128087, 0.647749, 0.523491), (0.150148, 0.676631, 0.506589), (0.19109, 0.708366, 0.482284), (0.24607, 0.73891, 0.452024), (0.311925, 0.767822, 0.415586), (0.386433, 0.794644, 0.372886), (0.468053, 0.818921, 0.323998), (0.545524, 0.838039, 0.275626), (0.636902, 0.856542, 0.21662), (0.730889, 0.871916, 0.156029), (0.82494, 0.88472, 0.106217), (0.916242, 0.896091, 0.100717), (0.993248, 0.906157, 0.143936)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from ncuts_utils import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_chunks_unite_instances2\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "end_inds = {0:4541,1:1100,2:4661,3:800,4:271,5:2761,6:1101,7:1100,8:4071,9:1591,10:1201}\n",
    "SEQUENCE_NUM = 7\n",
    "old = False \n",
    "if SEQUENCE_NUM == 7 : \n",
    "        old = True \n",
    "ind_start = 0\n",
    "ind_end = end_inds[SEQUENCE_NUM]\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = 'pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_folder_ncuts):\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_folder + 'all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz',\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n",
    "        o3d.visualization.draw_geometries([pcd_nonground_minor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 11580178 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "print(pcd_ground_minor)\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz') as data :\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npcd_new = o3d.geometry.PointCloud()\\npts_num = 1000000\\npcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\\n\\nmap_labelled = color_pcd_by_labels(pcd_new,                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\\n\\no3d.visualization.draw_geometries([map_labelled])\\n#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pcd_new = o3d.geometry.PointCloud()\n",
    "pts_num = 1000000\n",
    "pcd_new.points = o3d.utility.Vector3dVector(np.asarray(pcd_nonground_minor.points)[:pts_num])\n",
    "\n",
    "map_labelled = color_pcd_by_labels(pcd_new,\\\n",
    "                kitti_labels['panoptic_nonground'][:pts_num].reshape(-1,1))\n",
    "\n",
    "o3d.visualization.draw_geometries([map_labelled])\n",
    "#o3d.io.write_point_cloud('labelled_map07.pcd',map_labelled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz') == False : \n",
    "\tprint(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz')\n",
    "\tposes, positions, \\\n",
    "\tsampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start,sequence_num=SEQUENCE_NUM,out_folder=out_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(f'{out_folder}subsampled_data{SEQUENCE_NUM}_0.npz') as data:\n",
    "\tposes=data['poses']\n",
    "\tpositions=data['positions']\n",
    "\tsampled_indices_local = data['sampled_indices_local']\n",
    "\tsampled_indices_global=data['sampled_indices_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (541161, 3) to (7776, 3) points (non-ground)\n",
      "Downsampled from (243917, 3) to (5294, 3) points (ground)\n",
      "Downsampled from (454490, 3) to (7216, 3) points (non-ground)\n",
      "Downsampled from (262770, 3) to (4499, 3) points (ground)\n",
      "Downsampled from (479361, 3) to (7341, 3) points (non-ground)\n",
      "Downsampled from (304983, 3) to (6061, 3) points (ground)\n",
      "Downsampled from (479273, 3) to (6272, 3) points (non-ground)\n",
      "Downsampled from (246003, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (473079, 3) to (8385, 3) points (non-ground)\n",
      "Downsampled from (221993, 3) to (4446, 3) points (ground)\n",
      "Downsampled from (488393, 3) to (9063, 3) points (non-ground)\n",
      "Downsampled from (220415, 3) to (5078, 3) points (ground)\n",
      "Downsampled from (545707, 3) to (8986, 3) points (non-ground)\n",
      "Downsampled from (292301, 3) to (4209, 3) points (ground)\n",
      "Downsampled from (409731, 3) to (6703, 3) points (non-ground)\n",
      "Downsampled from (441195, 3) to (4976, 3) points (ground)\n",
      "Downsampled from (300320, 3) to (4742, 3) points (non-ground)\n",
      "Downsampled from (509260, 3) to (6199, 3) points (ground)\n",
      "Downsampled from (350224, 3) to (6187, 3) points (non-ground)\n",
      "Downsampled from (372916, 3) to (5525, 3) points (ground)\n",
      "Downsampled from (452246, 3) to (7807, 3) points (non-ground)\n",
      "Downsampled from (385946, 3) to (5562, 3) points (ground)\n",
      "Downsampled from (262978, 3) to (4456, 3) points (non-ground)\n",
      "Downsampled from (451230, 3) to (6189, 3) points (ground)\n",
      "Downsampled from (260853, 3) to (4469, 3) points (non-ground)\n",
      "Downsampled from (540630, 3) to (6637, 3) points (ground)\n",
      "Downsampled from (477380, 3) to (7261, 3) points (non-ground)\n",
      "Downsampled from (438394, 3) to (6594, 3) points (ground)\n",
      "Downsampled from (484851, 3) to (7762, 3) points (non-ground)\n",
      "Downsampled from (389528, 3) to (6532, 3) points (ground)\n",
      "Downsampled from (406142, 3) to (6391, 3) points (non-ground)\n",
      "Downsampled from (339234, 3) to (5270, 3) points (ground)\n",
      "Downsampled from (322094, 3) to (5849, 3) points (non-ground)\n",
      "Downsampled from (273519, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (383759, 3) to (6583, 3) points (non-ground)\n",
      "Downsampled from (196088, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (471693, 3) to (7780, 3) points (non-ground)\n",
      "Downsampled from (309908, 3) to (6091, 3) points (ground)\n",
      "Downsampled from (570103, 3) to (5949, 3) points (non-ground)\n",
      "Downsampled from (939537, 3) to (9495, 3) points (ground)\n",
      "Downsampled from (567185, 3) to (7039, 3) points (non-ground)\n",
      "Downsampled from (480866, 3) to (7211, 3) points (ground)\n",
      "Downsampled from (324509, 3) to (5945, 3) points (non-ground)\n",
      "Downsampled from (214718, 3) to (4765, 3) points (ground)\n",
      "Downsampled from (296982, 3) to (5076, 3) points (non-ground)\n",
      "Downsampled from (295734, 3) to (5203, 3) points (ground)\n",
      "Downsampled from (311607, 3) to (5367, 3) points (non-ground)\n",
      "Downsampled from (283045, 3) to (4829, 3) points (ground)\n",
      "Downsampled from (336036, 3) to (5544, 3) points (non-ground)\n",
      "Downsampled from (254495, 3) to (4716, 3) points (ground)\n",
      "Downsampled from (351770, 3) to (5478, 3) points (non-ground)\n",
      "Downsampled from (493796, 3) to (6512, 3) points (ground)\n",
      "Downsampled from (333876, 3) to (5378, 3) points (non-ground)\n",
      "Downsampled from (579172, 3) to (6166, 3) points (ground)\n",
      "Downsampled from (576526, 3) to (8127, 3) points (non-ground)\n",
      "Downsampled from (359545, 3) to (6037, 3) points (ground)\n",
      "Downsampled from (796774, 3) to (9306, 3) points (non-ground)\n",
      "Downsampled from (383977, 3) to (6355, 3) points (ground)\n",
      "Downsampled from (790877, 3) to (8685, 3) points (non-ground)\n",
      "Downsampled from (627610, 3) to (6811, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "overlap = 3\n",
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None,semantics=False):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 and semantics == False : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else : \n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "        \n",
    "    if semantics : \n",
    "        pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    else : \n",
    "        pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_2d_list(my_list, target_sublist):\n",
    "    for i, sublist in enumerate(my_list):\n",
    "        if sublist == list(target_sublist): \n",
    "            return i\n",
    "    return None  # Sublist not found in the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_cols(colors,labels,pcd):\n",
    "\tcur_cols = np.asarray(pcd.colors)\n",
    "\tunique_labels = list(np.unique(labels))\n",
    "\tnew_labels = np.zeros_like(labels)\n",
    "\tfor label in unique_labels: \n",
    "\t\tidcs = np.where(labels == label)[0]\n",
    "\t\tcol = cur_cols[idcs[0]]\n",
    "\t\tidx = find_index_2d_list(colors,col)\n",
    "\t\tnew_labels[idcs] = idx \n",
    "\treturn new_labels\n",
    "\t\n",
    "def normalize_vector(v):\n",
    "    \"\"\"\n",
    "    Normalize a 2D vector to have unit norm.\n",
    "\n",
    "    Parameters:\n",
    "    - v: A tuple or list representing the 2D vector (x, y).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple representing the normalized 2D vector.\n",
    "    \"\"\"\n",
    "    norm = np.sqrt(v[0]**2 + v[1]**2)\n",
    "    return np.array([v[0] / norm, v[1] / norm])\n",
    "\n",
    "def find_unit_norm_orthogonal_vectors(v):\n",
    "    \"\"\"\n",
    "    Find two orthogonal vectors to a given 2D vector v, both of unit norm.\n",
    "\n",
    "    Parameters:\n",
    "    - v: A tuple or list representing the 2D vector (x, y).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing two tuples, each representing a unit norm orthogonal vector.\n",
    "    \"\"\"\n",
    "    # Given vector v = (x, y)\n",
    "    x, y = v\n",
    "\n",
    "    # Calculate orthogonal vectors\n",
    "    v_perp1 = (y, -x)\n",
    "    v_perp2 = (-y, x)\n",
    "\n",
    "    # Normalize the orthogonal vectors\n",
    "    v_perp1_normalized = normalize_vector(v_perp1)\n",
    "    v_perp2_normalized = normalize_vector(v_perp2)\n",
    "\n",
    "    return v_perp1_normalized, v_perp2_normalized\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sequence number 30\n",
      "Start of sequence 0\n",
      "7776 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 58 cut regions\n",
      "Ratio of points in top 3 groups: 0.25655864197530864\n",
      "Start of sequence 0\n",
      "5294 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 262 cut regions\n",
      "Ratio of points in top 3 groups: 0.3917642614280317\n",
      "Start of sequence 1\n",
      "7216 points in downsampled chunk (major)\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0\n",
    "theta = 0.0\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.1\n",
    "proximity_threshold = 1.0\n",
    "ncuts_threshold = 0.09\n",
    "        \n",
    "out_name = 'sam_only' + str(SEQUENCE_NUM) \n",
    "# Generate 30 different colors\n",
    " \n",
    "\n",
    "COLORS = generate_random_colors(400)\n",
    "COLORS = [(col[0]/255.,col[1]/255.,col[2]/255.) for col in COLORS]\n",
    "\n",
    "\n",
    "out_kitti = out_chunks + 'out_kitti' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_kitti) == True : \n",
    "        shutil.rmtree(out_kitti)\n",
    "\n",
    "os.makedirs(out_kitti)\n",
    "        \n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "'''\n",
    "if os.path.exists(out_kitti_instance) == True : \n",
    "        shutil.rmtree(out_kitti_instance)\n",
    "os.makedirs(out_kitti_instance)\n",
    "'''\n",
    "\n",
    "\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "'''\n",
    "if os.path.exists(out_kitti_semantic) == True : \n",
    "        shutil.rmtree(out_kitti_semantic)\n",
    "os.makedirs(out_kitti_semantic)\n",
    "'''\n",
    "\n",
    "limit = -1 ##use this for experiments to run limit chunks numberss\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "semantics = np.hstack((kitti_labels_orig['seg_nonground'].reshape(-1,),kitti_labels_orig['seg_ground'].reshape(-1,)))\n",
    "\n",
    "instances = np.hstack((kitti_labels_orig['instance_nonground'],kitti_labels_orig['instance_ground']))\n",
    "                \n",
    "merge_pcd = o3d.geometry.PointCloud()    \n",
    "                \n",
    "print(\"total sequence number\",len(center_ids))\n",
    "for sequence in range(0,len(center_ids)):\n",
    "        if NCUT_ground == False : \n",
    "                \n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,list(indices),pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,list(sampled_indices_global),\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold)\n",
    "                \n",
    "                ground_out,file_name = ncuts_chunk(dataset,list(indices_ground),pcd_chunk_ground,None,\n",
    "                        pcd_ground_chunks_major_downsampling,\n",
    "                        pcd_ground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,list(sampled_indices_global),\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=1.0,beta=0.0,gamma=1.0,theta=1.0,\n",
    "                        proximity_threshold=1.0,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=True,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=0.001,use_z=False)\n",
    "                #o3d.visualization.draw_geometries([pcd_chunk + ground_out])\n",
    "                \n",
    "                #o3d.visualization.draw_geometries([ground_out])\n",
    "                \n",
    "                \n",
    "                seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                \n",
    "                file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "\n",
    "                kitti_chunk = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['semantic'][sequence].reshape(-1,),\n",
    "                                        colors=COLORS,gt_labels=semantics,semantics=True\n",
    "                                        )\n",
    "                \n",
    "                kitti_chunk_instance = color_pcd_by_labels(pcd_chunk,kitti_labels['nonground']['instance'][sequence].reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(pcd_chunk_ground,inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_semantic_ground = color_pcd_by_labels(pcd_chunk_ground,seg_ground.reshape(-1,),\n",
    "                                        colors=COLORS,gt_labels=semantics,semantics=True)\n",
    "                \n",
    "                #o3d.visualization.draw_geometries([kitti_chunk_instance + kitti_chunk_instance_ground])\n",
    "                #o3d.visualization.draw_geometries([pcd_chunk + pcd_chunk_ground])\n",
    "                semantic_labels = np.hstack(( kitti_labels['nonground']['semantic'][sequence].reshape(-1,),seg_ground.reshape(-1,)))\n",
    "                np.savez(out_kitti_semantic + file_name.split('.')[0] + '.npz',labels=semantic_labels)\n",
    "                \n",
    "                o3d.io.write_point_cloud(out_folder_ncuts + file_name, pcd_chunk + ground_out , write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                #o3d.io.write_point_cloud(out_kitti_semantic + file_name, kitti_chunk + kitti_chunk_semantic_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_pcds(out_folder_ncuts):\n",
    "        point_clouds = []\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(out_folder_ncuts)\n",
    "        files.sort()\n",
    "\n",
    "        # Filter files with a .pcd extension\n",
    "        pcd_files = [file for file in files if file.endswith(\".pcd\")]\n",
    "        print(pcd_files)\n",
    "        # Load each point cloud and append to the list\n",
    "        for pcd_file in pcd_files:\n",
    "                file_path = os.path.join(out_folder_ncuts, pcd_file)\n",
    "                point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "                point_clouds.append(point_cloud)\n",
    "        return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_unite_gt(chunks):\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in chunks[1:]:\n",
    "        merge += new_chunk\n",
    "    \n",
    "    merge.remove_duplicated_points()\n",
    "    return merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def merge_chunks_unite_instances2(chunks: list, icp=False):\n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    chunk_means = [np.mean(np.asarray(chunk.points), axis=0) for chunk in chunks]\n",
    "\n",
    "    last_chunk = chunks[0] \n",
    "    merge = o3d.geometry.PointCloud()\n",
    "    merge += last_chunk\n",
    "\n",
    "    for new_chunk in tqdm(chunks[1:]):\n",
    "\n",
    "        new_chunk_center = np.asarray(new_chunk.points)\n",
    "        \n",
    "        x,y,z = new_chunk_center[:,0].mean(),new_chunk_center[:,1].mean(),new_chunk_center[:,2].mean()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        pcd_tree = o3d.geometry.KDTreeFlann(merge)\n",
    "        query_point = np.array([x, y, z])  # Replace x, y, z with your point's coordinates\n",
    "        distance_threshold = 35.0  # Adjust this value to your desired distance threshold\n",
    "        \n",
    "        \n",
    "        \n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(query_point, distance_threshold)\n",
    "\n",
    "        # Extract the points within the specified distance\n",
    "        if k > 0:\n",
    "            points_within_distance = np.asarray(merge.points)[idx]\n",
    "        else:\n",
    "            points_within_distance = np.array([])\n",
    "\n",
    "        extracted_pcd = o3d.geometry.PointCloud()\n",
    "        extracted_pcd.points = o3d.utility.Vector3dVector(points_within_distance)\n",
    "        extracted_pcd.colors = o3d.utility.Vector3dVector(np.asarray(merge.colors)[idx])\n",
    "        '''\n",
    "        side_length = 40 \n",
    "        center_point = np.array([x, y, z])  # Replace x, y, z with your point's coordinates\n",
    "        half_side = side_length / 2.0\n",
    "        min_bound = center_point - half_side\n",
    "        max_bound = center_point + half_side\n",
    "        aabb = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound, max_bound=max_bound)\n",
    "\n",
    "        # Crop the point cloud\n",
    "        extracted_pcd = merge.crop(aabb)\n",
    "\n",
    "        \n",
    "        points_1 = np.asarray(extracted_pcd.points)\n",
    "        points_2 = np.asarray(new_chunk.points)\n",
    "\n",
    "        colors_1 = np.asarray(extracted_pcd.colors)\n",
    "        colors_2 = np.asarray(new_chunk.colors)\n",
    "\n",
    "        unique_colors_1 = np.unique(colors_1, axis=0)\n",
    "        unique_colors_2 = np.unique(colors_2, axis=0)\n",
    "\n",
    "        instance2point_1 = {}\n",
    "        for i in range(unique_colors_1.shape[0]):\n",
    "            if not np.all(unique_colors_1[i] == 0.0): # Streets are black\n",
    "                instance2point_1[i] = {}\n",
    "                inds = np.where(np.all(colors_1 == unique_colors_1[i], axis=1))[0]\n",
    "                instance2point_1[i][\"points\"] = points_1[inds]\n",
    "                instance2point_1[i][\"inds\"] = inds\n",
    "\n",
    "        instance2point_2 = {}\n",
    "        for i in range(unique_colors_2.shape[0]):\n",
    "            if not np.all(unique_colors_2[i] == 0.0): # Streets are black\n",
    "                instance2point_2[i] = {}\n",
    "                inds = np.where(np.all(colors_2 == unique_colors_2[i], axis=1))[0]\n",
    "                instance2point_2[i][\"points\"] = points_2[inds]\n",
    "                instance2point_2[i][\"inds\"] = inds\n",
    "        \n",
    "        id_pairs_iou = []\n",
    "        for id_1, entries_1 in instance2point_1.items():\n",
    "            points1 = entries_1[\"points\"]\n",
    "            min_bound = np.min(points1, axis=0)\n",
    "            max_bound = np.max(points1, axis=0)\n",
    "            association = []\n",
    "            for id_2, entries_2 in instance2point_2.items():\n",
    "                points2 = entries_2[\"points\"]\n",
    "                intersection = np.where(np.all(points2 >= min_bound, axis=1) & np.all(points2 <= max_bound, axis=1))[0].shape[0]\n",
    "                if intersection > 0:\n",
    "                    union = len(np.unique(np.concatenate((points1, points2))))\n",
    "                    iou = float(intersection) / float(union)\n",
    "                    if iou > 0.01:\n",
    "                        association.append((id_2, iou))\n",
    "            if len(association) != 0:\n",
    "                for (association_id, iou) in association:\n",
    "                    id_pairs_iou.append((id_1, (association_id, iou)))\n",
    "        \n",
    "        ids_chunk_1 = []\n",
    "        ids_chunk_2 = []\n",
    "        ious = []\n",
    "        for id1, (id2, iou) in id_pairs_iou:\n",
    "            if id2 not in ids_chunk_2:\n",
    "                ids_chunk_1.append(id1)\n",
    "                ids_chunk_2.append(id2)\n",
    "                ious.append(iou)\n",
    "            else:\n",
    "                i = ids_chunk_2.index(id2)\n",
    "                if iou > ious[i]:\n",
    "                    ious[i] = iou\n",
    "                    ids_chunk_1[i] = id1\n",
    "\n",
    "        for id1, id2 in zip(ids_chunk_1, ids_chunk_2):\n",
    "            inds2 = instance2point_2[id2][\"inds\"]\n",
    "            colors_2[inds2] = unique_colors_1[id1]\n",
    "\n",
    "        new_chunk_recolored = o3d.geometry.PointCloud()\n",
    "        new_chunk_recolored.points = new_chunk.points\n",
    "        new_chunk_recolored.colors = o3d.utility.Vector3dVector(colors_2)\n",
    "        last_chunk = new_chunk_recolored\n",
    "\n",
    "        merge += new_chunk_recolored\n",
    "        merge.remove_duplicated_points()\n",
    "\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_kitti = out_chunks + 'out_kitti' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "point_clouds = get_merge_pcds(out_folder_ncuts)[:-1]\n",
    "#point_clouds_kitti = get_merge_pcds(out_kitti)[:-1]\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)[:-1]\n",
    "#point_clouds_kitti_semantic = get_merge_pcds(out_kitti_semantic)[:-1]\n",
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "\n",
    "\n",
    "#merge_dbscan = merge_chunks_unite_instances(point_clouds_dbscan)\n",
    "\n",
    "#merge_kitti = merge_unite_gt(point_clouds_kitti)\n",
    "merge_kitti_instance = merge_unite_gt(point_clouds_kitti_instances)\n",
    "#merge_kitti_semantic = merge_unite_gt(point_clouds_kitti_semantic)\n",
    "\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_semantic7.pcd\", merge_kitti_semantic, write_ascii=False, compressed=False, print_progress=False)\n",
    "o3d.io.write_point_cloud(out_folder + out_name + str(SEQUENCE_NUM) + \".pcd\", merge, write_ascii=False, compressed=False, print_progress=False)\n",
    "print(merge_kitti_instance)\n",
    "print(merge)\n",
    "#o3d.io.write_point_cloud(out_folder + \"merge_part_kitti_instance\" + str(SEQUENCE_NUM) +  \".pcd\", merge_kitti_instance, write_ascii=False, compressed=False, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "merge = o3d.io.read_point_cloud(out_folder + out_name + str(SEQUENCE_NUM) +  \".pcd\")\n",
    "unique_colors, labels_ncuts = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "merge_kitti_instance = o3d.io.read_point_cloud(out_folder + \"merge_part_kitti_instance\" + str(SEQUENCE_NUM) +  \".pcd\")\n",
    "unique_colors, labels_kitti = np.unique(np.asarray(merge_kitti_instance.colors),axis=0, return_inverse=True)\n",
    "print(merge_kitti_instance)\n",
    "def intersect(pred_indices, gt_indices):\n",
    "        intersection = np.intersect1d(pred_indices, gt_indices)\n",
    "        return intersection.size / pred_indices.shape[0]\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_batch(unique_pred, preds, labels, gt_idcs, threshold, new_ncuts_labels):\n",
    "    pred_idcs = np.where(preds == unique_pred)[0]\n",
    "    cur_intersect = np.sum(np.isin(pred_idcs, gt_idcs))\n",
    "    if cur_intersect > threshold * len(pred_idcs): \n",
    "        new_ncuts_labels[pred_idcs] = 0\n",
    "\n",
    "def remove_semantics(labels, preds, threshold=0.8, num_threads=None):\n",
    "    gt_idcs = np.where(labels == 0)[0]\n",
    "    new_ncuts_labels = preds.copy()\n",
    "    unique_preds = np.unique(preds)\n",
    "    \n",
    "    if num_threads is None:\n",
    "        num_threads = min(len(unique_preds), 8)  # Default to 8 threads if not specified\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for i in tqdm(unique_preds):\n",
    "            futures.append(executor.submit(process_batch, i, preds, labels, gt_idcs, threshold, new_ncuts_labels))\n",
    "        \n",
    "        # Wait for all tasks to complete\n",
    "        for future in tqdm(futures, total=len(futures), desc=\"Processing\"):\n",
    "            future.result()  # Get the result to catch any exceptions\n",
    "        \n",
    "    return new_ncuts_labels\n",
    "\n",
    "print('remove semantics')\n",
    "new_ncuts_labels = remove_semantics(labels_kitti,labels_ncuts)\n",
    "\n",
    "\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "\n",
    "metrics_ncuts.update_stats(labels_ncuts,new_ncuts_labels,labels_kitti)\n",
    "\n",
    "#merge_vis = color_pcd_by_labels(merge,new_ncuts_labels)\n",
    "#o3d.visualization.draw_geometries([merge_vis])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
