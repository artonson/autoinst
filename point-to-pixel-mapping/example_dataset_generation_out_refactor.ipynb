{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/Users/cedric/Datasets/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM)\n",
    "\n",
    "ind_start = 0\n",
    "ind_end = 100\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "\n",
    "\n",
    "out_folder = 'pcd_preprocessed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchWorkpp::PatchWorkpp() - INITIALIZATION COMPLETE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_and_save_point_clouds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mind_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43mind_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminor_voxel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminor_voxel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmajor_voxel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmajor_voxel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mout_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43msequence_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEQUENCE_NUM\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/dataset_utils.py:38\u001b[0m, in \u001b[0;36mprocess_and_save_point_clouds\u001b[0;34m(dataset, ind_start, ind_end, ground_segmentation_method, icp, minor_voxel_size, major_voxel_size, out_folder, sequence_num)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(out_folder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m : \n\u001b[1;32m     36\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(out_folder)\n\u001b[0;32m---> 38\u001b[0m pcd_ground, pcd_nonground, all_poses, T_pcd \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_pointcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_segmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mground_segmentation_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43micp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Downsampling\u001b[39;00m\n\u001b[1;32m     41\u001b[0m pcd_ground_minor \u001b[38;5;241m=\u001b[39m pcd_ground\u001b[38;5;241m.\u001b[39mvoxel_down_sample(voxel_size\u001b[38;5;241m=\u001b[39mminor_voxel_size)\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/aggregate_pointcloud.py:102\u001b[0m, in \u001b[0;36maggregate_pointcloud\u001b[0;34m(dataset, ind_start, ind_end, icp, icp_threshold, ground_segmentation)\u001b[0m\n\u001b[1;32m     99\u001b[0m         reg_p2l \u001b[38;5;241m=\u001b[39m registration\u001b[38;5;241m.\u001b[39mregistration_icp(pcd, merge, icp_threshold, transform, registration\u001b[38;5;241m.\u001b[39mTransformationEstimationPointToPlane(), registration\u001b[38;5;241m.\u001b[39mICPConvergenceCriteria(max_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    100\u001b[0m         transform \u001b[38;5;241m=\u001b[39m reg_p2l\u001b[38;5;241m.\u001b[39mtransformation\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mpcd_ground\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_normals\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKDTreeSearchParamHybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_nn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     pcd_nonground\u001b[38;5;241m.\u001b[39mestimate_normals(search_param\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mKDTreeSearchParamHybrid(radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,max_nn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m))\n\u001b[1;32m    105\u001b[0m map_pcd_ground \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pcd_ground\u001b[38;5;241m.\u001b[39mtransform(transform)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                              major_voxel_size=major_voxel_size,\n",
    "                              out_folder=out_folder,sequence_num=SEQUENCE_NUM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "pcd_ground_minor, pcd_nonground_minor,\\\n",
    "\tall_poses, T_pcd, first_position = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses, positions, \\\n",
    "sampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (441534, 3) to (7148, 3) points (non-ground)\n",
      "Downsampled from (210612, 3) to (4546, 3) points (ground)\n",
      "Downsampled from (328813, 3) to (5497, 3) points (non-ground)\n",
      "Downsampled from (204410, 3) to (4111, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices, center_positions, \\\n",
    "center_ids, chunk_bounds = chunk_and_downsample_point_clouds(pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, overlap=overlap, major_voxel_size=major_voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of sequence  0\n",
      "9619 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 74 cut regions\n",
      "Ratio of points in top 3 groups: 0.2504418338704647\n",
      "Pointcloud written to file\n",
      "Start of sequence  1\n",
      "6468 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 40 cut regions\n",
      "Ratio of points in top 3 groups: 0.2911255411255411\n",
      "Pointcloud written to file\n",
      "Start of sequence  2\n",
      "7564 points in downsampled chunk (major)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "There are 37 cut regions\n",
      "Ratio of points in top 3 groups: 0.2513220518244315\n",
      "Pointcloud written to file\n",
      "Start of sequence  3\n",
      "5933 points in downsampled chunk (major)\n"
     ]
    }
   ],
   "source": [
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "\n",
    "for sequence in range(len(center_ids)):\n",
    "\n",
    "    print(\"Start of sequence \", sequence)\n",
    "\n",
    "    first_id = patchwise_indices[sequence][0]\n",
    "    center_id = center_ids[sequence]\n",
    "    center_position = center_positions[sequence]\n",
    "    chunk_indices = indices[sequence]\n",
    "\n",
    "    cam_indices_global, hpr_mask_indices = get_indices_feature_reprojection(sampled_indices_global, first_id, adjacent_frames=(16,13)) \n",
    "    \n",
    "    pcd_chunk = pcd_nonground_chunks[sequence]\n",
    "    pcd_ground_chunk = pcd_ground_chunks[sequence]\n",
    "    chunk_major = pcd_nonground_chunks_major_downsampling[sequence]\n",
    "\n",
    "    points_major = np.asarray(chunk_major.points)\n",
    "    num_points_major = points_major.shape[0]   \n",
    "\n",
    "    print(num_points_major, \"points in downsampled chunk (major)\")\n",
    "\n",
    "    #tarl_features = tarl_features_per_patch(dataset, chunk_major, center_id, T_pcd, center_position, sampled_indices_global, chunk_size, major_voxel_size)\n",
    "\n",
    "    cams = [\"cam2\", \"cam3\"]\n",
    "\n",
    "    sam_features_minor, chunk_minor = image_based_features_per_patch(dataset, pcd_nonground_minor, chunk_indices, T_pcd, cam_indices_global, cams, cam_id=0, hpr_radius=2000, dino=False, rm_perp=0.0)\n",
    "    #point2dino\n",
    "    #dinov2_features_minor = dinov2_mean(point2dino)\n",
    "    \n",
    "    sam_features_major = -1 * np.ones((num_points_major, sam_features_minor.shape[1]))\n",
    "    #dinov2_features_major = np.zeros((num_points_major, dinov2_features_minor.shape[1])) \n",
    "\n",
    "    sam_features_major = kDTree_1NN_feature_reprojection(sam_features_major, chunk_major, sam_features_minor, chunk_minor)\n",
    "    #dinov2_features_major = kDTree_1NN_feature_reprojection(dinov2_features_major, chunk_major, dinov2_features_minor, chunk_minor)\n",
    "\n",
    "    zero_rows = np.sum(~np.array(sam_features_major).any(1))\n",
    "    ratio = zero_rows / num_points_major\n",
    "\n",
    "    if ratio > 0.3:\n",
    "        print(\"The ratio of points without image-based features is\", ratio, \". Skipping this chunk.\")\n",
    "        continue\n",
    "\n",
    "    spatial_distance = cdist(points_major, points_major)\n",
    "    #dinov2_distance = cdist(dinov2_features_major, dinov2_features_major)\n",
    "    #tarl_distance = cdist(tarl_features, tarl_features)\n",
    "\n",
    "    proximity_threshold = 1 # meters that points can be apart from each other and still be considered neighbors\n",
    "    alpha = 6.0 # weight of the spatial proximity term \n",
    "    beta = 0.0 # weight of the label similarity term\n",
    "    gamma = 0.0 # weight of the dinov2 feature similarity term\n",
    "    theta = 3.0 # weight of the tarl feature similarity term\n",
    "\n",
    "    sam_edge_weights, mask = sam_label_distance(sam_features_major, spatial_distance, proximity_threshold, beta)\n",
    "    #spatial_edge_weights = mask * np.exp(-alpha * spatial_distance)\n",
    "    #dinov2_edge_weights = mask * np.exp(-gamma * dinov2_distance)\n",
    "    #tarl_edge_weights = mask * np.exp(-theta * tarl_distance)\n",
    "\n",
    "    A = sam_edge_weights #spatial_edge_weights * sam_edge_weights * dinov2_edge_weights * tarl_edge_weights\n",
    "    print(\"Adjacency Matrix built\")\n",
    "\n",
    "    # Remove isolated points\n",
    "    chunk_major, A = remove_isolated_points(chunk_major, A)\n",
    "    print(num_points_major - np.asarray(chunk_major.points).shape[0], \"isolated points removed\")\n",
    "    num_points_major = np.asarray(chunk_major.points).shape[0]\n",
    "\n",
    "    print(\"Start of normalized Cuts\")\n",
    "    grouped_labels = normalized_cut(A, np.arange(num_points_major), T = 0.08)\n",
    "    num_groups = len(grouped_labels)\n",
    "    print(\"There are\", num_groups, \"cut regions\")\n",
    "\n",
    "    sorted_groups = sorted(grouped_labels, key=lambda x: len(x))\n",
    "    num_points_top3 = np.sum([len(g) for g in sorted_groups[-3:]])\n",
    "    top3_ratio = num_points_top3 / num_points_major\n",
    "    print(\"Ratio of points in top 3 groups:\", top3_ratio)\n",
    "\n",
    "    random_colors = generate_random_colors(600)\n",
    "\n",
    "    pcd_color = np.zeros((num_points_major, 3))\n",
    "\n",
    "    for i, s in enumerate(grouped_labels):\n",
    "        for j in s:\n",
    "            pcd_color[j] = np.array(random_colors[i]) / 255\n",
    "\n",
    "    pcd_chunk.paint_uniform_color([0, 0, 0])\n",
    "    colors = kDTree_1NN_feature_reprojection(np.asarray(pcd_chunk.colors), pcd_chunk, pcd_color, chunk_major)\n",
    "    pcd_chunk.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    inliers = get_statistical_inlier_indices(pcd_ground_chunk)\n",
    "    ground_inliers = get_subpcd(pcd_ground_chunk, inliers)\n",
    "    mean_hight = np.mean(np.asarray(ground_inliers.points)[:,2])\n",
    "    cut_hight = get_subpcd(ground_inliers, np.where(np.asarray(ground_inliers.points)[:,2] < (mean_hight + 0.2))[0])\n",
    "    cut_hight.paint_uniform_color([0, 0, 0])\n",
    "\n",
    "    merged_chunk = pcd_chunk + cut_hight\n",
    "\n",
    "    index_file = str(center_id).zfill(6) + '.pcd'\n",
    "    file = os.path.join(\"test_data\", index_file)\n",
    "\n",
    "    o3d.io.write_point_cloud(file, merged_chunk, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "    print(\"Pointcloud written to file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the chunks to one large Map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000061.pcd', '000088.pcd', '000117.pcd']\n"
     ]
    }
   ],
   "source": [
    "point_clouds = []\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(\"test_data\")\n",
    "files.sort()\n",
    "\n",
    "# Filter files with a .pcd extension\n",
    "pcd_files = [file for file in files if file.endswith(\".pcd\")][:3]\n",
    "print(pcd_files)\n",
    "# Load each point cloud and append to the list\n",
    "for pcd_file in pcd_files:\n",
    "    file_path = os.path.join(\"test_data\", pcd_file)\n",
    "    point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "    point_clouds.append(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "o3d.io.write_point_cloud(\"test_data/merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    sam_folder_name=\"sam_pred_medium\",\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kDTree_1NN_feature_reprojection(features_to, pcd_to, features_from, pcd_from, labels=None,max_radius=None, no_feature_label=[1,0,0]):\n",
    "    '''\n",
    "    Args:\n",
    "        pcd_from: point cloud to be projected\n",
    "        pcd_to: point cloud to be projected to\n",
    "        search_method: search method (\"radius\", \"knn\")\n",
    "        search_param: search parameter (radius or k)\n",
    "    Returns:\n",
    "        features_to: features projected on pcd_to\n",
    "    '''\n",
    "    from_tree = o3d.geometry.KDTreeFlann(pcd_from)\n",
    "    labels_output = np.ones(np.asarray(pcd_to.points).shape[0],) * -1\n",
    "    unique_colors = list(np.unique(np.asarray(pcd_from.colors),axis=0)) \n",
    "    \n",
    "    for i, point in enumerate(np.asarray(pcd_to.points)):\n",
    "\n",
    "        [_, idx, _] = from_tree.search_knn_vector_3d(point, 1)\n",
    "        if max_radius is not None:\n",
    "            if np.linalg.norm(point - np.asarray(pcd_from.points)[idx[0]]) > max_radius:\n",
    "                features_to[i,:] = no_feature_label\n",
    "                if labels is not None : \n",
    "                    labels[i] = -1\n",
    "                    labels_output[i] = -1 \n",
    "            else:\n",
    "                features_to[i,:] = features_from[idx[0]]\n",
    "                labels_output[i] = np.where((unique_colors == features_from[idx[0]]).all(axis=1))[0]\n",
    "        else:\n",
    "            features_to[i,:] = features_from[idx[0]]\n",
    "            labels_output[i] = np.where((unique_colors == features_from[idx[0]]).all(axis=1))[0]\n",
    "        \n",
    "        \n",
    "    if labels is not None : \n",
    "        return features_to,labels, labels_output\n",
    "    else : \n",
    "        return features_to, None, labels_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def color_pcd_by_labels(pcd, labels):\n",
    "    \n",
    "    colors = generate_random_colors(500)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(np.zeros(np.asarray(pcd.points).shape))\n",
    "    \n",
    "    unique_labels = list(np.unique(labels)) \n",
    "    for i in range(len(pcd_colored.points)):\n",
    "        if labels[i] != (-1):\n",
    "            color = colors[unique_labels.index(labels[i])]\n",
    "            pcd_colored.colors[i] = np.array(color) / 255\n",
    "\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_443508/1041532388.py:14: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  labeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m local_pcd\u001b[39m.\u001b[39mnormals \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mutility\u001b[39m.\u001b[39mVector3dVector([])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m local_pcd\u001b[39m.\u001b[39mpaint_uniform_color([\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m colors, labels,local_labels \u001b[39m=\u001b[39m kDTree_1NN_feature_reprojection(np\u001b[39m.\u001b[39;49masarray(local_pcd\u001b[39m.\u001b[39;49mcolors), local_pcd, np\u001b[39m.\u001b[39;49masarray(merge\u001b[39m.\u001b[39;49mcolors), merge,panoptic_labels, max_radius\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m labeled_pcd \u001b[39m=\u001b[39m color_pcd_by_labels(labeled_pcd,labels\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m local_pcd\u001b[39m.\u001b[39mcolors \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mutility\u001b[39m.\u001b[39mVector3dVector(colors)\n",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m [_, idx, _] \u001b[39m=\u001b[39m from_tree\u001b[39m.\u001b[39msearch_knn_vector_3d(point, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m max_radius \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(point \u001b[39m-\u001b[39;49m np\u001b[39m.\u001b[39;49masarray(pcd_from\u001b[39m.\u001b[39;49mpoints)[idx[\u001b[39m0\u001b[39;49m]]) \u001b[39m>\u001b[39m max_radius:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         features_to[i,:] \u001b[39m=\u001b[39m no_feature_label\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/example_dataset_generation_out.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m : \n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/numpy/linalg/linalg.py:2530\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2529\u001b[0m     sqnorm \u001b[39m=\u001b[39m dot(x, x)\n\u001b[0;32m-> 2530\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2531\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   2532\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mreshape(ndim\u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from open3d.pipelines import registration\n",
    "import numpy as np \n",
    "merge = o3d.io.read_point_cloud(\"test_data/merge_part.pcd\")\n",
    "merge.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\n",
    "for i in range(0,100):\n",
    "\tlocal_pcd = o3d.geometry.PointCloud()\n",
    "\tlocal_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\t\n",
    "\t\n",
    "\t## label visualization \n",
    "\tlabeled_pcd = o3d.geometry.PointCloud()\n",
    "\tlabeled_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\tlabeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n",
    "\tpanoptic_labels = dataset[i].panoptic_labels # semantics + panoptics combined \n",
    "\tsemantic_labels = dataset[i].semantic_labels\n",
    "\tinstance_labels = dataset[i].instance_labels\n",
    "\tintensity = dataset[i].intensity\n",
    "\t\n",
    "\t\n",
    "\ttransform = dataset.get_pose(i)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tlocal_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\treg_p2l = registration.registration_icp(local_pcd, merge, 0.9, transform, registration.TransformationEstimationPointToPlane(), registration.ICPConvergenceCriteria(max_iteration=1000))\n",
    "\ttransform = reg_p2l.transformation\n",
    "\tlocal_pcd.transform(transform)\n",
    "\t\n",
    "\tlocal_pcd.normals = o3d.utility.Vector3dVector([])\n",
    "\t\n",
    "\tlocal_pcd.paint_uniform_color([0, 0, 0])\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tcolors, labels,local_labels = kDTree_1NN_feature_reprojection(np.asarray(local_pcd.colors), local_pcd, np.asarray(merge.colors), merge,panoptic_labels, max_radius=0.2)\n",
    "\tlabeled_pcd = color_pcd_by_labels(labeled_pcd,labels.reshape(-1,))\n",
    "\tlocal_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\to3d.io.write_point_cloud(\"test_data/test.pcd\", local_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t#labeled_pcd.translate([0,120,0])\n",
    "\t#o3d.visualization.draw_geometries([local_pcd,labeled_pcd])\n",
    "\tunique_colors, labels = np.unique(colors, axis=0, return_inverse=True)\n",
    "\tunseen_mask = np.all(colors == [1,0,0], axis=1)\n",
    "\tlabels[unseen_mask] = -1\n",
    "\tstreet_mask = np.all(colors == [0,0,0], axis=1)\n",
    "\tlabels[street_mask] = 1\n",
    "\tnp.savez('output_files/7_tarl/ ' + str(i) + '.npz',labels=labels)\n",
    "\n",
    "\t\n",
    "\n",
    "\tnp.savez('output_files/7_original/' + str(i) + '.npz',ncut_labels=local_labels,kitti_labels=labels,pts=np.asarray(local_pcd.points),           \n",
    "\tintensities=intensity,kitti_labels_semantic=semantic_labels,kitti_labels_instance=instance_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_443508/69016850.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  xyz = data['pts'].astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "with np.load('output_files/7_original/0.npz') as data:\n",
    "            xyz = data['pts'].astype(np.float)\n",
    "            labels = data['ncut_labels'].astype(np.int32)  \n",
    "            kitti_labels = data['kitti_labels']\n",
    "            intensity = data['intensities']\n",
    "            \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "pcd = color_pcd_by_labels(pcd,labels)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
