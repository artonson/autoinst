{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from ncuts_utils_ablations import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_chunks_unite_instances2, remove_semantics, get_merge_pcds, merge_unite_gt\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import shutil\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets2/semantic_kitti/')\n",
    "end_inds = {0:4541,1:1100,2:4661,3:800,4:271,5:2761,6:1101,7:1100,8:4071,9:1591,10:1201}\n",
    "SEQUENCE_NUM = 7\n",
    "old = False \n",
    "\n",
    "ind_start = 0\n",
    "ind_end = end_inds[SEQUENCE_NUM]\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = '../../pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_folder_ncuts) == True:\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = '../../pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_folder + 'all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz',\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n",
    "        #o3d.visualization.draw_geometries([pcd_nonground_minor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 11580178 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "print(pcd_ground_minor)\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz') as data :\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz') == False : \n",
    "\tprint(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz')\n",
    "\tposes, positions, \\\n",
    "\tsampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start,sequence_num=SEQUENCE_NUM,out_folder=out_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(f'{out_folder}subsampled_data{SEQUENCE_NUM}_0.npz') as data:\n",
    "\tposes=data['poses']\n",
    "\tpositions=data['positions']\n",
    "\tsampled_indices_local = data['sampled_indices_local']\n",
    "\tsampled_indices_global=data['sampled_indices_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 293/681 [00:15<00:17, 22.23it/s]"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels, obbs = chunk_and_downsample_point_clouds(dataset,pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None,semantics=False):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 and semantics == False : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else :\n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "    \n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_normalized = {\n",
    "    0: [0.0, 0.0, 0.0],\n",
    "    1: [0.0, 0.0, 1.0],\n",
    "    10: [0.9607843137254902, 0.5882352941176471, 0.39215686274509803],\n",
    "    11: [0.9607843137254902, 0.9019607843137255, 0.39215686274509803],\n",
    "    13: [0.9803921568627451, 0.3137254901960784, 0.39215686274509803],\n",
    "    15: [0.5882352941176471, 0.23529411764705882, 0.11764705882352941],\n",
    "    16: [1.0, 0.0, 0.0],\n",
    "    18: [0.7058823529411765, 0.11764705882352941, 0.3137254901960784],\n",
    "    20: [1.0, 0.0, 0.0],\n",
    "    30: [0.11764705882352941, 0.11764705882352941, 1.0],\n",
    "    31: [0.7843137254901961, 0.1568627450980392, 1.0],\n",
    "    32: [0.35294117647058826, 0.11764705882352941, 0.5882352941176471],\n",
    "    40: [1.0, 0.0, 1.0],\n",
    "    44: [1.0, 0.5882352941176471, 1.0],\n",
    "    48: [0.29411764705882354, 0.0, 0.29411764705882354],\n",
    "    49: [0.29411764705882354, 0.0, 0.6862745098039216],\n",
    "    50: [0.0, 0.7843137254901961, 1.0],\n",
    "    51: [0.19607843137254902, 0.47058823529411764, 1.0],\n",
    "    52: [0.0, 0.5882352941176471, 1.0],\n",
    "    60: [0.6666666666666666, 1.0, 0.5882352941176471],\n",
    "    70: [0.0, 0.6862745098039216, 0.0],\n",
    "    71: [0.0, 0.23529411764705882, 0.5294117647058824],\n",
    "    72: [0.3137254901960784, 0.9411764705882353, 0.5882352941176471],\n",
    "    80: [0.5882352941176471, 0.9411764705882353, 1.0],\n",
    "    81: [0.0, 0.0, 1.0],\n",
    "    99: [1.0, 1.0, 0.19607843137254902],\n",
    "    252: [0.9607843137254902, 0.5882352941176471, 0.39215686274509803],\n",
    "    256: [1.0, 0.0, 0.0],\n",
    "    253: [0.7843137254901961, 0.1568627450980392, 1.0],\n",
    "    254: [0.11764705882352941, 0.11764705882352941, 1.0],\n",
    "    255: [0.35294117647058826, 0.11764705882352941, 0.5882352941176471],\n",
    "    257: [0.9803921568627451, 0.3137254901960784, 0.39215686274509803],\n",
    "    258: [0.7058823529411765, 0.11764705882352941, 0.3137254901960784],\n",
    "    259: [1.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "reverse_color_dict = {tuple(v): k for k, v in color_dict_normalized.items()}\n",
    "\n",
    "\n",
    "def color_pcd_kitti(pcd, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    pcd_colors = np.zeros_like(np.asarray(pcd.points))\n",
    "    for i in unique_labels:\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        pcd_colors[idcs] = np.array(color_dict_normalized[int(i)])\n",
    "\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    return pcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_map(inst_labels, sem_labels, sem_classes=[49, 50, 51, 70, 72]):\n",
    "\n",
    "    semantic_map = {}\n",
    "    total_merges = 0\n",
    "\n",
    "    inst_labels = inst_labels[np.isin(sem_labels, sem_classes)]\n",
    "    sem_labels = sem_labels[np.isin(sem_labels, sem_classes)]\n",
    "    for inst in np.unique(inst_labels)[1:]:\n",
    "        intersect, area = np.unique(sem_labels[inst_labels == inst], return_counts=True)\n",
    "        main_sem_label = intersect[np.argmax(area)]\n",
    "        semantic_map[inst] = main_sem_label\n",
    "        to_merge_sem_labels = intersect[intersect != main_sem_label]\n",
    "        num_merges = len(to_merge_sem_labels)\n",
    "        total_merges += num_merges\n",
    "    return semantic_map\n",
    "\n",
    "\n",
    "def get_num_splits(intersection, sem_classes, t_area, t_score, t_ratio):\n",
    "    result = {\n",
    "        \"inst\": [],\n",
    "        \"area\": [],\n",
    "        \"score\": [],\n",
    "        \"sem_labels\": [],\n",
    "        \"num_splits\": [],\n",
    "        \"sem_splits\": [],\n",
    "        \"main_sem_label\": [],\n",
    "        \"other_splits\": [],\n",
    "        \"valid_sem_label\": [],\n",
    "        \"sem-sem_splits\": [],\n",
    "    }\n",
    "    for idx, inst in enumerate(intersection[\"inst\"]):\n",
    "        # print(f\"inst: {inst}, area: {intersection['area'][inst]}, score: {intersection['score'][inst]}, sem_labels: {intersection['sem_labels'][inst]}, num_intersection: {intersection['num_intersection'][inst]}\")\n",
    "        area = np.sum(intersection[\"area\"][idx])\n",
    "        score = intersection[\"score\"][idx]\n",
    "        sem_label = intersection[\"sem_labels\"][idx]\n",
    "        if area > t_area and score < t_score and inst != 0:\n",
    "            intersect_area = intersection[\"area\"][idx]\n",
    "            num_splits = np.count_nonzero(intersect_area / area > t_ratio) - 1\n",
    "            valid_sem_label = sem_label[intersect_area / area > t_ratio]\n",
    "            sem_sem_splits = np.count_nonzero(np.isin(valid_sem_label, sem_classes)) - 1\n",
    "            other_splits = num_splits - sem_sem_splits\n",
    "            result[\"inst\"].append(inst)\n",
    "            result[\"area\"].append(area)\n",
    "            result[\"score\"].append(score)\n",
    "            result[\"sem_labels\"].append(sem_label)\n",
    "            result[\"num_splits\"].append(num_splits)\n",
    "            result[\"sem_splits\"].append(sem_label[intersect_area / area > t_ratio])\n",
    "            result[\"main_sem_label\"].append(sem_label[np.argmax(intersect_area)])\n",
    "            result[\"other_splits\"].append(other_splits)\n",
    "            result[\"valid_sem_label\"].append(valid_sem_label)\n",
    "            result[\"sem-sem_splits\"].append(sem_sem_splits)\n",
    "        num_splits = np.sum(result[\"num_splits\"])\n",
    "        sem2sem_splits = np.sum(result[\"sem-sem_splits\"])\n",
    "        # print(f\"inst: {inst}, area: {area}, score: {score}, sem_labels: {intersection['sem_labels'][idx]}, num_intersection: {intersection['num_intersection'][idx]}, num_splits: {num_splits}\")\n",
    "    return result, (num_splits, sem2sem_splits)\n",
    "\n",
    "\n",
    "def create_sub_instances(inst_labels, sem_labels, result):\n",
    "    new_inst_labels = inst_labels.copy()\n",
    "    last_inst_id = np.max(inst_labels)\n",
    "    for inst in np.unique(inst_labels):\n",
    "\n",
    "        if inst in result[\"inst\"]:\n",
    "            idx = np.where(result[\"inst\"] == inst)[0][0]\n",
    "            sem_splits = result[\"sem_splits\"][idx]\n",
    "            main_sem_label = result[\"main_sem_label\"][idx]\n",
    "            to_split = sem_splits[sem_splits != main_sem_label]\n",
    "            for split in to_split:\n",
    "                last_inst_id += 1\n",
    "                # print(f\"Splitting instance {inst} with sem label {split} into {last_inst_id}\")\n",
    "                new_inst_labels[\n",
    "                    np.logical_and(inst_labels == inst, sem_labels == split)\n",
    "                ] = last_inst_id\n",
    "    return new_inst_labels\n",
    "\n",
    "\n",
    "def get_intersection(labels_sem, pred_labels, ignore_labels=[0, 1, 52, 99, 40, 48, 49]):\n",
    "    intersection = {\n",
    "        \"inst\": [],\n",
    "        \"sem_labels\": [],\n",
    "        \"area\": [],\n",
    "        \"num_intersection\": [],\n",
    "        \"score\": [],\n",
    "    }\n",
    "    for i in ignore_labels:\n",
    "        labels_sem[labels_sem == i] = 0\n",
    "    pred_labels = pred_labels[labels_sem != 0]\n",
    "    labels_sem = labels_sem[labels_sem != 0]\n",
    "    for label in np.unique(pred_labels):\n",
    "        intersect, area = np.unique(\n",
    "            labels_sem[pred_labels == label], return_counts=True\n",
    "        )\n",
    "        intersection[\"inst\"].append(label)\n",
    "        intersection[\"sem_labels\"].append(intersect)\n",
    "        intersection[\"area\"].append(area)\n",
    "        intersection[\"num_intersection\"].append(len(intersect))\n",
    "        max_area = np.max(area)\n",
    "        # error_area = np.sum(area[area != max_area])\n",
    "        score = max_area / np.sum(area)\n",
    "        intersection[\"score\"].append(score)\n",
    "    return intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subpcd(pcd, indices, colors=False, normals=False):\n",
    "    subpcd = o3d.geometry.PointCloud()\n",
    "    subpcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points)[indices])\n",
    "    new_cols = copy.deepcopy(np.asarray(pcd.colors)[indices])\n",
    "    subpcd.colors = o3d.utility.Vector3dVector(new_cols)\n",
    "    return subpcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131]\n",
      "total sequence number -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.1\n",
    "proximity_threshold = 1.0\n",
    "tarl_norm = False\n",
    "ncuts_threshold = 0.005\n",
    "        \n",
    "out_name = 'tarl_dino_spatial' + str(SEQUENCE_NUM) \n",
    "limit = len(center_ids)\n",
    "limit = 5\n",
    "VISIBLE = True \n",
    "# Generate 30 different colors\n",
    " \n",
    "\n",
    "COLORS = generate_random_colors(400)\n",
    "COLORS = [(col[0]/255.,col[1]/255.,col[2]/255.) for col in COLORS]\n",
    "\n",
    "\n",
    "        \n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "\n",
    "if os.path.exists(out_kitti_instance) == True : \n",
    "        shutil.rmtree(out_kitti_instance)\n",
    "os.makedirs(out_kitti_instance)\n",
    "\n",
    "\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "if os.path.exists(out_kitti_semantic) == True : \n",
    "        shutil.rmtree(out_kitti_semantic)\n",
    "os.makedirs(out_kitti_semantic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "semantics = np.hstack((kitti_labels_orig['seg_nonground'].reshape(-1,),kitti_labels_orig['seg_ground'].reshape(-1,)))\n",
    "\n",
    "instances = np.hstack((kitti_labels_orig['instance_nonground'].reshape(-1,),kitti_labels_orig['instance_ground'].reshape(-1,)))\n",
    "print('number of instances',np.unique(instances))\n",
    "merge_pcd = o3d.geometry.PointCloud()    \n",
    "\n",
    "\n",
    "\n",
    "print(\"total sequence number\",limit)\n",
    "for sequence in tqdm(range(0,limit)):\n",
    "                print('Sequence',center_ids[sequence])\n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,list(indices),pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,list(sampled_indices_global),\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold,obb=obbs[sequence],hpr_radius=20)\n",
    "                \n",
    "                cols, labels_kitti_cur = np.unique(\n",
    "                np.asarray(pcd_chunk.colors), axis=0, return_inverse=True\n",
    "                )\n",
    "                \n",
    "                visible_parts = np.where(labels_kitti_cur != 0)[0]\n",
    "                \n",
    "                #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_chunk,labels_kitti_cur)])\n",
    "                #o3d.visualization.draw_geometries([get_subpcd(pcd_chunk,visible_parts)])\n",
    "                \n",
    "                seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                \n",
    "                file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                \n",
    "                sem_non_ground = kitti_labels['nonground']['semantic'][sequence].reshape(-1,)\n",
    "                inst_non_ground = kitti_labels['nonground']['instance'][sequence].reshape(-1,)\n",
    "                if VISIBLE : \n",
    "                        sem_non_ground = sem_non_ground[visible_parts]\n",
    "                        inst_non_ground = inst_non_ground[visible_parts]\n",
    "                        pcd_chunk = get_subpcd(pcd_chunk,visible_parts)\n",
    "                        \n",
    "                cur_pred = pcd_chunk + pcd_chunk_ground\n",
    "                \n",
    "                kitti_chunk_instance = color_pcd_by_labels(copy.deepcopy(pcd_chunk),inst_non_ground,\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(copy.deepcopy(pcd_chunk_ground),inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "\n",
    "                semantics_non_ground = color_pcd_kitti(copy.deepcopy(pcd_chunk),sem_non_ground)\n",
    "                semantics_ground = color_pcd_kitti(copy.deepcopy(pcd_chunk_ground),seg_ground.reshape(-1,))\n",
    "                kitti_semantics = np.hstack((kitti_labels['nonground']['semantic'][sequence].reshape(-1,),seg_ground.reshape(-1,)))\n",
    "                                                \n",
    "                \n",
    "                o3d.io.write_point_cloud(out_folder_ncuts + file_name, cur_pred , write_ascii=False, compressed=False, print_progress=False)\n",
    "                print('write gt',out_kitti_instance + file_name)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_semantic + file_name, semantics_non_ground + semantics_ground, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out_kitti_semantic \u001b[39m=\u001b[39m out_chunks \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mout_kitti_semantic\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(SEQUENCE_NUM) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m point_cloud_semantis \u001b[39m=\u001b[39m get_merge_pcds(out_kitti_semantic)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m seg_pcd \u001b[39m=\u001b[39m merge_unite_gt(point_cloud_semantis)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cols, labels_kitti_cur \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 np\u001b[39m.\u001b[39masarray(seg_pcd\u001b[39m.\u001b[39mcolors), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m seg_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(np\u001b[39m.\u001b[39masarray(seg_pcd\u001b[39m.\u001b[39mcolors)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m#semantic labels \u001b[39;00m\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/point_cloud_utils.py:356\u001b[0m, in \u001b[0;36mmerge_unite_gt\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_unite_gt\u001b[39m(chunks):\n\u001b[0;32m--> 356\u001b[0m     last_chunk \u001b[39m=\u001b[39m chunks[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m    357\u001b[0m     merge \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mPointCloud()\n\u001b[1;32m    358\u001b[0m     merge \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m last_chunk\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "point_cloud_semantis = get_merge_pcds(out_kitti_semantic)\n",
    "seg_pcd = merge_unite_gt(point_cloud_semantis)\n",
    "cols, labels_kitti_cur = np.unique(\n",
    "                np.asarray(seg_pcd.colors), axis=0, return_inverse=True\n",
    "            )\n",
    "\n",
    "seg_labels = np.zeros(np.asarray(seg_pcd.colors).shape[0]) #semantic labels \n",
    "for label in np.unique(labels_kitti_cur):\n",
    "                idcs = np.where(labels_kitti_cur == label)[0]\n",
    "                col_cur = np.asarray(seg_pcd.colors)[idcs][0]\n",
    "                seg_labels[idcs] = reverse_color_dict[tuple(col_cur)]\n",
    "\n",
    "print('obtained semantic labels')\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)\n",
    "instance_pcd = merge_unite_gt(point_clouds_kitti_instances)\n",
    "\n",
    "point_clouds_pred = get_merge_pcds(out_folder_ncuts)\n",
    "merge = merge_chunks_unite_instances2(point_clouds_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 5890.16it/s]\n",
      "Processing: 100%|██████████| 23/23 [00:00<00:00, 896.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838241\n",
      "838241\n",
      "start\n",
      "Metrics for file ncuts\n",
      "update stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 2237.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got all the idcs\n",
      "full stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 67.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fScore': 0.888888888888889, 'precision': 1.0, 'recall': 0.8, 'panoptic': 0.7474371574787557}\n",
      "S_assoc score :  0.6611740659616921\n",
      "AP @ 0.25 80.0\n",
      "AP @ 0.5 80.0\n",
      "AP @ [0.5:0.95] 54.998\n",
      "Computing metrics with Visibility setting :  True\n",
      "Num merges 10\n",
      "Num splits 10\n",
      "Num actions 20\n",
      "Num sem2sem splits  5\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unique_colors, label_inst = np.unique(np.asarray(instance_pcd.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_ncuts_all = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "\n",
    "new_ncuts_labels = remove_semantics(label_inst,labels_ncuts_all)\n",
    "print(labels_ncuts_all.shape[0])\n",
    "print(label_inst.shape[0])\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_ncuts.update_stats(labels_ncuts_all,new_ncuts_labels,label_inst)\n",
    "\n",
    "\n",
    "\n",
    "sem_classes = [49, 50, 51, 70, 72]\n",
    "ignore_labels = [0, 1, 52, 99, 40, 48, 49]\n",
    "\n",
    "print(\"Computing metrics with Visibility setting : \",VISIBLE)\n",
    "sem_labels = seg_labels\n",
    "intersection = get_intersection(sem_labels, labels_ncuts_all)\n",
    "result, (num_splits, sem2sem_splits) = get_num_splits(\n",
    "            intersection, sem_classes, 200, 0.9, 0.02\n",
    "        )\n",
    "new_labels = create_sub_instances(labels_ncuts_all, sem_labels, result)\n",
    "semantic_map = get_semantic_map(new_labels, sem_labels, sem_classes)\n",
    "value_counts = Counter(semantic_map.values())\n",
    "num_merges = np.sum(list(value_counts.values())) - len(value_counts)\n",
    "\n",
    "print(\"Num merges\",num_merges)\n",
    "print(\"Num splits\",num_splits)\n",
    "print(\"Num actions\",num_merges + num_splits)\n",
    "print(\"Num sem2sem splits \", sem2sem_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
