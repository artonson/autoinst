{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from ncuts_utils_ablations import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_chunks_unite_instances2, remove_semantics, get_merge_pcds, merge_unite_gt\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import shutil\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets2/semantic_kitti/')\n",
    "end_inds = {0:4541,1:1100,2:4661,3:800,4:271,5:2761,6:1101,7:1100,8:4071,9:1591,10:1201}\n",
    "SEQUENCE_NUM = 7\n",
    "old = False \n",
    "\n",
    "ind_start = 0\n",
    "ind_end = end_inds[SEQUENCE_NUM]\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = '../../pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_folder_ncuts) == True:\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = '../../pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_folder + 'all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz',\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n",
    "        #o3d.visualization.draw_geometries([pcd_nonground_minor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 11580178 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "print(pcd_ground_minor)\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz') as data :\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz') == False : \n",
    "\tprint(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz')\n",
    "\tposes, positions, \\\n",
    "\tsampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start,sequence_num=SEQUENCE_NUM,out_folder=out_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(f'{out_folder}subsampled_data{SEQUENCE_NUM}_0.npz') as data:\n",
    "\tposes=data['poses']\n",
    "\tpositions=data['positions']\n",
    "\tsampled_indices_local = data['sampled_indices_local']\n",
    "\tsampled_indices_global=data['sampled_indices_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:32<00:00, 20.97it/s]\n",
      "100%|██████████| 681/681 [00:26<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (541161, 3) to (7776, 3) points (non-ground)\n",
      "Downsampled from (243917, 3) to (5294, 3) points (ground)\n",
      "Downsampled from (454490, 3) to (7216, 3) points (non-ground)\n",
      "Downsampled from (262770, 3) to (4499, 3) points (ground)\n",
      "Downsampled from (479361, 3) to (7341, 3) points (non-ground)\n",
      "Downsampled from (304983, 3) to (6061, 3) points (ground)\n",
      "Downsampled from (479273, 3) to (6272, 3) points (non-ground)\n",
      "Downsampled from (246003, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (473079, 3) to (8385, 3) points (non-ground)\n",
      "Downsampled from (221993, 3) to (4446, 3) points (ground)\n",
      "Downsampled from (488393, 3) to (9063, 3) points (non-ground)\n",
      "Downsampled from (220415, 3) to (5078, 3) points (ground)\n",
      "Downsampled from (545707, 3) to (8986, 3) points (non-ground)\n",
      "Downsampled from (292301, 3) to (4209, 3) points (ground)\n",
      "Downsampled from (409731, 3) to (6703, 3) points (non-ground)\n",
      "Downsampled from (441195, 3) to (4976, 3) points (ground)\n",
      "Downsampled from (300320, 3) to (4742, 3) points (non-ground)\n",
      "Downsampled from (509260, 3) to (6199, 3) points (ground)\n",
      "Downsampled from (350224, 3) to (6187, 3) points (non-ground)\n",
      "Downsampled from (372916, 3) to (5525, 3) points (ground)\n",
      "Downsampled from (452246, 3) to (7807, 3) points (non-ground)\n",
      "Downsampled from (385946, 3) to (5562, 3) points (ground)\n",
      "Downsampled from (262978, 3) to (4456, 3) points (non-ground)\n",
      "Downsampled from (451230, 3) to (6189, 3) points (ground)\n",
      "Downsampled from (260853, 3) to (4469, 3) points (non-ground)\n",
      "Downsampled from (540630, 3) to (6637, 3) points (ground)\n",
      "Downsampled from (477380, 3) to (7261, 3) points (non-ground)\n",
      "Downsampled from (438394, 3) to (6594, 3) points (ground)\n",
      "Downsampled from (484851, 3) to (7762, 3) points (non-ground)\n",
      "Downsampled from (389528, 3) to (6532, 3) points (ground)\n",
      "Downsampled from (406142, 3) to (6391, 3) points (non-ground)\n",
      "Downsampled from (339234, 3) to (5270, 3) points (ground)\n",
      "Downsampled from (322094, 3) to (5849, 3) points (non-ground)\n",
      "Downsampled from (273519, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (383759, 3) to (6583, 3) points (non-ground)\n",
      "Downsampled from (196088, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (471693, 3) to (7780, 3) points (non-ground)\n",
      "Downsampled from (309908, 3) to (6091, 3) points (ground)\n",
      "Downsampled from (570103, 3) to (5949, 3) points (non-ground)\n",
      "Downsampled from (939537, 3) to (9495, 3) points (ground)\n",
      "Downsampled from (567185, 3) to (7039, 3) points (non-ground)\n",
      "Downsampled from (480866, 3) to (7211, 3) points (ground)\n",
      "Downsampled from (324509, 3) to (5945, 3) points (non-ground)\n",
      "Downsampled from (214718, 3) to (4765, 3) points (ground)\n",
      "Downsampled from (296982, 3) to (5076, 3) points (non-ground)\n",
      "Downsampled from (295734, 3) to (5203, 3) points (ground)\n",
      "Downsampled from (311607, 3) to (5367, 3) points (non-ground)\n",
      "Downsampled from (283045, 3) to (4829, 3) points (ground)\n",
      "Downsampled from (336036, 3) to (5544, 3) points (non-ground)\n",
      "Downsampled from (254495, 3) to (4716, 3) points (ground)\n",
      "Downsampled from (351770, 3) to (5478, 3) points (non-ground)\n",
      "Downsampled from (493796, 3) to (6512, 3) points (ground)\n",
      "Downsampled from (333876, 3) to (5378, 3) points (non-ground)\n",
      "Downsampled from (579172, 3) to (6166, 3) points (ground)\n",
      "Downsampled from (576526, 3) to (8127, 3) points (non-ground)\n",
      "Downsampled from (359545, 3) to (6037, 3) points (ground)\n",
      "Downsampled from (796774, 3) to (9306, 3) points (non-ground)\n",
      "Downsampled from (383977, 3) to (6355, 3) points (ground)\n",
      "Downsampled from (790877, 3) to (8685, 3) points (non-ground)\n",
      "Downsampled from (627610, 3) to (6811, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels, obbs = chunk_and_downsample_point_clouds(dataset,pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None,semantics=False):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 and semantics == False : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else :\n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "    \n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_normalized = {\n",
    "    0: [0.0, 0.0, 0.0],\n",
    "    1: [0.0, 0.0, 1.0],\n",
    "    10: [0.9607843137254902, 0.5882352941176471, 0.39215686274509803],\n",
    "    11: [0.9607843137254902, 0.9019607843137255, 0.39215686274509803],\n",
    "    13: [0.9803921568627451, 0.3137254901960784, 0.39215686274509803],\n",
    "    15: [0.5882352941176471, 0.23529411764705882, 0.11764705882352941],\n",
    "    16: [1.0, 0.0, 0.0],\n",
    "    18: [0.7058823529411765, 0.11764705882352941, 0.3137254901960784],\n",
    "    20: [1.0, 0.0, 0.0],\n",
    "    30: [0.11764705882352941, 0.11764705882352941, 1.0],\n",
    "    31: [0.7843137254901961, 0.1568627450980392, 1.0],\n",
    "    32: [0.35294117647058826, 0.11764705882352941, 0.5882352941176471],\n",
    "    40: [1.0, 0.0, 1.0],\n",
    "    44: [1.0, 0.5882352941176471, 1.0],\n",
    "    48: [0.29411764705882354, 0.0, 0.29411764705882354],\n",
    "    49: [0.29411764705882354, 0.0, 0.6862745098039216],\n",
    "    50: [0.0, 0.7843137254901961, 1.0],\n",
    "    51: [0.19607843137254902, 0.47058823529411764, 1.0],\n",
    "    52: [0.0, 0.5882352941176471, 1.0],\n",
    "    60: [0.6666666666666666, 1.0, 0.5882352941176471],\n",
    "    70: [0.0, 0.6862745098039216, 0.0],\n",
    "    71: [0.0, 0.23529411764705882, 0.5294117647058824],\n",
    "    72: [0.3137254901960784, 0.9411764705882353, 0.5882352941176471],\n",
    "    80: [0.5882352941176471, 0.9411764705882353, 1.0],\n",
    "    81: [0.0, 0.0, 1.0],\n",
    "    99: [1.0, 1.0, 0.19607843137254902],\n",
    "    252: [0.9607843137254902, 0.5882352941176471, 0.39215686274509803],\n",
    "    256: [1.0, 0.0, 0.0],\n",
    "    253: [0.7843137254901961, 0.1568627450980392, 1.0],\n",
    "    254: [0.11764705882352941, 0.11764705882352941, 1.0],\n",
    "    255: [0.35294117647058826, 0.11764705882352941, 0.5882352941176471],\n",
    "    257: [0.9803921568627451, 0.3137254901960784, 0.39215686274509803],\n",
    "    258: [0.7058823529411765, 0.11764705882352941, 0.3137254901960784],\n",
    "    259: [1.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "reverse_color_dict = {tuple(v): k for k, v in color_dict_normalized.items()}\n",
    "\n",
    "\n",
    "def color_pcd_kitti(pcd, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    pcd_colors = np.zeros_like(np.asarray(pcd.points))\n",
    "    for i in unique_labels:\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        pcd_colors[idcs] = np.array(color_dict_normalized[int(i)])\n",
    "\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    return pcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_map(inst_labels, sem_labels, sem_classes=[49, 50, 51, 70, 72]):\n",
    "\n",
    "    semantic_map = {}\n",
    "    total_merges = 0\n",
    "\n",
    "    inst_labels = inst_labels[np.isin(sem_labels, sem_classes)]\n",
    "    sem_labels = sem_labels[np.isin(sem_labels, sem_classes)]\n",
    "    for inst in np.unique(inst_labels)[1:]:\n",
    "        intersect, area = np.unique(sem_labels[inst_labels == inst], return_counts=True)\n",
    "        main_sem_label = intersect[np.argmax(area)]\n",
    "        semantic_map[inst] = main_sem_label\n",
    "        to_merge_sem_labels = intersect[intersect != main_sem_label]\n",
    "        num_merges = len(to_merge_sem_labels)\n",
    "        total_merges += num_merges\n",
    "    return semantic_map\n",
    "\n",
    "\n",
    "def get_num_splits(intersection, sem_classes, t_area, t_score, t_ratio):\n",
    "    result = {\n",
    "        \"inst\": [],\n",
    "        \"area\": [],\n",
    "        \"score\": [],\n",
    "        \"sem_labels\": [],\n",
    "        \"num_splits\": [],\n",
    "        \"sem_splits\": [],\n",
    "        \"main_sem_label\": [],\n",
    "        \"other_splits\": [],\n",
    "        \"valid_sem_label\": [],\n",
    "        \"sem-sem_splits\": [],\n",
    "    }\n",
    "    for idx, inst in enumerate(intersection[\"inst\"]):\n",
    "        # print(f\"inst: {inst}, area: {intersection['area'][inst]}, score: {intersection['score'][inst]}, sem_labels: {intersection['sem_labels'][inst]}, num_intersection: {intersection['num_intersection'][inst]}\")\n",
    "        area = np.sum(intersection[\"area\"][idx])\n",
    "        score = intersection[\"score\"][idx]\n",
    "        sem_label = intersection[\"sem_labels\"][idx]\n",
    "        if area > t_area and score < t_score and inst != 0:\n",
    "            intersect_area = intersection[\"area\"][idx]\n",
    "            num_splits = np.count_nonzero(intersect_area / area > t_ratio) - 1\n",
    "            valid_sem_label = sem_label[intersect_area / area > t_ratio]\n",
    "            sem_sem_splits = np.count_nonzero(np.isin(valid_sem_label, sem_classes)) - 1\n",
    "            other_splits = num_splits - sem_sem_splits\n",
    "            result[\"inst\"].append(inst)\n",
    "            result[\"area\"].append(area)\n",
    "            result[\"score\"].append(score)\n",
    "            result[\"sem_labels\"].append(sem_label)\n",
    "            result[\"num_splits\"].append(num_splits)\n",
    "            result[\"sem_splits\"].append(sem_label[intersect_area / area > t_ratio])\n",
    "            result[\"main_sem_label\"].append(sem_label[np.argmax(intersect_area)])\n",
    "            result[\"other_splits\"].append(other_splits)\n",
    "            result[\"valid_sem_label\"].append(valid_sem_label)\n",
    "            result[\"sem-sem_splits\"].append(sem_sem_splits)\n",
    "        num_splits = np.sum(result[\"num_splits\"])\n",
    "        sem2sem_splits = np.sum(result[\"sem-sem_splits\"])\n",
    "        # print(f\"inst: {inst}, area: {area}, score: {score}, sem_labels: {intersection['sem_labels'][idx]}, num_intersection: {intersection['num_intersection'][idx]}, num_splits: {num_splits}\")\n",
    "    return result, (num_splits, sem2sem_splits)\n",
    "\n",
    "\n",
    "def create_sub_instances(inst_labels, sem_labels, result):\n",
    "    new_inst_labels = inst_labels.copy()\n",
    "    last_inst_id = np.max(inst_labels)\n",
    "    for inst in np.unique(inst_labels):\n",
    "\n",
    "        if inst in result[\"inst\"]:\n",
    "            idx = np.where(result[\"inst\"] == inst)[0][0]\n",
    "            sem_splits = result[\"sem_splits\"][idx]\n",
    "            main_sem_label = result[\"main_sem_label\"][idx]\n",
    "            to_split = sem_splits[sem_splits != main_sem_label]\n",
    "            for split in to_split:\n",
    "                last_inst_id += 1\n",
    "                # print(f\"Splitting instance {inst} with sem label {split} into {last_inst_id}\")\n",
    "                new_inst_labels[\n",
    "                    np.logical_and(inst_labels == inst, sem_labels == split)\n",
    "                ] = last_inst_id\n",
    "    return new_inst_labels\n",
    "\n",
    "\n",
    "def get_intersection(labels_sem, pred_labels, ignore_labels=[0, 1, 52, 99, 40, 48, 49]):\n",
    "    intersection = {\n",
    "        \"inst\": [],\n",
    "        \"sem_labels\": [],\n",
    "        \"area\": [],\n",
    "        \"num_intersection\": [],\n",
    "        \"score\": [],\n",
    "    }\n",
    "    for i in ignore_labels:\n",
    "        labels_sem[labels_sem == i] = 0\n",
    "    pred_labels = pred_labels[labels_sem != 0]\n",
    "    labels_sem = labels_sem[labels_sem != 0]\n",
    "    for label in np.unique(pred_labels):\n",
    "        intersect, area = np.unique(\n",
    "            labels_sem[pred_labels == label], return_counts=True\n",
    "        )\n",
    "        intersection[\"inst\"].append(label)\n",
    "        intersection[\"sem_labels\"].append(intersect)\n",
    "        intersection[\"area\"].append(area)\n",
    "        intersection[\"num_intersection\"].append(len(intersect))\n",
    "        max_area = np.max(area)\n",
    "        # error_area = np.sum(area[area != max_area])\n",
    "        score = max_area / np.sum(area)\n",
    "        intersection[\"score\"].append(score)\n",
    "    return intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subpcd(pcd, indices, colors=False, normals=False):\n",
    "    subpcd = o3d.geometry.PointCloud()\n",
    "    subpcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points)[indices])\n",
    "    new_cols = copy.deepcopy(np.asarray(pcd.colors)[indices])\n",
    "    subpcd.colors = o3d.utility.Vector3dVector(new_cols)\n",
    "    return subpcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131]\n",
      "total sequence number 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 66\n",
      "Start of sequence 0\n",
      "7776 points in downsampled chunk (major)\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.1\n",
    "proximity_threshold = 1.0\n",
    "tarl_norm = False\n",
    "ncuts_threshold = 0.005\n",
    "        \n",
    "out_name = 'tarl_dino_spatial' + str(SEQUENCE_NUM) \n",
    "limit = len(center_ids)\n",
    "#limit = 5\n",
    "VISIBLE = True\n",
    "# Generate 30 different colors\n",
    " \n",
    "\n",
    "COLORS = generate_random_colors(400)\n",
    "COLORS = [(col[0]/255.,col[1]/255.,col[2]/255.) for col in COLORS]\n",
    "\n",
    "\n",
    "        \n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "\n",
    "if os.path.exists(out_kitti_instance) == True : \n",
    "        shutil.rmtree(out_kitti_instance)\n",
    "os.makedirs(out_kitti_instance)\n",
    "\n",
    "\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "if os.path.exists(out_kitti_semantic) == True : \n",
    "        shutil.rmtree(out_kitti_semantic)\n",
    "os.makedirs(out_kitti_semantic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "semantics = np.hstack((kitti_labels_orig['seg_nonground'].reshape(-1,),kitti_labels_orig['seg_ground'].reshape(-1,)))\n",
    "\n",
    "instances = np.hstack((kitti_labels_orig['instance_nonground'].reshape(-1,),kitti_labels_orig['instance_ground'].reshape(-1,)))\n",
    "print('number of instances',np.unique(instances))\n",
    "merge_pcd = o3d.geometry.PointCloud()    \n",
    "\n",
    "\n",
    "\n",
    "print(\"total sequence number\",limit)\n",
    "for sequence in tqdm(range(0,limit)):\n",
    "                print('Sequence',center_ids[sequence])\n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,list(indices),pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,list(sampled_indices_global),\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold,obb=obbs[sequence],hpr_radius=1000,visible=VISIBLE)\n",
    "                \n",
    "                cols, labels_kitti_cur = np.unique(\n",
    "                np.asarray(pcd_chunk.colors), axis=0, return_inverse=True\n",
    "                )\n",
    "                \n",
    "                visible_parts = np.where(labels_kitti_cur != 0)[0]\n",
    "                \n",
    "                \n",
    "                #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_chunk,labels_kitti_cur)])\n",
    "                #o3d.visualization.draw_geometries([get_subpcd(pcd_chunk,visible_parts)])\n",
    "                \n",
    "                seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                \n",
    "                file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                \n",
    "                sem_non_ground = kitti_labels['nonground']['semantic'][sequence].reshape(-1,)\n",
    "                inst_non_ground = kitti_labels['nonground']['instance'][sequence].reshape(-1,)\n",
    "                if VISIBLE : \n",
    "                        sem_non_ground = sem_non_ground[visible_parts]\n",
    "                        inst_non_ground = inst_non_ground[visible_parts]\n",
    "                        pcd_chunk = get_subpcd(pcd_chunk,visible_parts)\n",
    "                        \n",
    "                cur_pred = pcd_chunk + pcd_chunk_ground\n",
    "                #o3d.visualization.draw_geometries([cur_pred])\n",
    "                \n",
    "                kitti_chunk_instance = color_pcd_by_labels(copy.deepcopy(pcd_chunk),inst_non_ground,\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(copy.deepcopy(pcd_chunk_ground),inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "\n",
    "                semantics_non_ground = color_pcd_kitti(copy.deepcopy(pcd_chunk),sem_non_ground)\n",
    "                semantics_ground = color_pcd_kitti(copy.deepcopy(pcd_chunk_ground),seg_ground.reshape(-1,))\n",
    "                kitti_semantics = np.hstack((kitti_labels['nonground']['semantic'][sequence].reshape(-1,),seg_ground.reshape(-1,)))\n",
    "                                                \n",
    "                \n",
    "                o3d.io.write_point_cloud(out_folder_ncuts + file_name, cur_pred , write_ascii=False, compressed=False, print_progress=False)\n",
    "                print('write gt',out_kitti_instance + file_name)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_semantic + file_name, semantics_non_ground + semantics_ground, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd', '000220.pcd', '000249.pcd', '000278.pcd', '000336.pcd', '000368.pcd', '000391.pcd', '000415.pcd', '000441.pcd', '000483.pcd', '000515.pcd', '000540.pcd', '000565.pcd', '000587.pcd', '000610.pcd', '000650.pcd', '000774.pcd', '000794.pcd', '000813.pcd', '000833.pcd', '000854.pcd', '000877.pcd', '000915.pcd', '000949.pcd', '000982.pcd', '001048.pcd']\n",
      "obtained semantic labels\n",
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd', '000220.pcd', '000249.pcd', '000278.pcd', '000336.pcd', '000368.pcd', '000391.pcd', '000415.pcd', '000441.pcd', '000483.pcd', '000515.pcd', '000540.pcd', '000565.pcd', '000587.pcd', '000610.pcd', '000650.pcd', '000774.pcd', '000794.pcd', '000813.pcd', '000833.pcd', '000854.pcd', '000877.pcd', '000915.pcd', '000949.pcd', '000982.pcd', '001048.pcd']\n",
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd', '000220.pcd', '000249.pcd', '000278.pcd', '000336.pcd', '000368.pcd', '000391.pcd', '000415.pcd', '000441.pcd', '000483.pcd', '000515.pcd', '000540.pcd', '000565.pcd', '000587.pcd', '000610.pcd', '000650.pcd', '000774.pcd', '000794.pcd', '000813.pcd', '000833.pcd', '000854.pcd', '000877.pcd', '000915.pcd', '000949.pcd', '000982.pcd', '001048.pcd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [02:04<00:00,  4.45s/it]\n"
     ]
    }
   ],
   "source": [
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "point_cloud_semantis = get_merge_pcds(out_kitti_semantic)[:-1]\n",
    "seg_pcd = merge_unite_gt(point_cloud_semantis)\n",
    "cols, labels_kitti_cur = np.unique(\n",
    "                np.asarray(seg_pcd.colors), axis=0, return_inverse=True\n",
    "            )\n",
    "\n",
    "seg_labels = np.zeros(np.asarray(seg_pcd.colors).shape[0]) #semantic labels \n",
    "for label in np.unique(labels_kitti_cur):\n",
    "                idcs = np.where(labels_kitti_cur == label)[0]\n",
    "                col_cur = np.asarray(seg_pcd.colors)[idcs][0]\n",
    "                seg_labels[idcs] = reverse_color_dict[tuple(col_cur)]\n",
    "\n",
    "print('obtained semantic labels')\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)[:-1]\n",
    "instance_pcd = merge_unite_gt(point_clouds_kitti_instances)\n",
    "\n",
    "point_clouds_pred = get_merge_pcds(out_folder_ncuts)[:-1]\n",
    "merge = merge_chunks_unite_instances2(point_clouds_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud('semantics_visible' + str(VISIBLE) +  '.pcd',seg_pcd)\n",
    "o3d.io.write_point_cloud('instance_visible' + str(VISIBLE) +  '.pcd',instance_pcd)\n",
    "o3d.io.write_point_cloud('merge_visible' + str(VISIBLE) +  '.pcd',merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISIBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([merge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [00:00<00:00, 17440.90it/s]\n",
      "Processing: 100%|██████████| 337/337 [00:35<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13349670\n",
      "13349670\n",
      "start\n",
      "Metrics for file ncuts\n",
      "update stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:00<00:00, 112.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got all the idcs\n",
      "full stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:22<00:00,  3.75it/s]\n",
      "100%|██████████| 1/1 [00:22<00:00, 22.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fScore': 0.6878306878306878, 'precision': 0.7926829268292683, 'recall': 0.6074766355140186, 'panoptic': 0.5986484493649586}\n",
      "S_assoc score :  0.5720039541851389\n",
      "AP @ 0.25 54.831\n",
      "AP @ 0.5 45.505\n",
      "AP @ [0.5:0.95] 30.853\n",
      "Computing metrics with Visibility setting :  True\n",
      "theta 0.5\n",
      "alpha 1.0\n",
      "gamma 0.1\n",
      "Num merges 209\n",
      "Num splits 126\n",
      "Num actions 335\n",
      "Num sem2sem splits  57\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unique_colors, label_inst = np.unique(np.asarray(instance_pcd.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_ncuts_all = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "\n",
    "new_ncuts_labels = remove_semantics(label_inst,labels_ncuts_all)\n",
    "print(labels_ncuts_all.shape[0])\n",
    "print(label_inst.shape[0])\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_ncuts.update_stats(labels_ncuts_all,new_ncuts_labels,label_inst)\n",
    "\n",
    "\n",
    "\n",
    "sem_classes = [49, 50, 51, 70, 72]\n",
    "ignore_labels = [0, 1, 52, 99, 40, 48, 49]\n",
    "\n",
    "print(\"Computing metrics with Visibility setting : \",VISIBLE)\n",
    "sem_labels = seg_labels\n",
    "intersection = get_intersection(sem_labels, labels_ncuts_all)\n",
    "result, (num_splits, sem2sem_splits) = get_num_splits(\n",
    "            intersection, sem_classes, 200, 0.9, 0.02\n",
    "        )\n",
    "new_labels = create_sub_instances(labels_ncuts_all, sem_labels, result)\n",
    "semantic_map = get_semantic_map(new_labels, sem_labels, sem_classes)\n",
    "value_counts = Counter(semantic_map.values())\n",
    "num_merges = np.sum(list(value_counts.values())) - len(value_counts)\n",
    "\n",
    "print('theta',theta)\n",
    "print('alpha',alpha)\n",
    "print('gamma',gamma)\n",
    "\n",
    "print(\"Num merges\",num_merges)\n",
    "print(\"Num splits\",num_splits)\n",
    "print(\"Num actions\",num_merges + num_splits)\n",
    "print(\"Num sem2sem splits \", sem2sem_splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
