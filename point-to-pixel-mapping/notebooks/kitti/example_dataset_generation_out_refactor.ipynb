{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from ncuts_utils_ablations import ncuts_chunk,kDTree_1NN_feature_reprojection_colors, get_merge_pcds\n",
    "from dataset_utils import * \n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances, merge_chunks_unite_instances2, remove_semantics, get_merge_pcds, merge_unite_gt\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels,generate_random_colors_map\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection\n",
    "from metrics.metrics_class import Metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import shutil\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets2/semantic_kitti/')\n",
    "end_inds = {0:4541,1:1100,2:4661,3:800,4:271,5:2761,6:1101,7:1100,8:4071,9:1591,10:1201}\n",
    "SEQUENCE_NUM = 7\n",
    "old = False \n",
    "\n",
    "ind_start = 0\n",
    "ind_end = end_inds[SEQUENCE_NUM]\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "ground_segmentation_method = 'patchwork' \n",
    "NCUT_ground = False\n",
    "\n",
    "out_chunks = '../../pcd_preprocessed/output_chunks/'\n",
    "\n",
    "out_folder_ncuts = out_chunks + 'test_data' + str(SEQUENCE_NUM) + '/'\n",
    "if os.path.exists(out_folder_ncuts) == True:\n",
    "        shutil.rmtree(out_folder_ncuts)\n",
    "os.makedirs(out_folder_ncuts)\n",
    "\n",
    "dataset = create_kitti_odometry_dataset(DATASET_PATH,SEQUENCE_NUM,ncuts_mode=True)\n",
    "\n",
    "out_folder = '../../pcd_preprocessed/'\n",
    "if os.path.exists(out_folder) == False : \n",
    "        os.makedirs(out_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)\n",
    "## This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_folder + 'all_poses_' + str(SEQUENCE_NUM) + '_' + str(0) + '.npz') == False:\n",
    "        process_and_save_point_clouds(dataset,ind_start,ind_end,minor_voxel_size=minor_voxel_size,\n",
    "                                major_voxel_size=major_voxel_size,icp=False,\n",
    "                                out_folder=out_folder,sequence_num=SEQUENCE_NUM,\n",
    "                                ground_segmentation_method=ground_segmentation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can be ignored after first run as outputs are stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data if already stored \n",
    "\n",
    "if os.path.exists(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd') == False:\n",
    "        pcd_ground_minor, pcd_nonground_minor,\\\n",
    "                all_poses, T_pcd, first_position,kitti_labels = load_and_downsample_point_clouds(out_folder,SEQUENCE_NUM,minor_voxel_size,\\\n",
    "                                                                        ground_mode=ground_segmentation_method)\n",
    "        #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_nonground_minor,kitti_labels['seg_nonground'])])\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd', pcd_ground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        o3d.io.write_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd', pcd_nonground_minor, write_ascii=False, compressed=False, print_progress=False)\n",
    "        np.savez(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz',\n",
    "                                                instance_nonground=kitti_labels['instance_nonground'],\n",
    "                                                instance_ground=kitti_labels['instance_ground'],\n",
    "                                                seg_ground = kitti_labels['seg_ground'],\n",
    "                                                seg_nonground=kitti_labels['seg_nonground']\n",
    "                                                )\n",
    "        #o3d.visualization.draw_geometries([pcd_nonground_minor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 11580178 points.\n"
     ]
    }
   ],
   "source": [
    "pcd_ground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_ground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "pcd_nonground_minor = o3d.io.read_point_cloud(f'{out_folder}pcd_nonground_minor{SEQUENCE_NUM}_0.pcd')\n",
    "print(pcd_ground_minor)\n",
    "kitti_labels_orig = {}\n",
    "with np.load(f'{out_folder}kitti_labels_preprocessed{SEQUENCE_NUM}_0.npz') as data :\n",
    "        kitti_labels_orig['instance_ground'] = data['instance_ground']\n",
    "        kitti_labels_orig['instance_nonground'] = data['instance_nonground']\n",
    "        kitti_labels_orig['seg_nonground'] = data['seg_nonground']\n",
    "        kitti_labels_orig['seg_ground'] = data['seg_ground']\n",
    "\n",
    "        \n",
    "\n",
    "with np.load(f'{out_folder}all_poses_{SEQUENCE_NUM}_0.npz') as data:\n",
    "        all_poses = data['all_poses']\n",
    "        T_pcd = data['T_pcd']\n",
    "        first_position = T_pcd[:3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz') == False : \n",
    "\tprint(f'{out_folder}subsampled_data{str(SEQUENCE_NUM)}_0.npz')\n",
    "\tposes, positions, \\\n",
    "\tsampled_indices_local, sampled_indices_global = subsample_and_extract_positions(all_poses,ind_start=ind_start,sequence_num=SEQUENCE_NUM,out_folder=out_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(f'{out_folder}subsampled_data{SEQUENCE_NUM}_0.npz') as data:\n",
    "\tposes=data['poses']\n",
    "\tpositions=data['positions']\n",
    "\tsampled_indices_local = data['sampled_indices_local']\n",
    "\tsampled_indices_global=data['sampled_indices_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:34<00:00, 19.59it/s]\n",
      "100%|██████████| 681/681 [00:26<00:00, 25.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled from (541161, 3) to (7776, 3) points (non-ground)\n",
      "Downsampled from (243917, 3) to (5294, 3) points (ground)\n",
      "Downsampled from (454490, 3) to (7216, 3) points (non-ground)\n",
      "Downsampled from (262770, 3) to (4499, 3) points (ground)\n",
      "Downsampled from (479361, 3) to (7341, 3) points (non-ground)\n",
      "Downsampled from (304983, 3) to (6061, 3) points (ground)\n",
      "Downsampled from (479273, 3) to (6272, 3) points (non-ground)\n",
      "Downsampled from (246003, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (473079, 3) to (8385, 3) points (non-ground)\n",
      "Downsampled from (221993, 3) to (4446, 3) points (ground)\n",
      "Downsampled from (488393, 3) to (9063, 3) points (non-ground)\n",
      "Downsampled from (220415, 3) to (5078, 3) points (ground)\n",
      "Downsampled from (545707, 3) to (8986, 3) points (non-ground)\n",
      "Downsampled from (292301, 3) to (4209, 3) points (ground)\n",
      "Downsampled from (409731, 3) to (6703, 3) points (non-ground)\n",
      "Downsampled from (441195, 3) to (4976, 3) points (ground)\n",
      "Downsampled from (300320, 3) to (4742, 3) points (non-ground)\n",
      "Downsampled from (509260, 3) to (6199, 3) points (ground)\n",
      "Downsampled from (350224, 3) to (6187, 3) points (non-ground)\n",
      "Downsampled from (372916, 3) to (5525, 3) points (ground)\n",
      "Downsampled from (452246, 3) to (7807, 3) points (non-ground)\n",
      "Downsampled from (385946, 3) to (5562, 3) points (ground)\n",
      "Downsampled from (262978, 3) to (4456, 3) points (non-ground)\n",
      "Downsampled from (451230, 3) to (6189, 3) points (ground)\n",
      "Downsampled from (260853, 3) to (4469, 3) points (non-ground)\n",
      "Downsampled from (540630, 3) to (6637, 3) points (ground)\n",
      "Downsampled from (477380, 3) to (7261, 3) points (non-ground)\n",
      "Downsampled from (438394, 3) to (6594, 3) points (ground)\n",
      "Downsampled from (484851, 3) to (7762, 3) points (non-ground)\n",
      "Downsampled from (389528, 3) to (6532, 3) points (ground)\n",
      "Downsampled from (406142, 3) to (6391, 3) points (non-ground)\n",
      "Downsampled from (339234, 3) to (5270, 3) points (ground)\n",
      "Downsampled from (322094, 3) to (5849, 3) points (non-ground)\n",
      "Downsampled from (273519, 3) to (5086, 3) points (ground)\n",
      "Downsampled from (383759, 3) to (6583, 3) points (non-ground)\n",
      "Downsampled from (196088, 3) to (4418, 3) points (ground)\n",
      "Downsampled from (471693, 3) to (7780, 3) points (non-ground)\n",
      "Downsampled from (309908, 3) to (6091, 3) points (ground)\n",
      "Downsampled from (570103, 3) to (5949, 3) points (non-ground)\n",
      "Downsampled from (939537, 3) to (9495, 3) points (ground)\n",
      "Downsampled from (567185, 3) to (7039, 3) points (non-ground)\n",
      "Downsampled from (480866, 3) to (7211, 3) points (ground)\n",
      "Downsampled from (324509, 3) to (5945, 3) points (non-ground)\n",
      "Downsampled from (214718, 3) to (4765, 3) points (ground)\n",
      "Downsampled from (296982, 3) to (5076, 3) points (non-ground)\n",
      "Downsampled from (295734, 3) to (5203, 3) points (ground)\n",
      "Downsampled from (311607, 3) to (5367, 3) points (non-ground)\n",
      "Downsampled from (283045, 3) to (4829, 3) points (ground)\n",
      "Downsampled from (336036, 3) to (5544, 3) points (non-ground)\n",
      "Downsampled from (254495, 3) to (4716, 3) points (ground)\n",
      "Downsampled from (351770, 3) to (5478, 3) points (non-ground)\n",
      "Downsampled from (493796, 3) to (6512, 3) points (ground)\n",
      "Downsampled from (333876, 3) to (5378, 3) points (non-ground)\n",
      "Downsampled from (579172, 3) to (6166, 3) points (ground)\n",
      "Downsampled from (576526, 3) to (8127, 3) points (non-ground)\n",
      "Downsampled from (359545, 3) to (6037, 3) points (ground)\n",
      "Downsampled from (796774, 3) to (9306, 3) points (non-ground)\n",
      "Downsampled from (383977, 3) to (6355, 3) points (ground)\n",
      "Downsampled from (790877, 3) to (8685, 3) points (non-ground)\n",
      "Downsampled from (627610, 3) to (6811, 3) points (ground)\n"
     ]
    }
   ],
   "source": [
    "pcd_nonground_chunks, pcd_ground_chunks,\\\n",
    "pcd_nonground_chunks_major_downsampling, pcd_ground_chunks_major_downsampling, \\\n",
    "indices,indices_ground, center_positions, \\\n",
    "center_ids, chunk_bounds, kitti_labels, obbs = chunk_and_downsample_point_clouds(dataset,pcd_nonground_minor, pcd_ground_minor, T_pcd, positions, \n",
    "                                                            first_position, sampled_indices_global, chunk_size=chunk_size, \n",
    "                                                            overlap=overlap, major_voxel_size=major_voxel_size,kitti_labels=kitti_labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pcd_by_labels(pcd, labels,colors=None,gt_labels=None,semantics=False):\n",
    "    \n",
    "    if colors == None : \n",
    "        colors = generate_random_colors(2000)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colors = np.zeros(np.asarray(pcd.points).shape)\n",
    "    if gt_labels is None :\n",
    "    \tunique_labels = list(np.unique(labels)) \n",
    "    else: \n",
    "        unique_labels = list(np.unique(gt_labels))\n",
    "    \n",
    "    background_color = np.array([0,0,0])\n",
    "    #for i in range(len(pcd_colored.points)):\n",
    "    for i in unique_labels:\n",
    "        if i == -1 : \n",
    "            continue\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        if i == 0 and semantics == False : \n",
    "            pcd_colors[idcs] = background_color\n",
    "        else :\n",
    "            pcd_colors[idcs] = np.array(colors[unique_labels.index(i)])\n",
    "    \n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(pcd_colors/255)\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_normalized = {\n",
    "    0: [0.0, 0.0, 0.0],\n",
    "    1: [0.0, 0.0, 1.0],\n",
    "    10: [0.9607843137254902, 0.5882352941176471, 0.39215686274509803],\n",
    "    11: [0.9607843137254902, 0.9019607843137255, 0.39215686274509803],\n",
    "    13: [0.9803921568627451, 0.3137254901960784, 0.39215686274509803],\n",
    "    15: [0.5882352941176471, 0.23529411764705882, 0.11764705882352941],\n",
    "    16: [1.0, 0.0, 0.0],\n",
    "    18: [0.7058823529411765, 0.11764705882352941, 0.3137254901960784],\n",
    "    20: [1.0, 0.0, 0.0],\n",
    "    30: [0.11764705882352941, 0.11764705882352941, 1.0],\n",
    "    31: [0.7843137254901961, 0.1568627450980392, 1.0],\n",
    "    32: [0.35294117647058826, 0.11764705882352941, 0.5882352941176471],\n",
    "    40: [1.0, 0.0, 1.0],\n",
    "    44: [1.0, 0.5882352941176471, 1.0],\n",
    "    48: [0.29411764705882354, 0.0, 0.29411764705882354],\n",
    "    49: [0.29411764705882354, 0.0, 0.6862745098039216],\n",
    "    50: [0.0, 0.7843137254901961, 1.0],\n",
    "    51: [0.19607843137254902, 0.47058823529411764, 1.0],\n",
    "    52: [0.0, 0.5882352941176471, 1.0],\n",
    "    60: [0.6666666666666666, 1.0, 0.5882352941176471],\n",
    "    70: [0.0, 0.6862745098039216, 0.0],\n",
    "    71: [0.0, 0.23529411764705882, 0.5294117647058824],\n",
    "    72: [0.3137254901960784, 0.9411764705882353, 0.5882352941176471],\n",
    "    80: [0.5882352941176471, 0.9411764705882353, 1.0],\n",
    "    81: [0.0, 0.0, 1.0],\n",
    "    99: [1.0, 1.0, 0.19607843137254902],\n",
    "    252: [0.9607843137254902, 0.5882352941176471, 0.39215686274509803],\n",
    "    256: [1.0, 0.0, 0.0],\n",
    "    253: [0.7843137254901961, 0.1568627450980392, 1.0],\n",
    "    254: [0.11764705882352941, 0.11764705882352941, 1.0],\n",
    "    255: [0.35294117647058826, 0.11764705882352941, 0.5882352941176471],\n",
    "    257: [0.9803921568627451, 0.3137254901960784, 0.39215686274509803],\n",
    "    258: [0.7058823529411765, 0.11764705882352941, 0.3137254901960784],\n",
    "    259: [1.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "reverse_color_dict = {tuple(v): k for k, v in color_dict_normalized.items()}\n",
    "\n",
    "\n",
    "def color_pcd_kitti(pcd, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    pcd_colors = np.zeros_like(np.asarray(pcd.points))\n",
    "    for i in unique_labels:\n",
    "        idcs = np.where(labels == i)\n",
    "        idcs = idcs[0]\n",
    "        pcd_colors[idcs] = np.array(color_dict_normalized[int(i)])\n",
    "\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "    return pcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_map(inst_labels, sem_labels, sem_classes=[49, 50, 51, 70, 72]):\n",
    "\n",
    "    semantic_map = {}\n",
    "    total_merges = 0\n",
    "\n",
    "    inst_labels = inst_labels[np.isin(sem_labels, sem_classes)]\n",
    "    sem_labels = sem_labels[np.isin(sem_labels, sem_classes)]\n",
    "    for inst in np.unique(inst_labels)[1:]:\n",
    "        intersect, area = np.unique(sem_labels[inst_labels == inst], return_counts=True)\n",
    "        main_sem_label = intersect[np.argmax(area)]\n",
    "        semantic_map[inst] = main_sem_label\n",
    "        to_merge_sem_labels = intersect[intersect != main_sem_label]\n",
    "        num_merges = len(to_merge_sem_labels)\n",
    "        total_merges += num_merges\n",
    "    return semantic_map\n",
    "\n",
    "\n",
    "def get_num_splits(intersection, sem_classes, t_area, t_score, t_ratio):\n",
    "    result = {\n",
    "        \"inst\": [],\n",
    "        \"area\": [],\n",
    "        \"score\": [],\n",
    "        \"sem_labels\": [],\n",
    "        \"num_splits\": [],\n",
    "        \"sem_splits\": [],\n",
    "        \"main_sem_label\": [],\n",
    "        \"other_splits\": [],\n",
    "        \"valid_sem_label\": [],\n",
    "        \"sem-sem_splits\": [],\n",
    "    }\n",
    "    for idx, inst in enumerate(intersection[\"inst\"]):\n",
    "        # print(f\"inst: {inst}, area: {intersection['area'][inst]}, score: {intersection['score'][inst]}, sem_labels: {intersection['sem_labels'][inst]}, num_intersection: {intersection['num_intersection'][inst]}\")\n",
    "        area = np.sum(intersection[\"area\"][idx])\n",
    "        score = intersection[\"score\"][idx]\n",
    "        sem_label = intersection[\"sem_labels\"][idx]\n",
    "        if area > t_area and score < t_score and inst != 0:\n",
    "            intersect_area = intersection[\"area\"][idx]\n",
    "            num_splits = np.count_nonzero(intersect_area / area > t_ratio) - 1\n",
    "            valid_sem_label = sem_label[intersect_area / area > t_ratio]\n",
    "            sem_sem_splits = np.count_nonzero(np.isin(valid_sem_label, sem_classes)) - 1\n",
    "            other_splits = num_splits - sem_sem_splits\n",
    "            result[\"inst\"].append(inst)\n",
    "            result[\"area\"].append(area)\n",
    "            result[\"score\"].append(score)\n",
    "            result[\"sem_labels\"].append(sem_label)\n",
    "            result[\"num_splits\"].append(num_splits)\n",
    "            result[\"sem_splits\"].append(sem_label[intersect_area / area > t_ratio])\n",
    "            result[\"main_sem_label\"].append(sem_label[np.argmax(intersect_area)])\n",
    "            result[\"other_splits\"].append(other_splits)\n",
    "            result[\"valid_sem_label\"].append(valid_sem_label)\n",
    "            result[\"sem-sem_splits\"].append(sem_sem_splits)\n",
    "        num_splits = np.sum(result[\"num_splits\"])\n",
    "        sem2sem_splits = np.sum(result[\"sem-sem_splits\"])\n",
    "        # print(f\"inst: {inst}, area: {area}, score: {score}, sem_labels: {intersection['sem_labels'][idx]}, num_intersection: {intersection['num_intersection'][idx]}, num_splits: {num_splits}\")\n",
    "    return result, (num_splits, sem2sem_splits)\n",
    "\n",
    "\n",
    "def create_sub_instances(inst_labels, sem_labels, result):\n",
    "    new_inst_labels = inst_labels.copy()\n",
    "    last_inst_id = np.max(inst_labels)\n",
    "    for inst in np.unique(inst_labels):\n",
    "\n",
    "        if inst in result[\"inst\"]:\n",
    "            idx = np.where(result[\"inst\"] == inst)[0][0]\n",
    "            sem_splits = result[\"sem_splits\"][idx]\n",
    "            main_sem_label = result[\"main_sem_label\"][idx]\n",
    "            to_split = sem_splits[sem_splits != main_sem_label]\n",
    "            for split in to_split:\n",
    "                last_inst_id += 1\n",
    "                # print(f\"Splitting instance {inst} with sem label {split} into {last_inst_id}\")\n",
    "                new_inst_labels[\n",
    "                    np.logical_and(inst_labels == inst, sem_labels == split)\n",
    "                ] = last_inst_id\n",
    "    return new_inst_labels\n",
    "\n",
    "\n",
    "def get_intersection(labels_sem, pred_labels, ignore_labels=[0, 1, 52, 99, 40, 48, 49]):\n",
    "    intersection = {\n",
    "        \"inst\": [],\n",
    "        \"sem_labels\": [],\n",
    "        \"area\": [],\n",
    "        \"num_intersection\": [],\n",
    "        \"score\": [],\n",
    "    }\n",
    "    for i in ignore_labels:\n",
    "        labels_sem[labels_sem == i] = 0\n",
    "    pred_labels = pred_labels[labels_sem != 0]\n",
    "    labels_sem = labels_sem[labels_sem != 0]\n",
    "    for label in np.unique(pred_labels):\n",
    "        intersect, area = np.unique(\n",
    "            labels_sem[pred_labels == label], return_counts=True\n",
    "        )\n",
    "        intersection[\"inst\"].append(label)\n",
    "        intersection[\"sem_labels\"].append(intersect)\n",
    "        intersection[\"area\"].append(area)\n",
    "        intersection[\"num_intersection\"].append(len(intersect))\n",
    "        max_area = np.max(area)\n",
    "        # error_area = np.sum(area[area != max_area])\n",
    "        score = max_area / np.sum(area)\n",
    "        intersection[\"score\"].append(score)\n",
    "    return intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subpcd(pcd, indices, colors=False, normals=False):\n",
    "    subpcd = o3d.geometry.PointCloud()\n",
    "    subpcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points)[indices])\n",
    "    new_cols = copy.deepcopy(np.asarray(pcd.colors)[indices])\n",
    "    subpcd.colors = o3d.utility.Vector3dVector(new_cols)\n",
    "    return subpcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131]\n",
      "total sequence number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 66\n",
      "Start of sequence 0\n",
      "7776 points in downsampled chunk (major)\n",
      "label shape (370, 1226)\n",
      "Adjacency Matrix built\n",
      "0 isolated points removed\n",
      "Start of normalized Cuts\n",
      "--------------\n",
      "graph construction  94.73434400558472  s\n",
      "There are 31 cut regions\n",
      "NCuts took  28.06585669517517  s\n",
      "Ratio of points in top 3 groups: 0.5866769547325102\n",
      "Dino load  124.75428438186646  s\n",
      "Ncuts percentage  22.0\n",
      "Construction  76.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:06<08:24, 126.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write gt ../../pcd_preprocessed/output_chunks/out_kitti_instance7/000066.pcd\n",
      "Sequence 93\n",
      "Start of sequence 1\n",
      "7216 points in downsampled chunk (major)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:07<08:28, 127.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m sequence \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,limit)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSequence\u001b[39m\u001b[39m'\u001b[39m,center_ids[sequence])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m                 merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground \u001b[39m=\u001b[39m ncuts_chunk(dataset,\u001b[39mlist\u001b[39;49m(indices),pcd_nonground_chunks,pcd_ground_chunks,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m                         pcd_nonground_chunks_major_downsampling,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m                         pcd_nonground_minor,T_pcd,center_positions,center_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m                         positions,first_position,\u001b[39mlist\u001b[39;49m(sampled_indices_global),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m                         chunk_size\u001b[39m=\u001b[39;49mchunk_size,major_voxel_size\u001b[39m=\u001b[39;49mmajor_voxel_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m                         alpha\u001b[39m=\u001b[39;49malpha,beta\u001b[39m=\u001b[39;49mbeta,gamma\u001b[39m=\u001b[39;49mgamma,theta\u001b[39m=\u001b[39;49mtheta,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                         proximity_threshold\u001b[39m=\u001b[39;49mproximity_threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                         out_folder\u001b[39m=\u001b[39;49mout_folder_ncuts,ground_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,sequence\u001b[39m=\u001b[39;49msequence,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                         patchwise_indices\u001b[39m=\u001b[39;49mpatchwise_indices,ncuts_threshold\u001b[39m=\u001b[39;49mncuts_threshold,obb\u001b[39m=\u001b[39;49mobbs[sequence],hpr_radius\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,visible\u001b[39m=\u001b[39;49mVISIBLE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m                 cols, labels_kitti_cur \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                 np\u001b[39m.\u001b[39masarray(pcd_chunk\u001b[39m.\u001b[39mcolors), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                 )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cedric/unsup_3d_instances/point-to-pixel-mapping/notebooks/kitti/example_dataset_generation_out_refactor.ipynb#X22sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m                 visible_parts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(labels_kitti_cur \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/ncuts_utils_ablations.py:128\u001b[0m, in \u001b[0;36mncuts_chunk\u001b[0;34m(dataset, indices, pcd_nonground_chunks, pcd_ground_chunks, pcd_nonground_chunks_major_downsampling, pcd_nonground_minor, T_pcd, center_positions, center_ids, positions, first_position, sampled_indices_global, chunk_size, major_voxel_size, alpha, beta, gamma, theta, proximity_threshold, ncuts_threshold, cams, cam_ids, out_folder, ground_mode, sequence, patchwise_indices, adjacent_frames_cam, adjacent_frames_tarl, use_z, norm, split_lim, obb, mean_height, hpr_radius, visible)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m# print(\"Spatial construction took \", end  , \" s\")\u001b[39;00m\n\u001b[1;32m    127\u001b[0m cur_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 128\u001b[0m point2dino_list, visibility_mask \u001b[39m=\u001b[39m image_based_features_per_patch(\n\u001b[1;32m    129\u001b[0m     dataset,\n\u001b[1;32m    130\u001b[0m     pcd_nonground_minor,\n\u001b[1;32m    131\u001b[0m     chunk_indices,\n\u001b[1;32m    132\u001b[0m     chunk_major,\n\u001b[1;32m    133\u001b[0m     major_voxel_size,\n\u001b[1;32m    134\u001b[0m     T_pcd,\n\u001b[1;32m    135\u001b[0m     cam_indices_global,\n\u001b[1;32m    136\u001b[0m     cams,\n\u001b[1;32m    137\u001b[0m     cam_ids\u001b[39m=\u001b[39;49mcam_ids,\n\u001b[1;32m    138\u001b[0m     hpr_radius\u001b[39m=\u001b[39;49mhpr_radius,\n\u001b[1;32m    139\u001b[0m     num_dino_features\u001b[39m=\u001b[39;49m\u001b[39m384\u001b[39;49m,\n\u001b[1;32m    140\u001b[0m     sam\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    141\u001b[0m     dino\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    142\u001b[0m     rm_perp\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m    143\u001b[0m     pcd_chunk\u001b[39m=\u001b[39;49mpcd_chunk,\n\u001b[1;32m    144\u001b[0m     obb\u001b[39m=\u001b[39;49mobb,\n\u001b[1;32m    145\u001b[0m     vis\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m dinov2_features_major_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m point2dino \u001b[39min\u001b[39;00m point2dino_list:\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/chunk_generation.py:400\u001b[0m, in \u001b[0;36mimage_based_features_per_patch\u001b[0;34m(dataset, pcd, chunk_indices, chunk_nc, voxel_size, T_pcd2world, cam_indices, cams, cam_ids, hpr_radius, num_dino_features, hpr_masks, sam, dino, rm_perp, pcd_chunk, obb, vis)\u001b[0m\n\u001b[1;32m    397\u001b[0m num_points_nc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(chunk_nc\u001b[39m.\u001b[39mpoints)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    399\u001b[0m pcd_chunk \u001b[39m=\u001b[39m get_subpcd(pcd, chunk_indices)\n\u001b[0;32m--> 400\u001b[0m inlier_indices_of_chunk \u001b[39m=\u001b[39m get_statistical_inlier_indices(pcd_chunk)\n\u001b[1;32m    401\u001b[0m chunk_and_inlier_indices \u001b[39m=\u001b[39m chunk_indices[inlier_indices_of_chunk]\n\u001b[1;32m    403\u001b[0m visibility_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\n\u001b[1;32m    404\u001b[0m     (np\u001b[39m.\u001b[39masarray(chunk_nc\u001b[39m.\u001b[39mpoints)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    405\u001b[0m )  \u001b[39m### for ablation eval\u001b[39;00m\n",
      "File \u001b[0;32m~/unsup_3d_instances/point-to-pixel-mapping/point_cloud_utils.py:180\u001b[0m, in \u001b[0;36mget_statistical_inlier_indices\u001b[0;34m(pcd, nb_neighbors, std_ratio)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_statistical_inlier_indices\u001b[39m(pcd, nb_neighbors\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, std_ratio\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m):\n\u001b[0;32m--> 180\u001b[0m     _, inlier_indices \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(pcd)\u001b[39m.\u001b[39;49mremove_statistical_outlier(\n\u001b[1;32m    181\u001b[0m         nb_neighbors\u001b[39m=\u001b[39;49mnb_neighbors, std_ratio\u001b[39m=\u001b[39;49mstd_ratio\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m inlier_indices\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = 1.0\n",
    "theta = 0.5\n",
    "colors = generate_random_colors_map(600)\n",
    "beta = 0.0\n",
    "gamma = 0.0\n",
    "proximity_threshold = 1.0\n",
    "tarl_norm = False\n",
    "ncuts_threshold = 0.03\n",
    "        \n",
    "out_name = 'tarl_dino_spatial' + str(SEQUENCE_NUM) \n",
    "limit = len(center_ids)\n",
    "limit = 5\n",
    "VISIBLE = False \n",
    "# Generate 30 different colors\n",
    " \n",
    "\n",
    "COLORS = generate_random_colors(400)\n",
    "COLORS = [(col[0]/255.,col[1]/255.,col[2]/255.) for col in COLORS]\n",
    "\n",
    "\n",
    "        \n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "\n",
    "if os.path.exists(out_kitti_instance) == True : \n",
    "        shutil.rmtree(out_kitti_instance)\n",
    "os.makedirs(out_kitti_instance)\n",
    "\n",
    "\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "\n",
    "if os.path.exists(out_kitti_semantic) == True : \n",
    "        shutil.rmtree(out_kitti_semantic)\n",
    "os.makedirs(out_kitti_semantic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "out_data = []\n",
    "semantics = np.hstack((kitti_labels_orig['seg_nonground'].reshape(-1,),kitti_labels_orig['seg_ground'].reshape(-1,)))\n",
    "\n",
    "instances = np.hstack((kitti_labels_orig['instance_nonground'].reshape(-1,),kitti_labels_orig['instance_ground'].reshape(-1,)))\n",
    "print('number of instances',np.unique(instances))\n",
    "merge_pcd = o3d.geometry.PointCloud()    \n",
    "\n",
    "\n",
    "\n",
    "print(\"total sequence number\",limit)\n",
    "for sequence in tqdm(range(0,limit)):\n",
    "                print('Sequence',center_ids[sequence])\n",
    "                merged_chunk,file_name, pcd_chunk, pcd_chunk_ground,inliers, inliers_ground = ncuts_chunk(dataset,list(indices),pcd_nonground_chunks,pcd_ground_chunks,\n",
    "                        pcd_nonground_chunks_major_downsampling,\n",
    "                        pcd_nonground_minor,T_pcd,center_positions,center_ids,\n",
    "                        positions,first_position,list(sampled_indices_global),\n",
    "                        chunk_size=chunk_size,major_voxel_size=major_voxel_size,\n",
    "                        alpha=alpha,beta=beta,gamma=gamma,theta=theta,\n",
    "                        proximity_threshold=proximity_threshold,\n",
    "                        out_folder=out_folder_ncuts,ground_mode=False,sequence=sequence,\n",
    "                        patchwise_indices=patchwise_indices,ncuts_threshold=ncuts_threshold,obb=obbs[sequence],hpr_radius=1000,visible=VISIBLE)\n",
    "                \n",
    "                cols, labels_kitti_cur = np.unique(\n",
    "                np.asarray(pcd_chunk.colors), axis=0, return_inverse=True\n",
    "                )\n",
    "                \n",
    "                visible_parts = np.where(labels_kitti_cur != 0)[0]\n",
    "                \n",
    "                #o3d.visualization.draw_geometries([color_pcd_by_labels(pcd_chunk,labels_kitti_cur)])\n",
    "                #o3d.visualization.draw_geometries([get_subpcd(pcd_chunk,visible_parts)])\n",
    "                \n",
    "                seg_ground = kitti_labels['ground']['semantic'][sequence][inliers][inliers_ground]\n",
    "                inst_ground = kitti_labels['ground']['instance'][sequence][inliers][inliers_ground]\n",
    "                \n",
    "                file_name = str(center_ids[sequence]).zfill(6) + '.pcd'\n",
    "                \n",
    "                sem_non_ground = kitti_labels['nonground']['semantic'][sequence].reshape(-1,)\n",
    "                inst_non_ground = kitti_labels['nonground']['instance'][sequence].reshape(-1,)\n",
    "                if VISIBLE : \n",
    "                        sem_non_ground = sem_non_ground[visible_parts]\n",
    "                        inst_non_ground = inst_non_ground[visible_parts]\n",
    "                        pcd_chunk = get_subpcd(pcd_chunk,visible_parts)\n",
    "                        \n",
    "                cur_pred = pcd_chunk + pcd_chunk_ground\n",
    "                \n",
    "                kitti_chunk_instance = color_pcd_by_labels(copy.deepcopy(pcd_chunk),inst_non_ground,\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "                                        \n",
    "                kitti_chunk_instance_ground = color_pcd_by_labels(copy.deepcopy(pcd_chunk_ground),inst_ground.reshape(-1,),\n",
    "                                        colors=colors,gt_labels=instances)\n",
    "\n",
    "                semantics_non_ground = color_pcd_kitti(copy.deepcopy(pcd_chunk),sem_non_ground)\n",
    "                semantics_ground = color_pcd_kitti(copy.deepcopy(pcd_chunk_ground),seg_ground.reshape(-1,))\n",
    "                kitti_semantics = np.hstack((kitti_labels['nonground']['semantic'][sequence].reshape(-1,),seg_ground.reshape(-1,)))\n",
    "                                                \n",
    "                \n",
    "                o3d.io.write_point_cloud(out_folder_ncuts + file_name, cur_pred , write_ascii=False, compressed=False, print_progress=False)\n",
    "                print('write gt',out_kitti_instance + file_name)\n",
    "                o3d.io.write_point_cloud(out_kitti_instance + file_name, kitti_chunk_instance + kitti_chunk_instance_ground, write_ascii=False, compressed=False, print_progress=False)\n",
    "                o3d.io.write_point_cloud(out_kitti_semantic + file_name, semantics_non_ground + semantics_ground, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd']\n",
      "obtained semantic labels\n",
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd']\n",
      "['000066.pcd', '000093.pcd', '000125.pcd', '000164.pcd', '000193.pcd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "point_cloud_semantis = get_merge_pcds(out_kitti_semantic)\n",
    "seg_pcd = merge_unite_gt(point_cloud_semantis)\n",
    "cols, labels_kitti_cur = np.unique(\n",
    "                np.asarray(seg_pcd.colors), axis=0, return_inverse=True\n",
    "            )\n",
    "\n",
    "seg_labels = np.zeros(np.asarray(seg_pcd.colors).shape[0]) #semantic labels \n",
    "for label in np.unique(labels_kitti_cur):\n",
    "                idcs = np.where(labels_kitti_cur == label)[0]\n",
    "                col_cur = np.asarray(seg_pcd.colors)[idcs][0]\n",
    "                seg_labels[idcs] = reverse_color_dict[tuple(col_cur)]\n",
    "\n",
    "print('obtained semantic labels')\n",
    "out_kitti_instance = out_chunks + 'out_kitti_instance' + str(SEQUENCE_NUM) + '/'\n",
    "out_kitti_semantic = out_chunks + 'out_kitti_semantic' + str(SEQUENCE_NUM) + '/'\n",
    "point_clouds_kitti_instances = get_merge_pcds(out_kitti_instance)\n",
    "instance_pcd = merge_unite_gt(point_clouds_kitti_instances)\n",
    "\n",
    "point_clouds_pred = get_merge_pcds(out_folder_ncuts)\n",
    "merge = merge_chunks_unite_instances2(point_clouds_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 10572.21it/s]\n",
      "Processing: 100%|██████████| 48/48 [00:00<00:00, 104.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028865\n",
      "2028865\n",
      "start\n",
      "Metrics for file ncuts\n",
      "update stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 814.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got all the idcs\n",
      "full stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fScore': 0.6153846153846153, 'precision': 0.75, 'recall': 0.5217391304347826, 'panoptic': 0.5291278185193117}\n",
      "S_assoc score :  0.4723125906974671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP @ 0.25 43.985\n",
      "AP @ 0.5 39.252\n",
      "AP @ [0.5:0.95] 23.053\n",
      "Computing metrics with Visibility setting :  True\n",
      "Num merges 24\n",
      "Num splits 22\n",
      "Num actions 46\n",
      "Num sem2sem splits  7\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unique_colors, label_inst = np.unique(np.asarray(instance_pcd.colors), axis=0, return_inverse=True)\n",
    "unique_colors, labels_ncuts_all = np.unique(np.asarray(merge.colors), axis=0, return_inverse=True)\n",
    "\n",
    "new_ncuts_labels = remove_semantics(label_inst,labels_ncuts_all)\n",
    "print(labels_ncuts_all.shape[0])\n",
    "print(label_inst.shape[0])\n",
    "metrics_ncuts = Metrics(name='ncuts')\n",
    "metrics_ncuts.update_stats(labels_ncuts_all,new_ncuts_labels,label_inst)\n",
    "\n",
    "\n",
    "\n",
    "sem_classes = [49, 50, 51, 70, 72]\n",
    "ignore_labels = [0, 1, 52, 99, 40, 48, 49]\n",
    "\n",
    "print(\"Computing metrics with Visibility setting : \",VISIBLE)\n",
    "sem_labels = seg_labels\n",
    "intersection = get_intersection(sem_labels, labels_ncuts_all)\n",
    "result, (num_splits, sem2sem_splits) = get_num_splits(\n",
    "            intersection, sem_classes, 200, 0.9, 0.02\n",
    "        )\n",
    "new_labels = create_sub_instances(labels_ncuts_all, sem_labels, result)\n",
    "semantic_map = get_semantic_map(new_labels, sem_labels, sem_classes)\n",
    "value_counts = Counter(semantic_map.values())\n",
    "num_merges = np.sum(list(value_counts.values())) - len(value_counts)\n",
    "\n",
    "print('theta',theta)\n",
    "print('alpha',alpha)\n",
    "print('gamma',gamma)\n",
    "\n",
    "print(\"Num merges\",num_merges)\n",
    "print(\"Num splits\",num_splits)\n",
    "print(\"Num actions\",num_merges + num_splits)\n",
    "print(\"Num sem2sem splits \", sem2sem_splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
