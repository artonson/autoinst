{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "src_path = os.path.abspath(\"../..\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "%load_ext autoreload\n",
    "from dataset.kitti_odometry_dataset import KittiOdometryDataset, KittiOdometryDatasetConfig\n",
    "from dataset.filters.filter_list import FilterList\n",
    "from dataset.filters.kitti_gt_mo_filter import KittiGTMovingObjectFilter\n",
    "from dataset.filters.range_filter import RangeFilter\n",
    "from dataset.filters.apply_pose import ApplyPose\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from normalized_cut import normalized_cut\n",
    "\n",
    "from point_cloud_utils import get_pcd, transform_pcd, kDTree_1NN_feature_reprojection, remove_isolated_points, get_subpcd, get_statistical_inlier_indices, merge_chunks_unite_instances\n",
    "from aggregate_pointcloud import aggregate_pointcloud\n",
    "from visualization_utils import generate_random_colors, color_pcd_by_labels\n",
    "from sam_label_distace import sam_label_distance\n",
    "from chunk_generation import subsample_positions, chunks_from_pointcloud, indices_per_patch, tarl_features_per_patch, image_based_features_per_patch, dinov2_mean, get_indices_feature_reprojection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset depending on kitti sequence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    sam_folder_name=\"sam_pred_medium\",\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "            KittiGTMovingObjectFilter(\n",
    "                os.path.join(\n",
    "                    DATASET_PATH,\n",
    "                    \"sequences\",\n",
    "                    \"%.2d\" % SEQUENCE_NUM,\n",
    "                    \"labels\",\n",
    "                )\n",
    "            ),\n",
    "            RangeFilter(3, 25),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)\n",
    "out_folder = 'pcd_preprocessed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate a large point cloud based on (ind_start, ind_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 0\n",
    "ind_end = 1100\n",
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "\n",
    "pcd_ground, pcd_nonground, all_poses, T_pcd = aggregate_pointcloud(dataset, ind_start, ind_end, ground_segmentation=\"patchwork\", icp=True)\n",
    "first_position = T_pcd[:3,3]\n",
    "\n",
    "pcd_ground_minor = pcd_ground.voxel_down_sample(voxel_size=minor_voxel_size)\n",
    "pcd_nonground_minor = pcd_nonground.voxel_down_sample(voxel_size=minor_voxel_size)\n",
    "\n",
    "num_points = np.asarray(pcd_nonground.points).shape[0]\n",
    "print(\"num points: \", num_points, \"in non-ground pcd\")\n",
    "\n",
    "num_points_minor = np.asarray(pcd_nonground_minor.points).shape[0]\n",
    "print(\"num points: \", num_points_minor, \"in non-ground pcd with downsampling of\", minor_voxel_size)\n",
    "\n",
    "\n",
    "\n",
    "o3d.io.write_point_cloud(out_folder +  'ground' + str(SEQUENCE_NUM) + '.pcd', pcd_ground, \n",
    "\t\t\twrite_ascii=False, compressed=False, print_progress=False)\n",
    "\t\t\t\n",
    "o3d.io.write_point_cloud(out_folder + 'non_ground' + str(SEQUENCE_NUM) + '.pcd', pcd_nonground, \n",
    "\t\t\twrite_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "o3d.io.write_point_cloud(out_folder + 'ground_minor' + str(SEQUENCE_NUM) + '.pcd', pcd_ground_minor, \n",
    "\t\t\twrite_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "o3d.io.write_point_cloud(out_folder + 'non_ground_minor' + str(SEQUENCE_NUM) + '.pcd', pcd_nonground_minor, \n",
    "\t\t\twrite_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "np.savez(out_folder + 'all_poses.npz',all_poses=all_poses,T_pcd=T_pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_voxel_size = 0.05\n",
    "major_voxel_size = 0.35\n",
    "ind_start = 0 \n",
    "ind_end = 1100\n",
    "\n",
    "with np.load(out_folder + 'all_poses.npz') as data:\n",
    "\tall_poses = data['all_poses']\n",
    "\tT_pcd = data['T_pcd']\n",
    "\tfirst_position = T_pcd[:3,3]\n",
    "\t\n",
    "pcd_ground = o3d.io.read_point_cloud(out_folder + 'ground' + str(SEQUENCE_NUM) + '.pcd')\n",
    "pcd_nonground = o3d.io.read_point_cloud(out_folder + 'non_ground' + str(SEQUENCE_NUM) + '.pcd')\n",
    "\n",
    "pcd_ground_minor = pcd_ground.voxel_down_sample(voxel_size=minor_voxel_size)\n",
    "pcd_nonground_minor = pcd_nonground.voxel_down_sample(voxel_size=minor_voxel_size)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subsample the poses based on a voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positions = []\n",
    "for p in all_poses:\n",
    "    all_positions.append(tuple(p[:3,3]))\n",
    "\n",
    "sampled_indices_local = list(subsample_positions(all_positions, voxel_size=1))\n",
    "sampled_indices_global = list(subsample_positions(all_positions, voxel_size=1) + ind_start)\n",
    "\n",
    "poses = np.array(all_poses)[sampled_indices_local]\n",
    "positions = np.array(all_positions)[sampled_indices_local]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the point cloud into chunks based on a tbd chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = np.array([25, 25, 25]) #meters\n",
    "overlap = 3 #meters\n",
    "\n",
    "pcd_nonground_chunks, indices, center_positions, center_ids, chunk_bounds = chunks_from_pointcloud(pcd_nonground_minor, T_pcd, positions, first_position, sampled_indices_global, chunk_size, overlap)\n",
    "pcd_ground_chunks, _, _, _, _ = chunks_from_pointcloud(pcd_ground_minor, T_pcd, positions, first_position, sampled_indices_global, chunk_size, overlap)\n",
    "\n",
    "pcd_nonground_chunks_major_downsampling = []\n",
    "pcd_ground_chunks_major_downsampling = []\n",
    "\n",
    "for nonground, ground in zip(pcd_nonground_chunks, pcd_ground_chunks):\n",
    "    pcd_nonground_chunks_major_downsampling.append(nonground.voxel_down_sample(voxel_size=major_voxel_size))\n",
    "    pcd_ground_chunks_major_downsampling.append(ground.voxel_down_sample(voxel_size=major_voxel_size))\n",
    "    print(\"Downsampled from\", np.asarray(nonground.points).shape, \"to\", np.asarray(pcd_nonground_chunks_major_downsampling[-1].points).shape, \"points (non-ground)\")\n",
    "    print(\"Downsampled from\", np.asarray(ground.points).shape, \"to\", np.asarray(pcd_ground_chunks_major_downsampling[-1].points).shape, \"points (ground)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchwise_indices = indices_per_patch(T_pcd, center_positions, positions, first_position, sampled_indices_global, chunk_size)\n",
    "\n",
    "for sequence in range(len(center_ids)):\n",
    "\n",
    "    print(\"Start of sequence \", sequence)\n",
    "\n",
    "    first_id = patchwise_indices[sequence][0]\n",
    "    center_id = center_ids[sequence]\n",
    "    center_position = center_positions[sequence]\n",
    "    chunk_indices = indices[sequence]\n",
    "\n",
    "    cam_indices_global, hpr_mask_indices = get_indices_feature_reprojection(sampled_indices_global, first_id, adjacent_frames=(16,13)) \n",
    "    \n",
    "    pcd_chunk = pcd_nonground_chunks[sequence]\n",
    "    pcd_ground_chunk = pcd_ground_chunks[sequence]\n",
    "    chunk_major = pcd_nonground_chunks_major_downsampling[sequence]\n",
    "\n",
    "    points_major = np.asarray(chunk_major.points)\n",
    "    num_points_major = points_major.shape[0]   \n",
    "\n",
    "    print(num_points_major, \"points in downsampled chunk (major)\")\n",
    "\n",
    "    #tarl_features = tarl_features_per_patch(dataset, chunk_major, center_id, T_pcd, center_position, sampled_indices_global, chunk_size, major_voxel_size)\n",
    "\n",
    "    cams = [\"cam2\", \"cam3\"]\n",
    "\n",
    "    sam_features_minor, chunk_minor = image_based_features_per_patch(dataset, pcd_nonground_minor, chunk_indices, T_pcd, cam_indices_global, cams, cam_id=0, hpr_radius=2000, dino=False, rm_perp=0.0)\n",
    "    #point2dino\n",
    "    #dinov2_features_minor = dinov2_mean(point2dino)\n",
    "    \n",
    "    sam_features_major = -1 * np.ones((num_points_major, sam_features_minor.shape[1]))\n",
    "    #dinov2_features_major = np.zeros((num_points_major, dinov2_features_minor.shape[1])) \n",
    "\n",
    "    sam_features_major = kDTree_1NN_feature_reprojection(sam_features_major, chunk_major, sam_features_minor, chunk_minor)\n",
    "    #dinov2_features_major = kDTree_1NN_feature_reprojection(dinov2_features_major, chunk_major, dinov2_features_minor, chunk_minor)\n",
    "\n",
    "    zero_rows = np.sum(~np.array(sam_features_major).any(1))\n",
    "    ratio = zero_rows / num_points_major\n",
    "\n",
    "    if ratio > 0.3:\n",
    "        print(\"The ratio of points without image-based features is\", ratio, \". Skipping this chunk.\")\n",
    "        continue\n",
    "\n",
    "    spatial_distance = cdist(points_major, points_major)\n",
    "    #dinov2_distance = cdist(dinov2_features_major, dinov2_features_major)\n",
    "    #tarl_distance = cdist(tarl_features, tarl_features)\n",
    "\n",
    "    proximity_threshold = 1 # meters that points can be apart from each other and still be considered neighbors\n",
    "    alpha = 6.0 # weight of the spatial proximity term \n",
    "    beta = 0.0 # weight of the label similarity term\n",
    "    gamma = 0.0 # weight of the dinov2 feature similarity term\n",
    "    theta = 3.0 # weight of the tarl feature similarity term\n",
    "\n",
    "    sam_edge_weights, mask = sam_label_distance(sam_features_major, spatial_distance, proximity_threshold, beta)\n",
    "    #spatial_edge_weights = mask * np.exp(-alpha * spatial_distance)\n",
    "    #dinov2_edge_weights = mask * np.exp(-gamma * dinov2_distance)\n",
    "    #tarl_edge_weights = mask * np.exp(-theta * tarl_distance)\n",
    "\n",
    "    A = sam_edge_weights #spatial_edge_weights * sam_edge_weights * dinov2_edge_weights * tarl_edge_weights\n",
    "    print(\"Adjacency Matrix built\")\n",
    "\n",
    "    # Remove isolated points\n",
    "    chunk_major, A = remove_isolated_points(chunk_major, A)\n",
    "    print(num_points_major - np.asarray(chunk_major.points).shape[0], \"isolated points removed\")\n",
    "    num_points_major = np.asarray(chunk_major.points).shape[0]\n",
    "\n",
    "    print(\"Start of normalized Cuts\")\n",
    "    grouped_labels = normalized_cut(A, np.arange(num_points_major), T = 0.08)\n",
    "    num_groups = len(grouped_labels)\n",
    "    print(\"There are\", num_groups, \"cut regions\")\n",
    "\n",
    "    sorted_groups = sorted(grouped_labels, key=lambda x: len(x))\n",
    "    num_points_top3 = np.sum([len(g) for g in sorted_groups[-3:]])\n",
    "    top3_ratio = num_points_top3 / num_points_major\n",
    "    print(\"Ratio of points in top 3 groups:\", top3_ratio)\n",
    "\n",
    "    random_colors = generate_random_colors(600)\n",
    "\n",
    "    pcd_color = np.zeros((num_points_major, 3))\n",
    "\n",
    "    for i, s in enumerate(grouped_labels):\n",
    "        for j in s:\n",
    "            pcd_color[j] = np.array(random_colors[i]) / 255\n",
    "\n",
    "    pcd_chunk.paint_uniform_color([0, 0, 0])\n",
    "    colors = kDTree_1NN_feature_reprojection(np.asarray(pcd_chunk.colors), pcd_chunk, pcd_color, chunk_major)\n",
    "    pcd_chunk.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    inliers = get_statistical_inlier_indices(pcd_ground_chunk)\n",
    "    ground_inliers = get_subpcd(pcd_ground_chunk, inliers)\n",
    "    mean_hight = np.mean(np.asarray(ground_inliers.points)[:,2])\n",
    "    cut_hight = get_subpcd(ground_inliers, np.where(np.asarray(ground_inliers.points)[:,2] < (mean_hight + 0.2))[0])\n",
    "    cut_hight.paint_uniform_color([0, 0, 0])\n",
    "\n",
    "    merged_chunk = pcd_chunk + cut_hight\n",
    "\n",
    "    index_file = str(center_id).zfill(6) + '.pcd'\n",
    "    file = os.path.join(\"test_data\", index_file)\n",
    "\n",
    "    o3d.io.write_point_cloud(file, merged_chunk, write_ascii=False, compressed=False, print_progress=False)\n",
    "\n",
    "    print(\"Pointcloud written to file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the chunks to one large Map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_clouds = []\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(\"test_data\")\n",
    "files.sort()\n",
    "\n",
    "# Filter files with a .pcd extension\n",
    "pcd_files = [file for file in files if file.endswith(\".pcd\")][:3]\n",
    "print(pcd_files)\n",
    "# Load each point cloud and append to the list\n",
    "for pcd_file in pcd_files:\n",
    "    file_path = os.path.join(\"test_data\", pcd_file)\n",
    "    point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "    point_clouds.append(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge_chunks_unite_instances(point_clouds)\n",
    "o3d.io.write_point_cloud(\"test_data/merge_part.pcd\", merge, write_ascii=False, compressed=False, print_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/media/cedric/Datasets1/semantic_kitti/')\n",
    "SEQUENCE_NUM = 7\n",
    "\n",
    "\n",
    "config_filtered = KittiOdometryDatasetConfig(\n",
    "    cache=True,\n",
    "    dataset_path=DATASET_PATH,\n",
    "    sam_folder_name=\"sam_pred_medium\",\n",
    "    correct_scan_calibration=True,\n",
    "    filters=FilterList(\n",
    "        [\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "dataset = KittiOdometryDataset(config_filtered, SEQUENCE_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kDTree_1NN_feature_reprojection(features_to, pcd_to, features_from, pcd_from, labels=None,max_radius=None, no_feature_label=[1,0,0]):\n",
    "    '''\n",
    "    Args:\n",
    "        pcd_from: point cloud to be projected\n",
    "        pcd_to: point cloud to be projected to\n",
    "        search_method: search method (\"radius\", \"knn\")\n",
    "        search_param: search parameter (radius or k)\n",
    "    Returns:\n",
    "        features_to: features projected on pcd_to\n",
    "    '''\n",
    "    from_tree = o3d.geometry.KDTreeFlann(pcd_from)\n",
    "    labels_output = np.ones(np.asarray(pcd_to.points).shape[0],) * -1\n",
    "    unique_colors = list(np.unique(np.asarray(pcd_from.colors),axis=0)) \n",
    "    \n",
    "    for i, point in enumerate(np.asarray(pcd_to.points)):\n",
    "\n",
    "        [_, idx, _] = from_tree.search_knn_vector_3d(point, 1)\n",
    "        if max_radius is not None:\n",
    "            if np.linalg.norm(point - np.asarray(pcd_from.points)[idx[0]]) > max_radius:\n",
    "                features_to[i,:] = no_feature_label\n",
    "                if labels is not None : \n",
    "                    labels[i] = -1\n",
    "                    labels_output[i] = -1 \n",
    "            else:\n",
    "                features_to[i,:] = features_from[idx[0]]\n",
    "                labels_output[i] = np.where((unique_colors == features_from[idx[0]]).all(axis=1))[0]\n",
    "        else:\n",
    "            features_to[i,:] = features_from[idx[0]]\n",
    "            labels_output[i] = np.where((unique_colors == features_from[idx[0]]).all(axis=1))[0]\n",
    "        \n",
    "        \n",
    "    if labels is not None : \n",
    "        return features_to,labels, labels_output\n",
    "    else : \n",
    "        return features_to, None, labels_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def color_pcd_by_labels(pcd, labels):\n",
    "    \n",
    "    colors = generate_random_colors(500)\n",
    "    pcd_colored = copy.deepcopy(pcd)\n",
    "    pcd_colored.colors = o3d.utility.Vector3dVector(np.zeros(np.asarray(pcd.points).shape))\n",
    "    \n",
    "    unique_labels = list(np.unique(labels)) \n",
    "    for i in range(len(pcd_colored.points)):\n",
    "        if labels[i] != (-1):\n",
    "            color = colors[unique_labels.index(labels[i])]\n",
    "            pcd_colored.colors[i] = np.array(color) / 255\n",
    "\n",
    "    return pcd_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d.pipelines import registration\n",
    "import numpy as np \n",
    "merge = o3d.io.read_point_cloud(\"test_data/merge_part.pcd\")\n",
    "merge.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\n",
    "for i in range(0,100):\n",
    "\tlocal_pcd = o3d.geometry.PointCloud()\n",
    "\tlocal_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\t\n",
    "\t\n",
    "\t## label visualization \n",
    "\tlabeled_pcd = o3d.geometry.PointCloud()\n",
    "\tlabeled_pcd.points = o3d.utility.Vector3dVector(dataset[i].point_cloud[:, :3])\n",
    "\tlabeled_pcd.colors = o3d.utility.Vector3dVector(np.vstack([0,0,0] for i in range(np.asarray(labeled_pcd.points).shape[0])))\n",
    "\tpanoptic_labels = dataset[i].panoptic_labels # semantics + panoptics combined \n",
    "\tsemantic_labels = dataset[i].semantic_labels\n",
    "\tinstance_labels = dataset[i].instance_labels\n",
    "\tintensity = dataset[i].intensity\n",
    "\t\n",
    "\t\n",
    "\ttransform = dataset.get_pose(i)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tlocal_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,max_nn=200))\n",
    "\treg_p2l = registration.registration_icp(local_pcd, merge, 0.9, transform, registration.TransformationEstimationPointToPlane(), registration.ICPConvergenceCriteria(max_iteration=1000))\n",
    "\ttransform = reg_p2l.transformation\n",
    "\tlocal_pcd.transform(transform)\n",
    "\t\n",
    "\tlocal_pcd.normals = o3d.utility.Vector3dVector([])\n",
    "\t\n",
    "\tlocal_pcd.paint_uniform_color([0, 0, 0])\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tcolors, labels,local_labels = kDTree_1NN_feature_reprojection(np.asarray(local_pcd.colors), local_pcd, np.asarray(merge.colors), merge,panoptic_labels, max_radius=0.2)\n",
    "\tlabeled_pcd = color_pcd_by_labels(labeled_pcd,labels.reshape(-1,))\n",
    "\tlocal_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\to3d.io.write_point_cloud(\"test_data/test.pcd\", local_pcd, write_ascii=False, compressed=False, print_progress=False)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t#labeled_pcd.translate([0,120,0])\n",
    "\t#o3d.visualization.draw_geometries([local_pcd,labeled_pcd])\n",
    "\tunique_colors, labels = np.unique(colors, axis=0, return_inverse=True)\n",
    "\tunseen_mask = np.all(colors == [1,0,0], axis=1)\n",
    "\tlabels[unseen_mask] = -1\n",
    "\tstreet_mask = np.all(colors == [0,0,0], axis=1)\n",
    "\tlabels[street_mask] = 1\n",
    "\tnp.savez('output_files/7_tarl/ ' + str(i) + '.npz',labels=labels)\n",
    "\n",
    "\t\n",
    "\n",
    "\tnp.savez('output_files/7_original/' + str(i) + '.npz',ncut_labels=local_labels,kitti_labels=labels,pts=np.asarray(local_pcd.points),           \n",
    "\tintensities=intensity,kitti_labels_semantic=semantic_labels,kitti_labels_instance=instance_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "with np.load('output_files/7_original/0.npz') as data:\n",
    "            xyz = data['pts'].astype(np.float)\n",
    "            labels = data['ncut_labels'].astype(np.int32)  \n",
    "            kitti_labels = data['kitti_labels']\n",
    "            intensity = data['intensities']\n",
    "            \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "pcd = color_pcd_by_labels(pcd,labels)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
